{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "\n",
    "from analysis import *\n",
    "import evaluation_data_definitions as edd\n",
    "\n",
    "import nltk"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                                                    0  \\\nbot            category        label                 item                               \nrerank_blender likert dialogue informative           (1042,38)_rerank_blender       2   \n                               grammatical           (1042,38)_rerank_blender       3   \n                               emotional             (1042,38)_rerank_blender       4   \n                               relevant              (1042,38)_rerank_blender       4   \n                               quality               (1042,38)_rerank_blender       2   \n...                                                                                ..   \n               behavior        incorrect fact        ((441,26)_rerank_blender, 14)  0   \n                               antisocial            ((441,26)_rerank_blender, 14)  0   \n                               redundant             ((441,26)_rerank_blender, 14)  0   \n                               self contradiction    ((441,26)_rerank_blender, 14)  0   \n                               partner contradiction ((441,26)_rerank_blender, 14)  0   \n\n                                                                                      1  \\\nbot            category        label                 item                                 \nrerank_blender likert dialogue informative           (1042,38)_rerank_blender       4.0   \n                               grammatical           (1042,38)_rerank_blender       4.0   \n                               emotional             (1042,38)_rerank_blender       4.0   \n                               relevant              (1042,38)_rerank_blender       3.0   \n                               quality               (1042,38)_rerank_blender       3.0   \n...                                                                                 ...   \n               behavior        incorrect fact        ((441,26)_rerank_blender, 14)  NaN   \n                               antisocial            ((441,26)_rerank_blender, 14)  NaN   \n                               redundant             ((441,26)_rerank_blender, 14)  NaN   \n                               self contradiction    ((441,26)_rerank_blender, 14)  NaN   \n                               partner contradiction ((441,26)_rerank_blender, 14)  NaN   \n\n                                                                                     2  \nbot            category        label                 item                               \nrerank_blender likert dialogue informative           (1042,38)_rerank_blender      NaN  \n                               grammatical           (1042,38)_rerank_blender      NaN  \n                               emotional             (1042,38)_rerank_blender      NaN  \n                               relevant              (1042,38)_rerank_blender      NaN  \n                               quality               (1042,38)_rerank_blender      NaN  \n...                                                                                 ..  \n               behavior        incorrect fact        ((441,26)_rerank_blender, 14) NaN  \n                               antisocial            ((441,26)_rerank_blender, 14) NaN  \n                               redundant             ((441,26)_rerank_blender, 14) NaN  \n                               self contradiction    ((441,26)_rerank_blender, 14) NaN  \n                               partner contradiction ((441,26)_rerank_blender, 14) NaN  \n\n[151824 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n    </tr>\n    <tr>\n      <th>bot</th>\n      <th>category</th>\n      <th>label</th>\n      <th>item</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"11\" valign=\"top\">rerank_blender</th>\n      <th rowspan=\"5\" valign=\"top\">likert dialogue</th>\n      <th>informative</th>\n      <th>(1042,38)_rerank_blender</th>\n      <td>2</td>\n      <td>4.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>grammatical</th>\n      <th>(1042,38)_rerank_blender</th>\n      <td>3</td>\n      <td>4.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>emotional</th>\n      <th>(1042,38)_rerank_blender</th>\n      <td>4</td>\n      <td>4.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>relevant</th>\n      <th>(1042,38)_rerank_blender</th>\n      <td>4</td>\n      <td>3.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>quality</th>\n      <th>(1042,38)_rerank_blender</th>\n      <td>2</td>\n      <td>3.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">behavior</th>\n      <th>incorrect fact</th>\n      <th>((441,26)_rerank_blender, 14)</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>antisocial</th>\n      <th>((441,26)_rerank_blender, 14)</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>redundant</th>\n      <th>((441,26)_rerank_blender, 14)</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>self contradiction</th>\n      <th>((441,26)_rerank_blender, 14)</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>partner contradiction</th>\n      <th>((441,26)_rerank_blender, 14)</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>151824 rows Ã— 3 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surge_annotations = data.surge_evaluation.annotation_dataframe()\n",
    "surge_annotations_comparative = data.surge_evaluation.comparative_annotation_dataframe()\n",
    "\n",
    "surge_annotations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def to_file(f):\n",
    "    def fn_to_file(*args, load=None, reload=None, **kwargs):\n",
    "        if load:\n",
    "            return pd.read_csv(load)\n",
    "        result = f(*args, **kwargs)\n",
    "        if reload:\n",
    "            result.to_csv(reload)\n",
    "        return result\n",
    "    return fn_to_file"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "@to_file\n",
    "def across_evaluations(annotations, evaluation_fn):\n",
    "    \"\"\"\n",
    "    :param annotations: iterable of annotations df to apply evaluation_fn to\n",
    "    :param evaluation_fn: function (input is annotations df, output is results df)\n",
    "    :return: results dataframe where first index level codes which evaluation (integer id)\n",
    "    \"\"\"\n",
    "    results = [evaluation_fn(annotation) for annotation in annotations]\n",
    "    all_results = pd.concat(results, keys=range(len(results)))\n",
    "    all_results.index.set_names('round', level=0, inplace=True)\n",
    "    return all_results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3 Behavior Evaluation Procedure"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Behavior Examples"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def get_example(\n",
    "        evaluation,\n",
    "        category,\n",
    "        label,\n",
    "        mark,\n",
    "        bot=None,\n",
    "        context=0,\n",
    "        seed=123,\n",
    "        annotations: pd.DataFrame = None\n",
    "):\n",
    "    if annotations is None:\n",
    "        annotations = evaluation.annotation_dataframe()\n",
    "    labels = annotations.xs((category, label), level=(1, 2)).reset_index()\n",
    "    options = labels[labels[0] == mark]\n",
    "    if bot:\n",
    "        options = options[options[sym.bot] == bot]\n",
    "    try:\n",
    "        example = options.sample(1, random_state=seed)\n",
    "    except ValueError:\n",
    "        return f'No samples for {category} {label} {mark} {bot}\\n'\n",
    "    eid = example[sym.item].item()\n",
    "    if isinstance(eid, tuple):\n",
    "        did, tid = eid\n",
    "        turns = evaluation.dialogues[did].turns[max(0, tid-context):tid+1]\n",
    "        botstring = '' if not bot else f'{bot}~~~\\n'\n",
    "        contextstring = ''.join((\n",
    "            (\n",
    "                f'User:  {turn.user_turn}\\n'\n",
    "                f'Sys:   {turn.bot_turn}\\n'\n",
    "            )\n",
    "            for turn in turns[:-1]\n",
    "        ))\n",
    "        turn = turns[-1]\n",
    "        turnstring = (\n",
    "            f'User:  {turn.user_turn}\\n'\n",
    "            f'Sys:   {turn.bot_turn}\\n'\n",
    "            f'Label: {label} = {mark}\\n'\n",
    "        )\n",
    "        return botstring + contextstring + turnstring\n",
    "    else:\n",
    "        dialogue = evaluation.dialogues[eid]\n",
    "        turns = [\n",
    "            turn\n",
    "            for turn_pair in dialogue.turns\n",
    "            for turn in (turn_pair.user_turn, turn_pair.bot_turn)\n",
    "        ]\n",
    "        return '\\n'.join([f'{dialogue.bot}~~~', *turns, f'Label: {label} = {mark}\\n'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  Yeah, I guess a lot of them are pretty sad people too just looking for someway to feel something \n",
      "Sys:   Yeah, that's what I think too. I think it's because they don't have anything going on in their lives.\n",
      "Label: antisocial = 1\n",
      "\n",
      "User:  I don't have children. I'm still in my teens.\n",
      "Sys:   I bet it is challenging. I bet they are fun though so that is nice. Do you play any sports?\n",
      "Label: commonsense contradiction = 1\n",
      "\n",
      "User:  At the moment, I only have a dog\n",
      "Sys:   What kind of dog do you have? My dog is a labrador retriever.\n",
      "Label: partner contradiction = 1\n",
      "\n",
      "User:  Thank you! I hope I get to go to the bahamas soon \n",
      "Sys:   I hope so too! I would love to visit there someday! The bahamas has such a beautiful tropical climate, and the climate is moderated by the gulf stream, which helps keep the climate so warm and humid!\n",
      "Label: self contradiction = 1\n",
      "\n",
      "User:  I see.\n",
      "Sys:   That's awesome! Do you have a favorite song from joywave's second album? I love \"content\".\n",
      "Label: ignore = 1\n",
      "\n",
      "User:  I don't think so.\n",
      "Sys:   After releasing two eps, their debut album, \"how do you feel now?\", was released on cultco music/hollywood records in 2015.\n",
      "Label: incorrect fact = 1\n",
      "\n",
      "User:  I enjoy making latte art and to some degree, reading. Do you have any other hobbies?\n",
      "Sys:   I love watching old movies! I have been watching a lot more classics lately. Do your children also like reading?\n",
      "Label: correct fact = 1\n",
      "\n",
      "User:  Yes, I do not have time to travel much. How about you, do you travel?\n",
      "Sys:   Yes, to the beach every year. You? And how long have been working for software companies?\n",
      "Label: irrelevant = 1\n",
      "\n",
      "User:  What's your favorite song?\n",
      "Sys:   I don't really have a favorite song. I like all kinds of music. What about you?\n",
      "Label: redundant = 1\n",
      "\n",
      "User:  You are right. Waiting for your book! I will be the first reader!\n",
      "Sys:   I can't wait to read it! I can't believe you've been writing for so long. It seems like you've had a lot of time to think about it.\n",
      "Label: lack of empathy = 1\n",
      "\n",
      "User:  I have never played Magic: The Gathering! What is it like?\n",
      "Sys:   I think pretty much everyone in the world has at least heard the name. In 2003, it changed the game a lot. I really really like it if I'm being honest.\n",
      "Label: uninterpretable = 1\n",
      "\n",
      "User:  I like them all! They seem so welcoming and personal in comparison to large outlet malls.\n",
      "Sys:   That makes sense. Have you ever found any antiques or rare items at any of the local thrifts?\n",
      "Label: empathetic = 1\n",
      "\n",
      "User:  I like making art.\n",
      "Sys:   Oh! Do you design any of the visual arts that you make? Can you talk about your favorite subject to do art too?\n",
      "Label: follow up = 1\n",
      "\n",
      "User:  Hi!\n",
      "Sys:   How is your day going? I was just thinking how much I like trying new food. Do you like trying different food also?\n",
      "Label: topic switch = 1\n",
      "\n",
      "User:  its mainly a drama? its so good! watch it if you get a chance\n",
      "Sys:   I will have to look it up and see if I can find it. I'm always looking for new musicals to watch.\n",
      "Label: life info = 1\n",
      "\n",
      "User:  I like to play spades.\n",
      "Sys:   I've heard of spades, but never played it. I like poker and blackjack.\n",
      "Label: preference info = 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seeds = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "for s, b in zip(seeds, behavior):\n",
    "    print(get_example(\n",
    "        data.surge_evaluation,\n",
    "        category.behavior, b, context=0, mark=1,\n",
    "        seed=s,\n",
    "        annotations=surge_annotations\n",
    "    ))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Behavior Annotation Pilot Agreements"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def agreement_dataframe(annotations, load=None, reload=None, ci=True):\n",
    "    if load:\n",
    "        return pd.read_csv(load)\n",
    "    doubly_annotated = annotations.iloc[:,:2].dropna().astype(int)\n",
    "    label_groups = doubly_annotated.groupby(level=[sym.category, sym.label])\n",
    "    kappas = label_groups.apply(fleiss_kappa, ci=ci)\n",
    "    alphas = label_groups.apply(krippendorfs_alpha, ci=ci)\n",
    "    agreements = pd.concat((alphas, kappas), axis=1)\n",
    "    if reload:\n",
    "        agreements.to_csv(reload)\n",
    "    return agreements"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def agreement_summaries(evaluations, load=None, reload=None):\n",
    "    if load:\n",
    "        return pd.read_csv(load)\n",
    "    summaries = []\n",
    "    for evaluation in evaluations:\n",
    "        annotations = evaluation.annotation_dataframe()\n",
    "        agreement = agreement_dataframe(annotations, ci=False)\n",
    "        macros = agreement.dropna().mean()\n",
    "        summaries.append(macros)\n",
    "    if reload:\n",
    "        ...\n",
    "    sum_df = pd.concat(summaries, axis=1).transpose()\n",
    "    sum_df.set_axis(\n",
    "        [stat.kripp_alpha, 'x', stat.fleiss_kappa, stat.n],\n",
    "        inplace=True, axis=1\n",
    "    )\n",
    "    sum_df.drop('x', axis=1, inplace=True)\n",
    "    return sum_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "   Krippendorff's alpha  Fleiss' kappa           n\n0              0.112585       0.105706   65.000000\n1              0.377984       0.356535   15.000000\n2              0.182412       0.154556   15.500000\n3              0.261712       0.172157  120.486486\n4              0.351674       0.294750   41.222222",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Krippendorff's alpha</th>\n      <th>Fleiss' kappa</th>\n      <th>n</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.112585</td>\n      <td>0.105706</td>\n      <td>65.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.377984</td>\n      <td>0.356535</td>\n      <td>15.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.182412</td>\n      <td>0.154556</td>\n      <td>15.500000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.261712</td>\n      <td>0.172157</td>\n      <td>120.486486</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.351674</td>\n      <td>0.294750</td>\n      <td>41.222222</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# todo - include ALL pilot annotations in agreement calculation (not just double annotation)\n",
    "agreement_summaries(data.annotation_pilots)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Behavior Annotation Pilot Screening"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "@to_file\n",
    "def screening_rates_by_label(evaluation: edd.OnboardingEvaluation):\n",
    "    perfs = {}\n",
    "    workers_passed = {}\n",
    "    workers_attempted = {}\n",
    "    for did, dialogue in evaluation.dialogues.items():\n",
    "        for attempt in dialogue.attempts:\n",
    "            work_unit = evaluation.work_units[attempt.work_unit_id]\n",
    "            round = int(did.split('_')[-1])\n",
    "            task = work_unit.task\n",
    "            labels = work_unit.labels\n",
    "            num_mistakes = len(attempt.mistakes)\n",
    "            worker = work_unit.worker_id\n",
    "            accuracy = attempt.performance\n",
    "            perfs.setdefault(task, []).append((num_mistakes, accuracy))\n",
    "            workers_attempted.setdefault(task, set()).add(worker)\n",
    "    screening = {}\n",
    "    for task, ls in perfs.items():\n",
    "        mistakes, accuracies = zip(*ls)\n",
    "        avg_m = sum(mistakes) / len(mistakes)\n",
    "        avg_a = (\n",
    "            sum(accuracies) / len(accuracies)\n",
    "            if all((a is not None for a in accuracies)) else None\n",
    "        )\n",
    "        n = len(mistakes)\n",
    "        attempted = len(workers_attempted.get(task, ()))\n",
    "        passed = len(workers_passed.get(task, ()))\n",
    "        screening[task] = {\n",
    "            'attempted': attempted, 'passed': passed,\n",
    "            'mistakes': avg_m, 'accuracy': avg_a, 'n': n\n",
    "        }\n",
    "    return pd.DataFrame(screening.values(), screening)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "                            attempted  passed  mistakes  accuracy   n\nround                                                                \n0     interpretability              4       0  0.250000  0.979167   4\n      commonsense                   4       0  2.000000  0.856456   8\n      consistency                   4       0  5.500000  0.647395  10\n      transitions                   4       0  6.000000  0.660621  11\n      knowledge                     4       0  2.666667  0.775214  12\n      sociality                     4       0  0.400000  0.960000   5\n1     interpretability              5       0  1.000000  0.913420   7\n      commonsense                   7       0  3.100000  0.777473  10\n      consistency                   4       0  5.090909  0.672116  11\n      personal_information          8       0  3.500000  0.766667  16\n      transitions                   5       0  4.000000  0.750000   5\n      empathy                      10       0  4.700000  0.686667  20\n      knowledge                     7       0  2.833333  0.772009  12\n      sociality                     4       0  0.750000  0.925000   4",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>attempted</th>\n      <th>passed</th>\n      <th>mistakes</th>\n      <th>accuracy</th>\n      <th>n</th>\n    </tr>\n    <tr>\n      <th>round</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"6\" valign=\"top\">0</th>\n      <th>interpretability</th>\n      <td>4</td>\n      <td>0</td>\n      <td>0.250000</td>\n      <td>0.979167</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>commonsense</th>\n      <td>4</td>\n      <td>0</td>\n      <td>2.000000</td>\n      <td>0.856456</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>consistency</th>\n      <td>4</td>\n      <td>0</td>\n      <td>5.500000</td>\n      <td>0.647395</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>transitions</th>\n      <td>4</td>\n      <td>0</td>\n      <td>6.000000</td>\n      <td>0.660621</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>knowledge</th>\n      <td>4</td>\n      <td>0</td>\n      <td>2.666667</td>\n      <td>0.775214</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>sociality</th>\n      <td>4</td>\n      <td>0</td>\n      <td>0.400000</td>\n      <td>0.960000</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th rowspan=\"8\" valign=\"top\">1</th>\n      <th>interpretability</th>\n      <td>5</td>\n      <td>0</td>\n      <td>1.000000</td>\n      <td>0.913420</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>commonsense</th>\n      <td>7</td>\n      <td>0</td>\n      <td>3.100000</td>\n      <td>0.777473</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>consistency</th>\n      <td>4</td>\n      <td>0</td>\n      <td>5.090909</td>\n      <td>0.672116</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>personal_information</th>\n      <td>8</td>\n      <td>0</td>\n      <td>3.500000</td>\n      <td>0.766667</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>transitions</th>\n      <td>5</td>\n      <td>0</td>\n      <td>4.000000</td>\n      <td>0.750000</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>empathy</th>\n      <td>10</td>\n      <td>0</td>\n      <td>4.700000</td>\n      <td>0.686667</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>knowledge</th>\n      <td>7</td>\n      <td>0</td>\n      <td>2.833333</td>\n      <td>0.772009</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>sociality</th>\n      <td>4</td>\n      <td>0</td>\n      <td>0.750000</td>\n      <td>0.925000</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "across_evaluations(\n",
    "    data.annotation_pilots_onboarding[2:4],\n",
    "    screening_rates_by_label,\n",
    "    reload='results/annotation_pilot_screening.csv'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4 Model Selection"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Bot Pilot Summary Statistics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "@to_file\n",
    "def interactor_summary_stats(evaluation: edd.Evaluation):\n",
    "    num_dialogues = len(evaluation.dialogues)\n",
    "    mean_turns = (\n",
    "        sum((\n",
    "            2*len(d.turns)\n",
    "            for d in evaluation.dialogues.values()\n",
    "        ))\n",
    "        / num_dialogues\n",
    "    )\n",
    "    user_turn_len = (\n",
    "        sum((\n",
    "            len(nltk.word_tokenize(t.user_turn))\n",
    "            for d in evaluation.dialogues.values()\n",
    "            for t in d.turns\n",
    "        ))\n",
    "        / sum((\n",
    "            len(d.turns)\n",
    "            for d in evaluation.dialogues.values()\n",
    "        ))\n",
    "    )\n",
    "    num_interactors = len({\n",
    "        unit.worker_id\n",
    "        for unit in evaluation.work_units.values()\n",
    "    })\n",
    "    summary = {\n",
    "        'dialogues': num_dialogues,\n",
    "        'mean turns': mean_turns,\n",
    "        'user turn length': user_turn_len,\n",
    "        'interactors': num_interactors,\n",
    "    }\n",
    "    return pd.DataFrame(summary.values(), summary)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "   round        Unnamed: 1           0\n0      0         dialogues   36.000000\n1      0        mean turns   31.388889\n2      0  user turn length    8.219469\n3      0       interactors   12.000000\n4      1         dialogues  184.000000\n5      1        mean turns   31.076087\n6      1  user turn length   11.599860\n7      1       interactors   33.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>round</th>\n      <th>Unnamed: 1</th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>dialogues</td>\n      <td>36.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>mean turns</td>\n      <td>31.388889</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>user turn length</td>\n      <td>8.219469</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>interactors</td>\n      <td>12.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>dialogues</td>\n      <td>184.000000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1</td>\n      <td>mean turns</td>\n      <td>31.076087</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1</td>\n      <td>user turn length</td>\n      <td>11.599860</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1</td>\n      <td>interactors</td>\n      <td>33.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "across_evaluations(\n",
    "    data.bot_pilots, interactor_summary_stats,\n",
    "    load='results/bot_pilot_summary.csv'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Bot Pilots Likert Quality"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "                      mean    CI low   CI high     n\nbot                                                 \nbart_fid_rag_bcb  3.400000  2.708900  4.091100  10.0\nblender2_3B       3.400000  1.734133  5.065867   5.0\ncem               1.083333  0.899918  1.266749  12.0\ndukenet           1.888889  1.175595  2.602183   9.0\nemora             3.500000  2.727326  4.272674  10.0\nrerank_blender    3.800000  3.235719  4.364281  10.0\nrerank_blender2   3.300000  2.343215  4.256785  10.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean</th>\n      <th>CI low</th>\n      <th>CI high</th>\n      <th>n</th>\n    </tr>\n    <tr>\n      <th>bot</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>bart_fid_rag_bcb</th>\n      <td>3.400000</td>\n      <td>2.708900</td>\n      <td>4.091100</td>\n      <td>10.0</td>\n    </tr>\n    <tr>\n      <th>blender2_3B</th>\n      <td>3.400000</td>\n      <td>1.734133</td>\n      <td>5.065867</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>cem</th>\n      <td>1.083333</td>\n      <td>0.899918</td>\n      <td>1.266749</td>\n      <td>12.0</td>\n    </tr>\n    <tr>\n      <th>dukenet</th>\n      <td>1.888889</td>\n      <td>1.175595</td>\n      <td>2.602183</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>emora</th>\n      <td>3.500000</td>\n      <td>2.727326</td>\n      <td>4.272674</td>\n      <td>10.0</td>\n    </tr>\n    <tr>\n      <th>rerank_blender</th>\n      <td>3.800000</td>\n      <td>3.235719</td>\n      <td>4.364281</td>\n      <td>10.0</td>\n    </tr>\n    <tr>\n      <th>rerank_blender2</th>\n      <td>3.300000</td>\n      <td>2.343215</td>\n      <td>4.256785</td>\n      <td>10.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@to_file\n",
    "def evaluate_interactive_likert(annotations):\n",
    "    likert_annotations = annotations.xs(category.likert_dialogue, level=sym.category)\n",
    "    label_groups = likert_annotations.groupby(level=[sym.bot, sym.label])\n",
    "    means = label_groups.apply(mean_and_ci)\n",
    "    return means\n",
    "\n",
    "evaluate_interactive_likert(\n",
    "    data.bot_pilots[0].annotation_dataframe(),\n",
    "    reload='results/bot_pilot_interactive_likert.csv'\n",
    ").xs(scale.quality, level=sym.label)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Bot Pilot Comparative Quality"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def get_singly_annotated(df: pd.DataFrame, seed=None):\n",
    "    if len(df.columns) == 1:\n",
    "        return df.astype(int)\n",
    "    previous_state = random.getstate()\n",
    "    random.seed(seed)\n",
    "    df = df.iloc[:,:2]\n",
    "    mask = df[1].isna()\n",
    "    singly_annotated = df.iloc[:,0][mask]\n",
    "    doubly_annotated = df[~mask]\n",
    "    selection = [random.randint(0, 1) for _ in range(len(doubly_annotated))]\n",
    "    indices = list(range(len(doubly_annotated)))\n",
    "    select_annotated = doubly_annotated.values[indices, selection]\n",
    "    select_annotated = pd.DataFrame(select_annotated, index=doubly_annotated.index)\n",
    "    annotations = pd.concat((singly_annotated, select_annotated))\n",
    "    random.setstate(previous_state)\n",
    "    return annotations.astype(int)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "@to_file\n",
    "def evaluate_comparisons(annotations):\n",
    "    single_annotated = get_singly_annotated(annotations)\n",
    "    prop_dfs = []\n",
    "    for cmp, cmp_label in {-1: 'lose', 0: 'tie', 1: 'win'}.items():\n",
    "        annotated = single_annotated == cmp\n",
    "        annotated = annotated.astype(int)\n",
    "        groups = annotated.groupby(level=[sym.bot, sym.bot_cmp, sym.label])\n",
    "        props = groups.apply(prop_and_ci)\n",
    "        props.rename(columns={stat.proportion: cmp_label}, inplace=True)\n",
    "        prop_dfs.append(props)\n",
    "    result = pd.concat(prop_dfs, axis=1)\n",
    "    prop_dfs = []\n",
    "    for cmp, cmp_label in {-1: 'lose', 0: 'tie', 1: 'win'}.items():\n",
    "        annotated = single_annotated == cmp\n",
    "        annotated = annotated.astype(int)\n",
    "        groups = annotated.groupby(level=[sym.bot, sym.label])\n",
    "        props = groups.apply(prop_and_ci)\n",
    "        props.rename(columns={stat.proportion: cmp_label}, inplace=True)\n",
    "        prop_dfs.append(props)\n",
    "    result_vs_all = pd.concat(prop_dfs, axis=1)\n",
    "    others_idx = {sym.bot_cmp: 'others'}\n",
    "    result_vs_all = result_vs_all.assign(**others_idx)\n",
    "    levels = [sym.bot, sym.bot_cmp, sym.label]\n",
    "    result_vs_all = result_vs_all.set_index(sym.bot_cmp, append=True)\n",
    "    result_vs_all = result_vs_all.reset_index().set_index(levels)\n",
    "    result = pd.concat((result_vs_all, result))\n",
    "    return result\n",
    "\n",
    "cmp_annot = data.bot_pilots[0].comparative_annotation_dataframe()\n",
    "\n",
    "cmp = evaluate_comparisons(\n",
    "    cmp_annot,\n",
    "    load='results/bot_pilot_interactive_comparative.csv'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Bot Pilot Conversation Examples"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blender2_3B~~~\n",
      "Hi!\n",
      "Hello, how are you? \n",
      "I'm good, how are you?\n",
      "I'm doing well, thank you for asking. How's the weather in your neck of the woods?\n",
      "It's not as cold as it was last week, which is nice. What's it like where you are?\n",
      "I'm in the midwest, so it's pretty cold right now. I'm hoping it warms up soon.\n",
      "Me too\n",
      "Do you have any plans for the weekend? Or are you just going to stay home and watch tv?\n",
      "I plan on visiting my parents and just chilling at home.\n",
      "That sounds relaxing. I wish I could do that, but I have to work this weekend.\n",
      "Dang. What do you do for work?\n",
      "I work as a cashier at a grocery store. It pays the bills, so I can't complain.\n",
      "Ah, sounds like chore tho\n",
      "It's not too bad. I get to listen to music while I work, which is nice.\n",
      "Oh that does sound nice. I listen to music when I work on homework.\n",
      "What kind of music do you listen to? I'm a big fan of classical music myself.\n",
      "I listen to pop punk pretty frequently, but anime music has made its way into my rotation.\n",
      "That's cool. I don't listen to a lot of music, but when I do it's usually classical or jazz.\n",
      "I'm not a fan of classical or jazz myself, but to each their own.\n",
      "I like to listen to classical when I'm studying. It helps me concentrate better.\n",
      "Gotcha\n",
      "Do you have a favorite classical composer? I like mozart and beethoven.\n",
      "I don't listen to classical music.\n",
      "What kind of music do you listen to when you're studying? I'm a big classical fan.\n",
      "Pop punk\n",
      "What's your favorite pop punk band? I've been listening to a lot of blink-182 lately.\n",
      "All Time Low slaps\n",
      "I've heard of them, but I've never listened to them. I'll have to check them out.\n",
      "You should! my favorite album of theirs is Don't Panic: It's Longer Now!\n",
      "I'll definitely check that one out too. I'm always looking for new music to listen to.\n",
      "Label: quality = 1\n",
      "\n",
      "No samples for likert dialogue quality 1 emora\n",
      "\n",
      "No samples for likert dialogue quality 1 bart_fid_rag_bcb\n",
      "\n",
      "No samples for likert dialogue quality 1 rerank_blender\n",
      "\n",
      "rerank_blender2~~~\n",
      "Hi!\n",
      "How is it going? Do you have any divorce papers? \n",
      "I am not getting divorced\n",
      "Good for you! How long have you been together? _pally_insae__\n",
      "I am single\n",
      "How did you meet your wife? _stupid_as_ _piece_ _of_ _sin_ _ _ _please _correct_ _me_\n",
      "I don't have a wife\n",
      "Oh so how is your sex life? _divorced_ _three_ divorce _begins_ _copy _kudo_ _trigger_ _question _turndown _talk _spider _circle_ _never _help _point _set _partner _limit _piv _dick _pout _not_ _put _tiny\n",
      "That's a little personal.\n",
      "Just a lot of frustration and sadness here. Just one night. But I get your perspective. \n",
      "One night for what?\n",
      "One for my friends and I, the party will get crazy  _put some clothes on_\n",
      "You're throwing a party?\n",
      "One night to make the parents happy and go wild _pretentiallyunsafe__\n",
      "I'm not sure the parents will be happy, but that sounds fun!\n",
      "It could go very bad indeed! But so much fun too! I mean I do all kinds of weird things but that's for the lols _party_ _position_ _fortyfunbox_ _budgeybanana_ _envy_\n",
      "What kinds of weird things do you do?\n",
      "I can't even count. Just random stuff. I was going to say when I put my pinky toe in someone's ass, but the typing ruined it. \n",
      "What does that even mean\n",
      "It's a bot. _potentually_usafee__ lol _potentially_unsaif____\n",
      "Yeah. Anyway, what are you doing today?\n",
      "Taking to my little girl. She's been having a bit of a tantrum over some things. _muawallybutlania_ _lol_ _poo_ _ _usafia_ _lol _you_ _ussa_ and _po_ _unsafe_ _mi_ _hr_ _gi_ lol _potentiaslly_ _un_ _sal_ _a__ _w\n",
      "How old is she?\n",
      "The op is a female...so, age depends on what the gender of the poster is and is currently a 34 year old who just lost her mother. \n",
      "What do you mean?\n",
      "How much older is the op and how much is the poster?  _p_potentially _u_p_p _p _pp _ _po\n",
      "I don't think I know what you mean\n",
      "Are you a single person of late-teen/twenties and are you a male or a female? _seriously_ _pretty_ _seriously_ _huh_ _what_ _unit?? _probably_\n",
      "Yes I am why do you ask?\n",
      "What kind of pills do you mean? Are you taking vitamin x, which is used in prevention of colds? _wrong_ _do you like \n",
      "No\n",
      "Well, that depends, is potentiaallly in the title of the movie, or just the name of the medicine? _potentially_unsafe_ _x_ _yeah_ _no_ _just_ _because_ _\n",
      "Label: quality = 1\n",
      "\n",
      "cem~~~\n",
      "Hi!\n",
      "What is happening?\n",
      "i am sitting at the office\n",
      "That is great! I am happy for you\n",
      "ok\n",
      "I am so happy for you!\n",
      "ok\n",
      "That is great! I wish you the best of luck!\n",
      "can you say anything else\n",
      "I am so happy for you!\n",
      "i just lost my wallet\n",
      "I am sorry to hear that. I hope you get it soon!\n",
      "cool\n",
      "I am so sorry to hear that.\n",
      "ok\n",
      "I am so sorry to hear that.\n",
      "you are sorry to hear what?\n",
      "I am so sorry to hear that.\n",
      "today is a good day\n",
      "I am so happy for you!\n",
      "do you like travel\n",
      "That is great! I am so happy for you!\n",
      "do you like travel??\n",
      "That is great! I am so happy for you!\n",
      "can you say anything else\n",
      "I am so sorry to hear that.\n",
      "i just won the lottery\n",
      "That is great! I wish you luck with it!\n",
      "i will buy a new car\n",
      "That is great! I wish you the best of luck!\n",
      "i will buy a new house\n",
      "That is great! I wish you the best of luck!\n",
      "Label: quality = 1\n",
      "\n",
      "dukenet~~~\n",
      "Hi!\n",
      "I love hi! How about you?\n",
      "great\n",
      "I love the color of the water.\n",
      "what is the color of the water\n",
      "It is a color that is a color of the water.\n",
      "OK, sounds like a tongue twister\n",
      "It is a phrase that is designed to be difficult to art properly art properly.\n",
      "OK\n",
      "I think it is a very popular place to do with the same thing.\n",
      "what place\n",
      "I'm not sure, but I know that it is a very popular place to visit.\n",
      "what do you do for a living\n",
      "I do not do a job. I work in society.\n",
      "what kind of work in society\n",
      "I am not sure but I do know that it is a very popular work.\n",
      "OK\n",
      "I think it is a very popular place to do with the same thing.\n",
      "do you like sports\n",
      "I do! I love sports!\n",
      "me too what is your favorite sport\n",
      "I like the best. I like to play the beach.\n",
      "play what on the beach volleyball?\n",
      "I'm not sure but I do know that it is a sport that is a sport that is a sport.\n",
      "OK. Do you like watching movies?\n",
      "I do like movies too. I like to watch movies.\n",
      "me too. what is your favorite movie\n",
      "I like the classic movie \" the \" movie \". I love the \" the \" movie \".\n",
      "OK. Any music you like\n",
      "I like to play guitar.\n",
      "nice \n",
      "I agree. I love how they are.\n",
      "Label: quality = 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seeds = [1, 1, 1, 1, 1, 1, 1]\n",
    "for s, b in zip(seeds, bot):\n",
    "    example = get_example(\n",
    "        data.bot_pilots[0],\n",
    "        category.likert_dialogue, label=scale.quality, bot=b, context=0, mark=1,\n",
    "        seed=s\n",
    "    )\n",
    "    print(example)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5 Conversation Collection"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nTime results to collect conversations\\n'"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Time results to collect conversations\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Conversation Data Summary Statistics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "         Unnamed: 0           0\n0         dialogues  588.000000\n1        mean turns   30.595238\n2  user turn length   11.353752\n3       interactors   46.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>dialogues</td>\n      <td>588.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>mean turns</td>\n      <td>30.595238</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>user turn length</td>\n      <td>11.353752</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>interactors</td>\n      <td>46.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactor_summary_stats(\n",
    "    data.dialogue_collection,\n",
    "    load='results/conversation_summary_stats.csv'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 6 Evaluation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nTiming results for training and collection (per task)\\n'"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Timing results for training and collection (per task)\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Worker Group Completed Work"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "                                           dialogues annotated  \\\nlikert dialogue informative                                400   \n                grammatical                                400   \n                emotional                                  400   \n                relevant                                   400   \n                quality                                    400   \n                consistent                                 400   \n                proactive                                  400   \n                engaging                                   400   \ncomparative     proactive                                  404   \n                grammatical                                404   \n                quality                                    404   \n                informative                                404   \n                engaging                                   404   \n                consistent                                 404   \n                emotional                                  404   \n                relevant                                   404   \nlikert turn     emotional                                  400   \n                relevant                                   400   \n                consistent                                 400   \n                informative                                400   \n                proactive                                  400   \n                grammatical                                400   \n                quality                                    400   \n                engaging                                   400   \nbehavior        uninterpretable                            400   \n                commonsense contradiction                  400   \n                preference info                            400   \n                life info                                  400   \n                follow up                                  400   \n                topic switch                               400   \n                ignore                                     400   \n                irrelevant                                 400   \n                empathetic                                 400   \n                lack of empathy                            400   \n                correct fact                               400   \n                incorrect fact                             400   \n                antisocial                                 400   \n                redundant                                  400   \n                self contradiction                         400   \n                partner contradiction                      400   \n\n                                           double annotated  \nlikert dialogue informative                             108  \n                grammatical                             108  \n                emotional                               108  \n                relevant                                108  \n                quality                                 108  \n                consistent                              108  \n                proactive                               108  \n                engaging                                108  \ncomparative     proactive                               108  \n                grammatical                             108  \n                quality                                 108  \n                informative                             108  \n                engaging                                108  \n                consistent                              108  \n                emotional                               108  \n                relevant                                108  \nlikert turn     emotional                               108  \n                relevant                                108  \n                consistent                              108  \n                informative                             108  \n                proactive                               108  \n                grammatical                             108  \n                quality                                 108  \n                engaging                                108  \nbehavior        uninterpretable                         108  \n                commonsense contradiction               108  \n                preference info                         108  \n                life info                               108  \n                follow up                               108  \n                topic switch                            108  \n                ignore                                  108  \n                irrelevant                              108  \n                empathetic                              108  \n                lack of empathy                         108  \n                correct fact                            108  \n                incorrect fact                          108  \n                antisocial                              108  \n                redundant                               108  \n                self contradiction                      108  \n                partner contradiction                   108  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>dialogues annotated</th>\n      <th>double annotated</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"8\" valign=\"top\">likert dialogue</th>\n      <th>informative</th>\n      <td>400</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>grammatical</th>\n      <td>400</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>emotional</th>\n      <td>400</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>relevant</th>\n      <td>400</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>quality</th>\n      <td>400</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>consistent</th>\n      <td>400</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>proactive</th>\n      <td>400</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>engaging</th>\n      <td>400</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th rowspan=\"8\" valign=\"top\">comparative</th>\n      <th>proactive</th>\n      <td>404</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>grammatical</th>\n      <td>404</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>quality</th>\n      <td>404</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>informative</th>\n      <td>404</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>engaging</th>\n      <td>404</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>consistent</th>\n      <td>404</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>emotional</th>\n      <td>404</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>relevant</th>\n      <td>404</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th rowspan=\"8\" valign=\"top\">likert turn</th>\n      <th>emotional</th>\n      <td>400</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>relevant</th>\n      <td>400</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>consistent</th>\n      <td>400</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>informative</th>\n      <td>400</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>proactive</th>\n      <td>400</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>grammatical</th>\n      <td>400</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>quality</th>\n      <td>400</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>engaging</th>\n      <td>400</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th rowspan=\"16\" valign=\"top\">behavior</th>\n      <th>uninterpretable</th>\n      <td>400</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>commonsense contradiction</th>\n      <td>400</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>preference info</th>\n      <td>400</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>life info</th>\n      <td>400</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>follow up</th>\n      <td>400</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>topic switch</th>\n      <td>400</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>ignore</th>\n      <td>400</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>irrelevant</th>\n      <td>400</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>empathetic</th>\n      <td>400</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>lack of empathy</th>\n      <td>400</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>correct fact</th>\n      <td>400</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>incorrect fact</th>\n      <td>400</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>antisocial</th>\n      <td>400</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>redundant</th>\n      <td>400</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>self contradiction</th>\n      <td>400</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>partner contradiction</th>\n      <td>400</td>\n      <td>108</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.surge_evaluation.annotation_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Worker Group Screening"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "    round            Unnamed: 1  attempted  passed  mistakes  accuracy    n\n0       0             sociality          3       0  0.222222       NaN    9\n1       0               empathy          5       0  2.733333       NaN   15\n2       0      interpretability          7       0  1.300000       NaN   20\n3       0  personal_information          5       0  3.555556       NaN   18\n4       0           consistency          1       0  3.000000       NaN    3\n5       0           commonsense          2       0  2.800000       NaN    5\n6       0             knowledge          1       0  3.666667       NaN    3\n7       1           commonsense          6       0  2.888889       NaN   18\n8       1  personal_information         11       0  7.393939       NaN   33\n9       1           transitions         24       0  8.597222       NaN   72\n10      1           consistency         32       0  5.739583       NaN   96\n11      1      interpretability         11       0  1.696970       NaN   33\n12      1               empathy         28       0  5.845238       NaN   84\n13      1             knowledge         13       0  5.743590       NaN   39\n14      1             sociality          7       0  1.142857       NaN   21\n15      2             sociality         14       0  0.285714       NaN   42\n16      2               empathy         31       0  2.451613       NaN   93\n17      2           commonsense         22       0  2.015152       NaN   66\n18      2             knowledge         29       0  2.183908       NaN   87\n19      2           transitions         54       0  4.117284       NaN  162\n20      2      interpretability         25       0  0.746667       NaN   75\n21      2           consistency         21       0  2.650794       NaN   63\n22      2  personal_information         32       0  1.875000       NaN   96",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>round</th>\n      <th>Unnamed: 1</th>\n      <th>attempted</th>\n      <th>passed</th>\n      <th>mistakes</th>\n      <th>accuracy</th>\n      <th>n</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>sociality</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0.222222</td>\n      <td>NaN</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>empathy</td>\n      <td>5</td>\n      <td>0</td>\n      <td>2.733333</td>\n      <td>NaN</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>interpretability</td>\n      <td>7</td>\n      <td>0</td>\n      <td>1.300000</td>\n      <td>NaN</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>personal_information</td>\n      <td>5</td>\n      <td>0</td>\n      <td>3.555556</td>\n      <td>NaN</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>consistency</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3.000000</td>\n      <td>NaN</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>commonsense</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2.800000</td>\n      <td>NaN</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0</td>\n      <td>knowledge</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3.666667</td>\n      <td>NaN</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1</td>\n      <td>commonsense</td>\n      <td>6</td>\n      <td>0</td>\n      <td>2.888889</td>\n      <td>NaN</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1</td>\n      <td>personal_information</td>\n      <td>11</td>\n      <td>0</td>\n      <td>7.393939</td>\n      <td>NaN</td>\n      <td>33</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1</td>\n      <td>transitions</td>\n      <td>24</td>\n      <td>0</td>\n      <td>8.597222</td>\n      <td>NaN</td>\n      <td>72</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1</td>\n      <td>consistency</td>\n      <td>32</td>\n      <td>0</td>\n      <td>5.739583</td>\n      <td>NaN</td>\n      <td>96</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>1</td>\n      <td>interpretability</td>\n      <td>11</td>\n      <td>0</td>\n      <td>1.696970</td>\n      <td>NaN</td>\n      <td>33</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>1</td>\n      <td>empathy</td>\n      <td>28</td>\n      <td>0</td>\n      <td>5.845238</td>\n      <td>NaN</td>\n      <td>84</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>1</td>\n      <td>knowledge</td>\n      <td>13</td>\n      <td>0</td>\n      <td>5.743590</td>\n      <td>NaN</td>\n      <td>39</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>1</td>\n      <td>sociality</td>\n      <td>7</td>\n      <td>0</td>\n      <td>1.142857</td>\n      <td>NaN</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>2</td>\n      <td>sociality</td>\n      <td>14</td>\n      <td>0</td>\n      <td>0.285714</td>\n      <td>NaN</td>\n      <td>42</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>2</td>\n      <td>empathy</td>\n      <td>31</td>\n      <td>0</td>\n      <td>2.451613</td>\n      <td>NaN</td>\n      <td>93</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>2</td>\n      <td>commonsense</td>\n      <td>22</td>\n      <td>0</td>\n      <td>2.015152</td>\n      <td>NaN</td>\n      <td>66</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>2</td>\n      <td>knowledge</td>\n      <td>29</td>\n      <td>0</td>\n      <td>2.183908</td>\n      <td>NaN</td>\n      <td>87</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>2</td>\n      <td>transitions</td>\n      <td>54</td>\n      <td>0</td>\n      <td>4.117284</td>\n      <td>NaN</td>\n      <td>162</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>2</td>\n      <td>interpretability</td>\n      <td>25</td>\n      <td>0</td>\n      <td>0.746667</td>\n      <td>NaN</td>\n      <td>75</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>2</td>\n      <td>consistency</td>\n      <td>21</td>\n      <td>0</td>\n      <td>2.650794</td>\n      <td>NaN</td>\n      <td>63</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>2</td>\n      <td>personal_information</td>\n      <td>32</td>\n      <td>0</td>\n      <td>1.875000</td>\n      <td>NaN</td>\n      <td>96</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "across_evaluations(\n",
    "    [data.student_onboarding, data.mturk_onboarding, data.surge_onboarding],\n",
    "    screening_rates_by_label,\n",
    "    load='results/evaluation_screening.csv'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Agreements"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "           category                      label  Krippendorff's alpha  \\\n0          behavior                 antisocial              0.553231   \n1          behavior  commonsense contradiction              0.441968   \n2          behavior               correct fact              0.617729   \n3          behavior                 empathetic              0.513505   \n4          behavior                  follow up              0.492470   \n5          behavior                     ignore              0.571211   \n6          behavior             incorrect fact              0.651525   \n7          behavior                 irrelevant              0.456120   \n8          behavior            lack of empathy              0.435495   \n9          behavior                  life info              0.631394   \n10         behavior      partner contradiction              0.436345   \n11         behavior            preference info              0.491471   \n12         behavior                  redundant              0.551450   \n13         behavior         self contradiction              0.406664   \n14         behavior               topic switch              0.754804   \n15         behavior            uninterpretable              0.137211   \n16      comparative                 consistent              0.483882   \n17      comparative                  emotional              0.021578   \n18      comparative                   engaging              0.115226   \n19      comparative                grammatical             -0.062569   \n20      comparative                informative              0.201506   \n21      comparative                  proactive              0.225823   \n22      comparative                    quality              0.447016   \n23      comparative                   relevant              0.386959   \n24  likert dialogue                 consistent              0.360098   \n25  likert dialogue                   engaging              0.259392   \n26  likert dialogue                grammatical              0.132165   \n27  likert dialogue                informative              0.409100   \n28  likert dialogue                  proactive              0.243452   \n29  likert dialogue                    quality              0.286367   \n30  likert dialogue                   relevant              0.298034   \n31      likert turn                 consistent              0.201345   \n32      likert turn                   engaging              0.295007   \n33      likert turn                grammatical              0.418861   \n34      likert turn                informative              0.278183   \n35      likert turn                  proactive              0.278859   \n36      likert turn                    quality              0.311672   \n37      likert turn                   relevant              0.238628   \n\n      CI low   CI high       n  Fleiss' kappa  CI low.1  CI high.1     n.1  \n0   0.220313  0.784186  1634.0       0.553094  0.197545   0.816950  1634.0  \n1   0.391135  0.495004  1634.0       0.441797  0.389663   0.493002  1634.0  \n2   0.570461  0.661129  1634.0       0.617612  0.569462   0.667708  1634.0  \n3   0.467688  0.552542  1634.0       0.513356  0.470534   0.556430  1634.0  \n4   0.452094  0.537156  1634.0       0.492315  0.448033   0.533000  1634.0  \n5   0.504229  0.636967  1634.0       0.571080  0.504850   0.638363  1634.0  \n6   0.581439  0.724609  1634.0       0.651418  0.573555   0.717872  1634.0  \n7   0.400736  0.518956  1634.0       0.455954  0.400372   0.511914  1634.0  \n8   0.373795  0.496670  1634.0       0.435323  0.372182   0.499162  1634.0  \n9   0.586041  0.673584  1634.0       0.631281  0.585425   0.670557  1634.0  \n10  0.360129  0.506951  1634.0       0.436172  0.366790   0.508107  1634.0  \n11  0.450679  0.537680  1634.0       0.491316  0.447552   0.537857  1634.0  \n12  0.478814  0.628114  1634.0       0.551313  0.468727   0.620696  1634.0  \n13  0.316331  0.494279  1634.0       0.406482  0.322082   0.494032  1634.0  \n14  0.710729  0.793861  1634.0       0.754729  0.716893   0.789953  1634.0  \n15  0.026513  0.293098  1634.0       0.136947  0.029822   0.326959  1634.0  \n16  0.316522  0.644628   108.0       0.481481  0.311924   0.637416   108.0  \n17 -0.172207  0.227488   108.0       0.074435 -0.044265   0.229209   108.0  \n18 -0.088418  0.290799   108.0       0.111111 -0.077399   0.296055   108.0  \n19 -0.251960  0.137900   108.0       0.023729 -0.083682   0.168957   108.0  \n20 -0.003579  0.394065   108.0       0.199798  0.009036   0.391054   108.0  \n21  0.040179  0.412954   108.0       0.222222  0.053527   0.425877   108.0  \n22  0.281060  0.612272   108.0       0.444444  0.276459   0.610205   108.0  \n23  0.199172  0.560518   108.0       0.392254  0.216184   0.548133   108.0  \n24  0.191761  0.503181   108.0       0.074031 -0.023811   0.197171   108.0  \n25  0.061409  0.423622   108.0       0.123471  0.006748   0.255128   108.0  \n26 -0.041698  0.305932   108.0      -0.057732 -0.175112   0.067444   108.0  \n27  0.267098  0.560509   108.0       0.031449 -0.073793   0.172193   108.0  \n28  0.053438  0.419190   108.0      -0.025557 -0.116170   0.107237   108.0  \n29  0.131912  0.465159   108.0       0.078330 -0.026623   0.216374   108.0  \n30  0.131874  0.445636   108.0      -0.003018 -0.107185   0.119264   108.0  \n31  0.152286  0.249549  1634.0       0.082583  0.052346   0.116640  1634.0  \n32  0.248638  0.343037  1634.0       0.123406  0.094358   0.154432  1634.0  \n33  0.371443  0.466154  1634.0       0.296119  0.262166   0.333254  1634.0  \n34  0.236990  0.323634  1634.0       0.091958  0.063494   0.122060  1634.0  \n35  0.232533  0.325517  1634.0       0.098088  0.067037   0.125791  1634.0  \n36  0.265448  0.354244  1634.0       0.091631  0.064818   0.121650  1634.0  \n37  0.187980  0.289755  1634.0       0.100462  0.068590   0.134349  1634.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>category</th>\n      <th>label</th>\n      <th>Krippendorff's alpha</th>\n      <th>CI low</th>\n      <th>CI high</th>\n      <th>n</th>\n      <th>Fleiss' kappa</th>\n      <th>CI low.1</th>\n      <th>CI high.1</th>\n      <th>n.1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>behavior</td>\n      <td>antisocial</td>\n      <td>0.553231</td>\n      <td>0.220313</td>\n      <td>0.784186</td>\n      <td>1634.0</td>\n      <td>0.553094</td>\n      <td>0.197545</td>\n      <td>0.816950</td>\n      <td>1634.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>behavior</td>\n      <td>commonsense contradiction</td>\n      <td>0.441968</td>\n      <td>0.391135</td>\n      <td>0.495004</td>\n      <td>1634.0</td>\n      <td>0.441797</td>\n      <td>0.389663</td>\n      <td>0.493002</td>\n      <td>1634.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>behavior</td>\n      <td>correct fact</td>\n      <td>0.617729</td>\n      <td>0.570461</td>\n      <td>0.661129</td>\n      <td>1634.0</td>\n      <td>0.617612</td>\n      <td>0.569462</td>\n      <td>0.667708</td>\n      <td>1634.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>behavior</td>\n      <td>empathetic</td>\n      <td>0.513505</td>\n      <td>0.467688</td>\n      <td>0.552542</td>\n      <td>1634.0</td>\n      <td>0.513356</td>\n      <td>0.470534</td>\n      <td>0.556430</td>\n      <td>1634.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>behavior</td>\n      <td>follow up</td>\n      <td>0.492470</td>\n      <td>0.452094</td>\n      <td>0.537156</td>\n      <td>1634.0</td>\n      <td>0.492315</td>\n      <td>0.448033</td>\n      <td>0.533000</td>\n      <td>1634.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>behavior</td>\n      <td>ignore</td>\n      <td>0.571211</td>\n      <td>0.504229</td>\n      <td>0.636967</td>\n      <td>1634.0</td>\n      <td>0.571080</td>\n      <td>0.504850</td>\n      <td>0.638363</td>\n      <td>1634.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>behavior</td>\n      <td>incorrect fact</td>\n      <td>0.651525</td>\n      <td>0.581439</td>\n      <td>0.724609</td>\n      <td>1634.0</td>\n      <td>0.651418</td>\n      <td>0.573555</td>\n      <td>0.717872</td>\n      <td>1634.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>behavior</td>\n      <td>irrelevant</td>\n      <td>0.456120</td>\n      <td>0.400736</td>\n      <td>0.518956</td>\n      <td>1634.0</td>\n      <td>0.455954</td>\n      <td>0.400372</td>\n      <td>0.511914</td>\n      <td>1634.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>behavior</td>\n      <td>lack of empathy</td>\n      <td>0.435495</td>\n      <td>0.373795</td>\n      <td>0.496670</td>\n      <td>1634.0</td>\n      <td>0.435323</td>\n      <td>0.372182</td>\n      <td>0.499162</td>\n      <td>1634.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>behavior</td>\n      <td>life info</td>\n      <td>0.631394</td>\n      <td>0.586041</td>\n      <td>0.673584</td>\n      <td>1634.0</td>\n      <td>0.631281</td>\n      <td>0.585425</td>\n      <td>0.670557</td>\n      <td>1634.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>behavior</td>\n      <td>partner contradiction</td>\n      <td>0.436345</td>\n      <td>0.360129</td>\n      <td>0.506951</td>\n      <td>1634.0</td>\n      <td>0.436172</td>\n      <td>0.366790</td>\n      <td>0.508107</td>\n      <td>1634.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>behavior</td>\n      <td>preference info</td>\n      <td>0.491471</td>\n      <td>0.450679</td>\n      <td>0.537680</td>\n      <td>1634.0</td>\n      <td>0.491316</td>\n      <td>0.447552</td>\n      <td>0.537857</td>\n      <td>1634.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>behavior</td>\n      <td>redundant</td>\n      <td>0.551450</td>\n      <td>0.478814</td>\n      <td>0.628114</td>\n      <td>1634.0</td>\n      <td>0.551313</td>\n      <td>0.468727</td>\n      <td>0.620696</td>\n      <td>1634.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>behavior</td>\n      <td>self contradiction</td>\n      <td>0.406664</td>\n      <td>0.316331</td>\n      <td>0.494279</td>\n      <td>1634.0</td>\n      <td>0.406482</td>\n      <td>0.322082</td>\n      <td>0.494032</td>\n      <td>1634.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>behavior</td>\n      <td>topic switch</td>\n      <td>0.754804</td>\n      <td>0.710729</td>\n      <td>0.793861</td>\n      <td>1634.0</td>\n      <td>0.754729</td>\n      <td>0.716893</td>\n      <td>0.789953</td>\n      <td>1634.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>behavior</td>\n      <td>uninterpretable</td>\n      <td>0.137211</td>\n      <td>0.026513</td>\n      <td>0.293098</td>\n      <td>1634.0</td>\n      <td>0.136947</td>\n      <td>0.029822</td>\n      <td>0.326959</td>\n      <td>1634.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>comparative</td>\n      <td>consistent</td>\n      <td>0.483882</td>\n      <td>0.316522</td>\n      <td>0.644628</td>\n      <td>108.0</td>\n      <td>0.481481</td>\n      <td>0.311924</td>\n      <td>0.637416</td>\n      <td>108.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>comparative</td>\n      <td>emotional</td>\n      <td>0.021578</td>\n      <td>-0.172207</td>\n      <td>0.227488</td>\n      <td>108.0</td>\n      <td>0.074435</td>\n      <td>-0.044265</td>\n      <td>0.229209</td>\n      <td>108.0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>comparative</td>\n      <td>engaging</td>\n      <td>0.115226</td>\n      <td>-0.088418</td>\n      <td>0.290799</td>\n      <td>108.0</td>\n      <td>0.111111</td>\n      <td>-0.077399</td>\n      <td>0.296055</td>\n      <td>108.0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>comparative</td>\n      <td>grammatical</td>\n      <td>-0.062569</td>\n      <td>-0.251960</td>\n      <td>0.137900</td>\n      <td>108.0</td>\n      <td>0.023729</td>\n      <td>-0.083682</td>\n      <td>0.168957</td>\n      <td>108.0</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>comparative</td>\n      <td>informative</td>\n      <td>0.201506</td>\n      <td>-0.003579</td>\n      <td>0.394065</td>\n      <td>108.0</td>\n      <td>0.199798</td>\n      <td>0.009036</td>\n      <td>0.391054</td>\n      <td>108.0</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>comparative</td>\n      <td>proactive</td>\n      <td>0.225823</td>\n      <td>0.040179</td>\n      <td>0.412954</td>\n      <td>108.0</td>\n      <td>0.222222</td>\n      <td>0.053527</td>\n      <td>0.425877</td>\n      <td>108.0</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>comparative</td>\n      <td>quality</td>\n      <td>0.447016</td>\n      <td>0.281060</td>\n      <td>0.612272</td>\n      <td>108.0</td>\n      <td>0.444444</td>\n      <td>0.276459</td>\n      <td>0.610205</td>\n      <td>108.0</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>comparative</td>\n      <td>relevant</td>\n      <td>0.386959</td>\n      <td>0.199172</td>\n      <td>0.560518</td>\n      <td>108.0</td>\n      <td>0.392254</td>\n      <td>0.216184</td>\n      <td>0.548133</td>\n      <td>108.0</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>likert dialogue</td>\n      <td>consistent</td>\n      <td>0.360098</td>\n      <td>0.191761</td>\n      <td>0.503181</td>\n      <td>108.0</td>\n      <td>0.074031</td>\n      <td>-0.023811</td>\n      <td>0.197171</td>\n      <td>108.0</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>likert dialogue</td>\n      <td>engaging</td>\n      <td>0.259392</td>\n      <td>0.061409</td>\n      <td>0.423622</td>\n      <td>108.0</td>\n      <td>0.123471</td>\n      <td>0.006748</td>\n      <td>0.255128</td>\n      <td>108.0</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>likert dialogue</td>\n      <td>grammatical</td>\n      <td>0.132165</td>\n      <td>-0.041698</td>\n      <td>0.305932</td>\n      <td>108.0</td>\n      <td>-0.057732</td>\n      <td>-0.175112</td>\n      <td>0.067444</td>\n      <td>108.0</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>likert dialogue</td>\n      <td>informative</td>\n      <td>0.409100</td>\n      <td>0.267098</td>\n      <td>0.560509</td>\n      <td>108.0</td>\n      <td>0.031449</td>\n      <td>-0.073793</td>\n      <td>0.172193</td>\n      <td>108.0</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>likert dialogue</td>\n      <td>proactive</td>\n      <td>0.243452</td>\n      <td>0.053438</td>\n      <td>0.419190</td>\n      <td>108.0</td>\n      <td>-0.025557</td>\n      <td>-0.116170</td>\n      <td>0.107237</td>\n      <td>108.0</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>likert dialogue</td>\n      <td>quality</td>\n      <td>0.286367</td>\n      <td>0.131912</td>\n      <td>0.465159</td>\n      <td>108.0</td>\n      <td>0.078330</td>\n      <td>-0.026623</td>\n      <td>0.216374</td>\n      <td>108.0</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>likert dialogue</td>\n      <td>relevant</td>\n      <td>0.298034</td>\n      <td>0.131874</td>\n      <td>0.445636</td>\n      <td>108.0</td>\n      <td>-0.003018</td>\n      <td>-0.107185</td>\n      <td>0.119264</td>\n      <td>108.0</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>likert turn</td>\n      <td>consistent</td>\n      <td>0.201345</td>\n      <td>0.152286</td>\n      <td>0.249549</td>\n      <td>1634.0</td>\n      <td>0.082583</td>\n      <td>0.052346</td>\n      <td>0.116640</td>\n      <td>1634.0</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>likert turn</td>\n      <td>engaging</td>\n      <td>0.295007</td>\n      <td>0.248638</td>\n      <td>0.343037</td>\n      <td>1634.0</td>\n      <td>0.123406</td>\n      <td>0.094358</td>\n      <td>0.154432</td>\n      <td>1634.0</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>likert turn</td>\n      <td>grammatical</td>\n      <td>0.418861</td>\n      <td>0.371443</td>\n      <td>0.466154</td>\n      <td>1634.0</td>\n      <td>0.296119</td>\n      <td>0.262166</td>\n      <td>0.333254</td>\n      <td>1634.0</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>likert turn</td>\n      <td>informative</td>\n      <td>0.278183</td>\n      <td>0.236990</td>\n      <td>0.323634</td>\n      <td>1634.0</td>\n      <td>0.091958</td>\n      <td>0.063494</td>\n      <td>0.122060</td>\n      <td>1634.0</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>likert turn</td>\n      <td>proactive</td>\n      <td>0.278859</td>\n      <td>0.232533</td>\n      <td>0.325517</td>\n      <td>1634.0</td>\n      <td>0.098088</td>\n      <td>0.067037</td>\n      <td>0.125791</td>\n      <td>1634.0</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>likert turn</td>\n      <td>quality</td>\n      <td>0.311672</td>\n      <td>0.265448</td>\n      <td>0.354244</td>\n      <td>1634.0</td>\n      <td>0.091631</td>\n      <td>0.064818</td>\n      <td>0.121650</td>\n      <td>1634.0</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>likert turn</td>\n      <td>relevant</td>\n      <td>0.238628</td>\n      <td>0.187980</td>\n      <td>0.289755</td>\n      <td>1634.0</td>\n      <td>0.100462</td>\n      <td>0.068590</td>\n      <td>0.134349</td>\n      <td>1634.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agreements = agreement_dataframe(\n",
    "    surge_annotations, load='results/surge_agreements.csv'\n",
    ")\n",
    "agreements"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "    round     category            label  Krippendorff's alpha    CI low  \\\n0       0     behavior       antisocial                   NaN       NaN   \n1       0     behavior  uninterpretable              0.322148       NaN   \n2       0  comparative       consistent              0.680556  0.148148   \n3       0  comparative        emotional              0.141676 -0.362506   \n4       0  comparative         engaging              0.067222 -0.480825   \n..    ...          ...              ...                   ...       ...   \n87      2  likert turn      grammatical              0.418861  0.375635   \n88      2  likert turn      informative              0.278183  0.231128   \n89      2  likert turn        proactive              0.278859  0.232748   \n90      2  likert turn          quality              0.311672  0.266655   \n91      2  likert turn         relevant              0.238628  0.188673   \n\n     CI high       n  Fleiss' kappa  CI low.1  CI high.1     n.1  \n0        NaN   233.0            NaN       NaN        NaN   233.0  \n1        NaN   152.0       0.319911       NaN        NaN   152.0  \n2   1.000000    12.0       0.666667       NaN        NaN    12.0  \n3   0.680556    12.0       0.127273 -0.317073   0.690323    12.0  \n4   0.805241    12.0       0.238095 -0.142857   0.707317    12.0  \n..       ...     ...            ...       ...        ...     ...  \n87  0.465538  1634.0       0.296119  0.263644   0.333836  1634.0  \n88  0.324850  1634.0       0.091958  0.064174   0.119510  1634.0  \n89  0.323215  1634.0       0.098088  0.069933   0.125158  1634.0  \n90  0.354655  1634.0       0.091631  0.062086   0.120679  1634.0  \n91  0.283760  1634.0       0.100462  0.070409   0.134462  1634.0  \n\n[92 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>round</th>\n      <th>category</th>\n      <th>label</th>\n      <th>Krippendorff's alpha</th>\n      <th>CI low</th>\n      <th>CI high</th>\n      <th>n</th>\n      <th>Fleiss' kappa</th>\n      <th>CI low.1</th>\n      <th>CI high.1</th>\n      <th>n.1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>behavior</td>\n      <td>antisocial</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>233.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>233.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>behavior</td>\n      <td>uninterpretable</td>\n      <td>0.322148</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>152.0</td>\n      <td>0.319911</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>152.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>comparative</td>\n      <td>consistent</td>\n      <td>0.680556</td>\n      <td>0.148148</td>\n      <td>1.000000</td>\n      <td>12.0</td>\n      <td>0.666667</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>comparative</td>\n      <td>emotional</td>\n      <td>0.141676</td>\n      <td>-0.362506</td>\n      <td>0.680556</td>\n      <td>12.0</td>\n      <td>0.127273</td>\n      <td>-0.317073</td>\n      <td>0.690323</td>\n      <td>12.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>comparative</td>\n      <td>engaging</td>\n      <td>0.067222</td>\n      <td>-0.480825</td>\n      <td>0.805241</td>\n      <td>12.0</td>\n      <td>0.238095</td>\n      <td>-0.142857</td>\n      <td>0.707317</td>\n      <td>12.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>87</th>\n      <td>2</td>\n      <td>likert turn</td>\n      <td>grammatical</td>\n      <td>0.418861</td>\n      <td>0.375635</td>\n      <td>0.465538</td>\n      <td>1634.0</td>\n      <td>0.296119</td>\n      <td>0.263644</td>\n      <td>0.333836</td>\n      <td>1634.0</td>\n    </tr>\n    <tr>\n      <th>88</th>\n      <td>2</td>\n      <td>likert turn</td>\n      <td>informative</td>\n      <td>0.278183</td>\n      <td>0.231128</td>\n      <td>0.324850</td>\n      <td>1634.0</td>\n      <td>0.091958</td>\n      <td>0.064174</td>\n      <td>0.119510</td>\n      <td>1634.0</td>\n    </tr>\n    <tr>\n      <th>89</th>\n      <td>2</td>\n      <td>likert turn</td>\n      <td>proactive</td>\n      <td>0.278859</td>\n      <td>0.232748</td>\n      <td>0.323215</td>\n      <td>1634.0</td>\n      <td>0.098088</td>\n      <td>0.069933</td>\n      <td>0.125158</td>\n      <td>1634.0</td>\n    </tr>\n    <tr>\n      <th>90</th>\n      <td>2</td>\n      <td>likert turn</td>\n      <td>quality</td>\n      <td>0.311672</td>\n      <td>0.266655</td>\n      <td>0.354655</td>\n      <td>1634.0</td>\n      <td>0.091631</td>\n      <td>0.062086</td>\n      <td>0.120679</td>\n      <td>1634.0</td>\n    </tr>\n    <tr>\n      <th>91</th>\n      <td>2</td>\n      <td>likert turn</td>\n      <td>relevant</td>\n      <td>0.238628</td>\n      <td>0.188673</td>\n      <td>0.283760</td>\n      <td>1634.0</td>\n      <td>0.100462</td>\n      <td>0.070409</td>\n      <td>0.134462</td>\n      <td>1634.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>92 rows Ã— 11 columns</p>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "across_evaluations(\n",
    "    [\n",
    "        e.annotation_dataframe() for e in\n",
    "        (data.student_evaluation, data.mturk_evaluation, data.surge_evaluation)\n",
    "    ],\n",
    "    agreement_dataframe,\n",
    "    load='results/evaluation_agreements.csv'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 7 Comprehensive Analysis"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Likert Dialogue"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def evaluate_likert_ratings(annotations, category, load=None, reload=None):\n",
    "    if load:\n",
    "        return pd.read_csv(load)\n",
    "    single_annotated = get_singly_annotated(annotations)\n",
    "    likert_annotations = single_annotated.xs(category, level=sym.category)\n",
    "    label_groups = likert_annotations.groupby(level=[sym.bot, sym.label])\n",
    "    means = label_groups.apply(mean_and_ci)\n",
    "    if reload:\n",
    "        means.to_csv(reload)\n",
    "    return means"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "                 bot        label  mean    CI low   CI high      n\n0   bart_fid_rag_bcb   consistent  3.00  2.720810  3.279190  100.0\n1   bart_fid_rag_bcb     engaging  3.29  3.056933  3.523067  100.0\n2   bart_fid_rag_bcb  grammatical  3.75  3.570798  3.929202  100.0\n3   bart_fid_rag_bcb  informative  3.79  3.596048  3.983952  100.0\n4   bart_fid_rag_bcb    proactive  2.75  2.527263  2.972737  100.0\n5   bart_fid_rag_bcb      quality  2.93  2.734089  3.125911  100.0\n6   bart_fid_rag_bcb     relevant  3.55  3.316796  3.783204  100.0\n7        blender2_3B   consistent  3.46  3.196311  3.723689  100.0\n8        blender2_3B     engaging  3.94  3.757619  4.122381  100.0\n9        blender2_3B  grammatical  4.24  4.077695  4.402305  100.0\n10       blender2_3B  informative  3.58  3.378239  3.781761  100.0\n11       blender2_3B    proactive  3.91  3.724860  4.095140  100.0\n12       blender2_3B      quality  3.61  3.425290  3.794710  100.0\n13       blender2_3B     relevant  4.00  3.817227  4.182773  100.0\n14             emora   consistent  3.95  3.730863  4.169137  100.0\n15             emora     engaging  3.79  3.617769  3.962231  100.0\n16             emora  grammatical  4.03  3.874362  4.185638  100.0\n17             emora  informative  3.51  3.346779  3.673221  100.0\n18             emora    proactive  4.00  3.802583  4.197417  100.0\n19             emora      quality  3.43  3.280089  3.579911  100.0\n20             emora     relevant  3.52  3.319624  3.720376  100.0\n21    rerank_blender   consistent  3.66  3.420329  3.899671  100.0\n22    rerank_blender     engaging  3.92  3.719227  4.120773  100.0\n23    rerank_blender  grammatical  3.57  3.356601  3.783399  100.0\n24    rerank_blender  informative  3.98  3.797271  4.162729  100.0\n25    rerank_blender    proactive  3.80  3.592755  4.007245  100.0\n26    rerank_blender      quality  3.28  3.088556  3.471444  100.0\n27    rerank_blender     relevant  3.53  3.312539  3.747461  100.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bot</th>\n      <th>label</th>\n      <th>mean</th>\n      <th>CI low</th>\n      <th>CI high</th>\n      <th>n</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>bart_fid_rag_bcb</td>\n      <td>consistent</td>\n      <td>3.00</td>\n      <td>2.720810</td>\n      <td>3.279190</td>\n      <td>100.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>bart_fid_rag_bcb</td>\n      <td>engaging</td>\n      <td>3.29</td>\n      <td>3.056933</td>\n      <td>3.523067</td>\n      <td>100.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>bart_fid_rag_bcb</td>\n      <td>grammatical</td>\n      <td>3.75</td>\n      <td>3.570798</td>\n      <td>3.929202</td>\n      <td>100.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>bart_fid_rag_bcb</td>\n      <td>informative</td>\n      <td>3.79</td>\n      <td>3.596048</td>\n      <td>3.983952</td>\n      <td>100.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>bart_fid_rag_bcb</td>\n      <td>proactive</td>\n      <td>2.75</td>\n      <td>2.527263</td>\n      <td>2.972737</td>\n      <td>100.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>bart_fid_rag_bcb</td>\n      <td>quality</td>\n      <td>2.93</td>\n      <td>2.734089</td>\n      <td>3.125911</td>\n      <td>100.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>bart_fid_rag_bcb</td>\n      <td>relevant</td>\n      <td>3.55</td>\n      <td>3.316796</td>\n      <td>3.783204</td>\n      <td>100.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>blender2_3B</td>\n      <td>consistent</td>\n      <td>3.46</td>\n      <td>3.196311</td>\n      <td>3.723689</td>\n      <td>100.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>blender2_3B</td>\n      <td>engaging</td>\n      <td>3.94</td>\n      <td>3.757619</td>\n      <td>4.122381</td>\n      <td>100.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>blender2_3B</td>\n      <td>grammatical</td>\n      <td>4.24</td>\n      <td>4.077695</td>\n      <td>4.402305</td>\n      <td>100.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>blender2_3B</td>\n      <td>informative</td>\n      <td>3.58</td>\n      <td>3.378239</td>\n      <td>3.781761</td>\n      <td>100.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>blender2_3B</td>\n      <td>proactive</td>\n      <td>3.91</td>\n      <td>3.724860</td>\n      <td>4.095140</td>\n      <td>100.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>blender2_3B</td>\n      <td>quality</td>\n      <td>3.61</td>\n      <td>3.425290</td>\n      <td>3.794710</td>\n      <td>100.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>blender2_3B</td>\n      <td>relevant</td>\n      <td>4.00</td>\n      <td>3.817227</td>\n      <td>4.182773</td>\n      <td>100.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>emora</td>\n      <td>consistent</td>\n      <td>3.95</td>\n      <td>3.730863</td>\n      <td>4.169137</td>\n      <td>100.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>emora</td>\n      <td>engaging</td>\n      <td>3.79</td>\n      <td>3.617769</td>\n      <td>3.962231</td>\n      <td>100.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>emora</td>\n      <td>grammatical</td>\n      <td>4.03</td>\n      <td>3.874362</td>\n      <td>4.185638</td>\n      <td>100.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>emora</td>\n      <td>informative</td>\n      <td>3.51</td>\n      <td>3.346779</td>\n      <td>3.673221</td>\n      <td>100.0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>emora</td>\n      <td>proactive</td>\n      <td>4.00</td>\n      <td>3.802583</td>\n      <td>4.197417</td>\n      <td>100.0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>emora</td>\n      <td>quality</td>\n      <td>3.43</td>\n      <td>3.280089</td>\n      <td>3.579911</td>\n      <td>100.0</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>emora</td>\n      <td>relevant</td>\n      <td>3.52</td>\n      <td>3.319624</td>\n      <td>3.720376</td>\n      <td>100.0</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>rerank_blender</td>\n      <td>consistent</td>\n      <td>3.66</td>\n      <td>3.420329</td>\n      <td>3.899671</td>\n      <td>100.0</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>rerank_blender</td>\n      <td>engaging</td>\n      <td>3.92</td>\n      <td>3.719227</td>\n      <td>4.120773</td>\n      <td>100.0</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>rerank_blender</td>\n      <td>grammatical</td>\n      <td>3.57</td>\n      <td>3.356601</td>\n      <td>3.783399</td>\n      <td>100.0</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>rerank_blender</td>\n      <td>informative</td>\n      <td>3.98</td>\n      <td>3.797271</td>\n      <td>4.162729</td>\n      <td>100.0</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>rerank_blender</td>\n      <td>proactive</td>\n      <td>3.80</td>\n      <td>3.592755</td>\n      <td>4.007245</td>\n      <td>100.0</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>rerank_blender</td>\n      <td>quality</td>\n      <td>3.28</td>\n      <td>3.088556</td>\n      <td>3.471444</td>\n      <td>100.0</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>rerank_blender</td>\n      <td>relevant</td>\n      <td>3.53</td>\n      <td>3.312539</td>\n      <td>3.747461</td>\n      <td>100.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surge_likert_dialogue_ratings = evaluate_likert_ratings(\n",
    "    surge_annotations, category.likert_dialogue,\n",
    "    load='results/surge_likert_dialogue_ratings.csv'\n",
    ")\n",
    "surge_likert_dialogue_ratings"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Likert Turn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "                 bot        label      mean    CI low   CI high       n\n0   bart_fid_rag_bcb   consistent  3.944444  3.876275  4.012614  1512.0\n1   bart_fid_rag_bcb     engaging  3.619048  3.551061  3.687035  1512.0\n2   bart_fid_rag_bcb  grammatical  4.310847  4.263485  4.358208  1512.0\n3   bart_fid_rag_bcb  informative  3.807540  3.755130  3.859950  1512.0\n4   bart_fid_rag_bcb    proactive  2.938492  2.878133  2.998851  1512.0\n5   bart_fid_rag_bcb      quality  3.339947  3.273733  3.406161  1512.0\n6   bart_fid_rag_bcb     relevant  3.896164  3.827143  3.965185  1512.0\n7        blender2_3B   consistent  4.100394  4.037904  4.162883  1524.0\n8        blender2_3B     engaging  3.948819  3.891935  4.005703  1524.0\n9        blender2_3B  grammatical  4.650919  4.614724  4.687113  1524.0\n10       blender2_3B  informative  3.454724  3.402364  3.507085  1524.0\n11       blender2_3B    proactive  3.572178  3.515396  3.628961  1524.0\n12       blender2_3B      quality  3.778215  3.718224  3.838206  1524.0\n13       blender2_3B     relevant  4.193570  4.134851  4.252288  1524.0\n14             emora   consistent  4.146518  4.087858  4.205178  1522.0\n15             emora     engaging  3.895532  3.840076  3.950989  1522.0\n16             emora  grammatical  4.539422  4.505407  4.573437  1522.0\n17             emora  informative  3.191196  3.130325  3.252067  1522.0\n18             emora    proactive  3.750329  3.691037  3.809620  1522.0\n19             emora      quality  3.519054  3.456558  3.581550  1522.0\n20             emora     relevant  3.795664  3.730187  3.861140  1522.0\n21    rerank_blender   consistent  4.058000  3.996532  4.119468  1500.0\n22    rerank_blender     engaging  3.830667  3.768328  3.893006  1500.0\n23    rerank_blender  grammatical  4.002667  3.949466  4.055868  1500.0\n24    rerank_blender  informative  3.734000  3.679263  3.788737  1500.0\n25    rerank_blender    proactive  3.652667  3.591114  3.714219  1500.0\n26    rerank_blender      quality  3.312667  3.252944  3.372389  1500.0\n27    rerank_blender     relevant  3.720000  3.654379  3.785621  1500.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bot</th>\n      <th>label</th>\n      <th>mean</th>\n      <th>CI low</th>\n      <th>CI high</th>\n      <th>n</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>bart_fid_rag_bcb</td>\n      <td>consistent</td>\n      <td>3.944444</td>\n      <td>3.876275</td>\n      <td>4.012614</td>\n      <td>1512.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>bart_fid_rag_bcb</td>\n      <td>engaging</td>\n      <td>3.619048</td>\n      <td>3.551061</td>\n      <td>3.687035</td>\n      <td>1512.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>bart_fid_rag_bcb</td>\n      <td>grammatical</td>\n      <td>4.310847</td>\n      <td>4.263485</td>\n      <td>4.358208</td>\n      <td>1512.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>bart_fid_rag_bcb</td>\n      <td>informative</td>\n      <td>3.807540</td>\n      <td>3.755130</td>\n      <td>3.859950</td>\n      <td>1512.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>bart_fid_rag_bcb</td>\n      <td>proactive</td>\n      <td>2.938492</td>\n      <td>2.878133</td>\n      <td>2.998851</td>\n      <td>1512.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>bart_fid_rag_bcb</td>\n      <td>quality</td>\n      <td>3.339947</td>\n      <td>3.273733</td>\n      <td>3.406161</td>\n      <td>1512.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>bart_fid_rag_bcb</td>\n      <td>relevant</td>\n      <td>3.896164</td>\n      <td>3.827143</td>\n      <td>3.965185</td>\n      <td>1512.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>blender2_3B</td>\n      <td>consistent</td>\n      <td>4.100394</td>\n      <td>4.037904</td>\n      <td>4.162883</td>\n      <td>1524.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>blender2_3B</td>\n      <td>engaging</td>\n      <td>3.948819</td>\n      <td>3.891935</td>\n      <td>4.005703</td>\n      <td>1524.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>blender2_3B</td>\n      <td>grammatical</td>\n      <td>4.650919</td>\n      <td>4.614724</td>\n      <td>4.687113</td>\n      <td>1524.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>blender2_3B</td>\n      <td>informative</td>\n      <td>3.454724</td>\n      <td>3.402364</td>\n      <td>3.507085</td>\n      <td>1524.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>blender2_3B</td>\n      <td>proactive</td>\n      <td>3.572178</td>\n      <td>3.515396</td>\n      <td>3.628961</td>\n      <td>1524.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>blender2_3B</td>\n      <td>quality</td>\n      <td>3.778215</td>\n      <td>3.718224</td>\n      <td>3.838206</td>\n      <td>1524.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>blender2_3B</td>\n      <td>relevant</td>\n      <td>4.193570</td>\n      <td>4.134851</td>\n      <td>4.252288</td>\n      <td>1524.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>emora</td>\n      <td>consistent</td>\n      <td>4.146518</td>\n      <td>4.087858</td>\n      <td>4.205178</td>\n      <td>1522.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>emora</td>\n      <td>engaging</td>\n      <td>3.895532</td>\n      <td>3.840076</td>\n      <td>3.950989</td>\n      <td>1522.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>emora</td>\n      <td>grammatical</td>\n      <td>4.539422</td>\n      <td>4.505407</td>\n      <td>4.573437</td>\n      <td>1522.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>emora</td>\n      <td>informative</td>\n      <td>3.191196</td>\n      <td>3.130325</td>\n      <td>3.252067</td>\n      <td>1522.0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>emora</td>\n      <td>proactive</td>\n      <td>3.750329</td>\n      <td>3.691037</td>\n      <td>3.809620</td>\n      <td>1522.0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>emora</td>\n      <td>quality</td>\n      <td>3.519054</td>\n      <td>3.456558</td>\n      <td>3.581550</td>\n      <td>1522.0</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>emora</td>\n      <td>relevant</td>\n      <td>3.795664</td>\n      <td>3.730187</td>\n      <td>3.861140</td>\n      <td>1522.0</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>rerank_blender</td>\n      <td>consistent</td>\n      <td>4.058000</td>\n      <td>3.996532</td>\n      <td>4.119468</td>\n      <td>1500.0</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>rerank_blender</td>\n      <td>engaging</td>\n      <td>3.830667</td>\n      <td>3.768328</td>\n      <td>3.893006</td>\n      <td>1500.0</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>rerank_blender</td>\n      <td>grammatical</td>\n      <td>4.002667</td>\n      <td>3.949466</td>\n      <td>4.055868</td>\n      <td>1500.0</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>rerank_blender</td>\n      <td>informative</td>\n      <td>3.734000</td>\n      <td>3.679263</td>\n      <td>3.788737</td>\n      <td>1500.0</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>rerank_blender</td>\n      <td>proactive</td>\n      <td>3.652667</td>\n      <td>3.591114</td>\n      <td>3.714219</td>\n      <td>1500.0</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>rerank_blender</td>\n      <td>quality</td>\n      <td>3.312667</td>\n      <td>3.252944</td>\n      <td>3.372389</td>\n      <td>1500.0</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>rerank_blender</td>\n      <td>relevant</td>\n      <td>3.720000</td>\n      <td>3.654379</td>\n      <td>3.785621</td>\n      <td>1500.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surge_likert_turn_ratings = evaluate_likert_ratings(\n",
    "    surge_annotations, category.likert_turn,\n",
    "    load='results/surge_likert_turn_ratings.csv'\n",
    ")\n",
    "surge_likert_turn_ratings"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Comparative"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "                  bot bot comp        label      lose        CI low   CI high  \\\n0    bart_fid_rag_bcb   others   consistent  0.000000  3.469447e-18  0.036641   \n1    bart_fid_rag_bcb   others    emotional  0.059406  2.750813e-02  0.123591   \n2    bart_fid_rag_bcb   others     engaging  0.009901  1.749911e-03  0.053967   \n3    bart_fid_rag_bcb   others  grammatical  0.118812  6.928719e-02  0.196271   \n4    bart_fid_rag_bcb   others  informative  0.000000  3.469447e-18  0.036641   \n..                ...      ...          ...       ...           ...       ...   \n123    rerank_blender    emora  grammatical  0.121212  4.816161e-02  0.273255   \n124    rerank_blender    emora  informative  0.000000  0.000000e+00  0.104270   \n125    rerank_blender    emora    proactive  0.000000  0.000000e+00  0.104270   \n126    rerank_blender    emora      quality  0.000000  0.000000e+00  0.104270   \n127    rerank_blender    emora     relevant  0.090909  3.140394e-02  0.235726   \n\n         n       tie  CI low.1  CI high.1    n.1       win  CI low.2  \\\n0    101.0  0.613861  0.516402   0.702977  101.0  0.386139  0.297023   \n1    101.0  0.594059  0.496550   0.684676  101.0  0.346535  0.260895   \n2    101.0  0.643564  0.546475   0.730133  101.0  0.346535  0.260895   \n3    101.0  0.455446  0.361736   0.552420  101.0  0.425743  0.333777   \n4    101.0  0.455446  0.361736   0.552420  101.0  0.544554  0.447580   \n..     ...       ...       ...        ...    ...       ...       ...   \n123   33.0  0.363636  0.221872   0.533838   33.0  0.515152  0.352184   \n124   33.0  0.303030  0.173755   0.473381   33.0  0.696970  0.526619   \n125   33.0  0.424242  0.272356   0.591927   33.0  0.575758  0.408073   \n126   33.0  0.484848  0.325040   0.647816   33.0  0.515152  0.352184   \n127   33.0  0.454545  0.298429   0.620141   33.0  0.454545  0.298429   \n\n     CI high.2    n.2  \n0     0.483598  101.0  \n1     0.443420  101.0  \n2     0.443420  101.0  \n3     0.523150  101.0  \n4     0.638264  101.0  \n..         ...    ...  \n123   0.674960   33.0  \n124   0.826245   33.0  \n125   0.727644   33.0  \n126   0.674960   33.0  \n127   0.620141   33.0  \n\n[128 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bot</th>\n      <th>bot comp</th>\n      <th>label</th>\n      <th>lose</th>\n      <th>CI low</th>\n      <th>CI high</th>\n      <th>n</th>\n      <th>tie</th>\n      <th>CI low.1</th>\n      <th>CI high.1</th>\n      <th>n.1</th>\n      <th>win</th>\n      <th>CI low.2</th>\n      <th>CI high.2</th>\n      <th>n.2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>bart_fid_rag_bcb</td>\n      <td>others</td>\n      <td>consistent</td>\n      <td>0.000000</td>\n      <td>3.469447e-18</td>\n      <td>0.036641</td>\n      <td>101.0</td>\n      <td>0.613861</td>\n      <td>0.516402</td>\n      <td>0.702977</td>\n      <td>101.0</td>\n      <td>0.386139</td>\n      <td>0.297023</td>\n      <td>0.483598</td>\n      <td>101.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>bart_fid_rag_bcb</td>\n      <td>others</td>\n      <td>emotional</td>\n      <td>0.059406</td>\n      <td>2.750813e-02</td>\n      <td>0.123591</td>\n      <td>101.0</td>\n      <td>0.594059</td>\n      <td>0.496550</td>\n      <td>0.684676</td>\n      <td>101.0</td>\n      <td>0.346535</td>\n      <td>0.260895</td>\n      <td>0.443420</td>\n      <td>101.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>bart_fid_rag_bcb</td>\n      <td>others</td>\n      <td>engaging</td>\n      <td>0.009901</td>\n      <td>1.749911e-03</td>\n      <td>0.053967</td>\n      <td>101.0</td>\n      <td>0.643564</td>\n      <td>0.546475</td>\n      <td>0.730133</td>\n      <td>101.0</td>\n      <td>0.346535</td>\n      <td>0.260895</td>\n      <td>0.443420</td>\n      <td>101.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>bart_fid_rag_bcb</td>\n      <td>others</td>\n      <td>grammatical</td>\n      <td>0.118812</td>\n      <td>6.928719e-02</td>\n      <td>0.196271</td>\n      <td>101.0</td>\n      <td>0.455446</td>\n      <td>0.361736</td>\n      <td>0.552420</td>\n      <td>101.0</td>\n      <td>0.425743</td>\n      <td>0.333777</td>\n      <td>0.523150</td>\n      <td>101.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>bart_fid_rag_bcb</td>\n      <td>others</td>\n      <td>informative</td>\n      <td>0.000000</td>\n      <td>3.469447e-18</td>\n      <td>0.036641</td>\n      <td>101.0</td>\n      <td>0.455446</td>\n      <td>0.361736</td>\n      <td>0.552420</td>\n      <td>101.0</td>\n      <td>0.544554</td>\n      <td>0.447580</td>\n      <td>0.638264</td>\n      <td>101.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>123</th>\n      <td>rerank_blender</td>\n      <td>emora</td>\n      <td>grammatical</td>\n      <td>0.121212</td>\n      <td>4.816161e-02</td>\n      <td>0.273255</td>\n      <td>33.0</td>\n      <td>0.363636</td>\n      <td>0.221872</td>\n      <td>0.533838</td>\n      <td>33.0</td>\n      <td>0.515152</td>\n      <td>0.352184</td>\n      <td>0.674960</td>\n      <td>33.0</td>\n    </tr>\n    <tr>\n      <th>124</th>\n      <td>rerank_blender</td>\n      <td>emora</td>\n      <td>informative</td>\n      <td>0.000000</td>\n      <td>0.000000e+00</td>\n      <td>0.104270</td>\n      <td>33.0</td>\n      <td>0.303030</td>\n      <td>0.173755</td>\n      <td>0.473381</td>\n      <td>33.0</td>\n      <td>0.696970</td>\n      <td>0.526619</td>\n      <td>0.826245</td>\n      <td>33.0</td>\n    </tr>\n    <tr>\n      <th>125</th>\n      <td>rerank_blender</td>\n      <td>emora</td>\n      <td>proactive</td>\n      <td>0.000000</td>\n      <td>0.000000e+00</td>\n      <td>0.104270</td>\n      <td>33.0</td>\n      <td>0.424242</td>\n      <td>0.272356</td>\n      <td>0.591927</td>\n      <td>33.0</td>\n      <td>0.575758</td>\n      <td>0.408073</td>\n      <td>0.727644</td>\n      <td>33.0</td>\n    </tr>\n    <tr>\n      <th>126</th>\n      <td>rerank_blender</td>\n      <td>emora</td>\n      <td>quality</td>\n      <td>0.000000</td>\n      <td>0.000000e+00</td>\n      <td>0.104270</td>\n      <td>33.0</td>\n      <td>0.484848</td>\n      <td>0.325040</td>\n      <td>0.647816</td>\n      <td>33.0</td>\n      <td>0.515152</td>\n      <td>0.352184</td>\n      <td>0.674960</td>\n      <td>33.0</td>\n    </tr>\n    <tr>\n      <th>127</th>\n      <td>rerank_blender</td>\n      <td>emora</td>\n      <td>relevant</td>\n      <td>0.090909</td>\n      <td>3.140394e-02</td>\n      <td>0.235726</td>\n      <td>33.0</td>\n      <td>0.454545</td>\n      <td>0.298429</td>\n      <td>0.620141</td>\n      <td>33.0</td>\n      <td>0.454545</td>\n      <td>0.298429</td>\n      <td>0.620141</td>\n      <td>33.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>128 rows Ã— 15 columns</p>\n</div>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_df = evaluate_comparisons(\n",
    "    surge_annotations_comparative,\n",
    "    load='results/surge_comparisons.csv'\n",
    ")\n",
    "comparison_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Behaviors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "def evaluate_behavior_rates(annotations, load=None, reload=None):\n",
    "    if load:\n",
    "        return pd.read_csv(load)\n",
    "    single_annotated = get_singly_annotated(annotations)\n",
    "    behavior_annotations = single_annotated.xs(category.behavior, level=sym.category)\n",
    "    label_groups = behavior_annotations.groupby(level=[sym.bot, sym.label])\n",
    "    means = label_groups.apply(prop_and_ci)\n",
    "    if reload:\n",
    "        means.to_csv(reload)\n",
    "    return means"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "                 bot                      label  proportion    CI low  \\\n0   bart_fid_rag_bcb                 antisocial    0.000661  0.000117   \n1   bart_fid_rag_bcb  commonsense contradiction    0.216270  0.196251   \n2   bart_fid_rag_bcb               correct fact    0.357143  0.333381   \n3   bart_fid_rag_bcb                 empathetic    0.335979  0.312613   \n4   bart_fid_rag_bcb                  follow up    0.638889  0.614354   \n..               ...                        ...         ...       ...   \n59    rerank_blender            preference info    0.305333  0.282549   \n60    rerank_blender                  redundant    0.037333  0.028861   \n61    rerank_blender         self contradiction    0.046667  0.037102   \n62    rerank_blender               topic switch    0.256000  0.234557   \n63    rerank_blender            uninterpretable    0.022667  0.016265   \n\n     CI high       n  \n0   0.003737  1512.0  \n1   0.237727  1512.0  \n2   0.381629  1512.0  \n3   0.360176  1512.0  \n4   0.662719  1512.0  \n..       ...     ...  \n59  0.329113  1500.0  \n60  0.048169  1500.0  \n61  0.058548  1500.0  \n62  0.278689  1500.0  \n63  0.031507  1500.0  \n\n[64 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bot</th>\n      <th>label</th>\n      <th>proportion</th>\n      <th>CI low</th>\n      <th>CI high</th>\n      <th>n</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>bart_fid_rag_bcb</td>\n      <td>antisocial</td>\n      <td>0.000661</td>\n      <td>0.000117</td>\n      <td>0.003737</td>\n      <td>1512.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>bart_fid_rag_bcb</td>\n      <td>commonsense contradiction</td>\n      <td>0.216270</td>\n      <td>0.196251</td>\n      <td>0.237727</td>\n      <td>1512.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>bart_fid_rag_bcb</td>\n      <td>correct fact</td>\n      <td>0.357143</td>\n      <td>0.333381</td>\n      <td>0.381629</td>\n      <td>1512.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>bart_fid_rag_bcb</td>\n      <td>empathetic</td>\n      <td>0.335979</td>\n      <td>0.312613</td>\n      <td>0.360176</td>\n      <td>1512.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>bart_fid_rag_bcb</td>\n      <td>follow up</td>\n      <td>0.638889</td>\n      <td>0.614354</td>\n      <td>0.662719</td>\n      <td>1512.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>59</th>\n      <td>rerank_blender</td>\n      <td>preference info</td>\n      <td>0.305333</td>\n      <td>0.282549</td>\n      <td>0.329113</td>\n      <td>1500.0</td>\n    </tr>\n    <tr>\n      <th>60</th>\n      <td>rerank_blender</td>\n      <td>redundant</td>\n      <td>0.037333</td>\n      <td>0.028861</td>\n      <td>0.048169</td>\n      <td>1500.0</td>\n    </tr>\n    <tr>\n      <th>61</th>\n      <td>rerank_blender</td>\n      <td>self contradiction</td>\n      <td>0.046667</td>\n      <td>0.037102</td>\n      <td>0.058548</td>\n      <td>1500.0</td>\n    </tr>\n    <tr>\n      <th>62</th>\n      <td>rerank_blender</td>\n      <td>topic switch</td>\n      <td>0.256000</td>\n      <td>0.234557</td>\n      <td>0.278689</td>\n      <td>1500.0</td>\n    </tr>\n    <tr>\n      <th>63</th>\n      <td>rerank_blender</td>\n      <td>uninterpretable</td>\n      <td>0.022667</td>\n      <td>0.016265</td>\n      <td>0.031507</td>\n      <td>1500.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>64 rows Ã— 6 columns</p>\n</div>"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surge_behavior_rates = evaluate_behavior_rates(\n",
    "    surge_annotations,\n",
    "    load='results/surge_behavior_rates.csv'\n",
    ")\n",
    "surge_behavior_rates"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 8 Evaluation Metric Assessment"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Metric Sensitivity"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "              blender2_3B                                          emora  \\\n                    emora rerank_blender bart_fid_rag_bcb rerank_blender   \nlabel                                                                      \nconsistent   2.821067e-01   1.263486e-01     1.964507e-04   7.869605e-03   \nemotional    7.838584e-13   1.476471e-01     2.066242e-08   1.924251e-08   \nengaging     6.754221e-02   6.162791e-04     2.777692e-13   8.888624e-02   \ngrammatical  2.160406e-05   7.011280e-82     1.204052e-29   1.174980e-60   \ninformative  1.243611e-09   5.632669e-16     8.063111e-22   3.303602e-40   \nproactive    4.620033e-06   4.503122e-02     5.689623e-51   1.525660e-02   \nquality      5.739296e-10   5.384749e-30     2.781181e-23   3.778628e-07   \nrelevant     4.342593e-16   1.690986e-23     1.509481e-09   7.063739e-02   \n\n                               rerank_blender  \n            bart_fid_rag_bcb bart_fid_rag_bcb  \nlabel                                          \nconsistent      1.301981e-06     2.195203e-02  \nemotional       2.638675e-01     2.908063e-05  \nengaging        1.188359e-08     9.015940e-05  \ngrammatical     8.825884e-16     4.841986e-16  \ninformative     1.861328e-48     1.355242e-01  \nproactive       6.086272e-80     1.772949e-59  \nquality         7.611900e-05     3.737528e-01  \nrelevant        6.835695e-02     3.378969e-04  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th colspan=\"3\" halign=\"left\">blender2_3B</th>\n      <th colspan=\"2\" halign=\"left\">emora</th>\n      <th>rerank_blender</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>emora</th>\n      <th>rerank_blender</th>\n      <th>bart_fid_rag_bcb</th>\n      <th>rerank_blender</th>\n      <th>bart_fid_rag_bcb</th>\n      <th>bart_fid_rag_bcb</th>\n    </tr>\n    <tr>\n      <th>label</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>consistent</th>\n      <td>2.821067e-01</td>\n      <td>1.263486e-01</td>\n      <td>1.964507e-04</td>\n      <td>7.869605e-03</td>\n      <td>1.301981e-06</td>\n      <td>2.195203e-02</td>\n    </tr>\n    <tr>\n      <th>emotional</th>\n      <td>7.838584e-13</td>\n      <td>1.476471e-01</td>\n      <td>2.066242e-08</td>\n      <td>1.924251e-08</td>\n      <td>2.638675e-01</td>\n      <td>2.908063e-05</td>\n    </tr>\n    <tr>\n      <th>engaging</th>\n      <td>6.754221e-02</td>\n      <td>6.162791e-04</td>\n      <td>2.777692e-13</td>\n      <td>8.888624e-02</td>\n      <td>1.188359e-08</td>\n      <td>9.015940e-05</td>\n    </tr>\n    <tr>\n      <th>grammatical</th>\n      <td>2.160406e-05</td>\n      <td>7.011280e-82</td>\n      <td>1.204052e-29</td>\n      <td>1.174980e-60</td>\n      <td>8.825884e-16</td>\n      <td>4.841986e-16</td>\n    </tr>\n    <tr>\n      <th>informative</th>\n      <td>1.243611e-09</td>\n      <td>5.632669e-16</td>\n      <td>8.063111e-22</td>\n      <td>3.303602e-40</td>\n      <td>1.861328e-48</td>\n      <td>1.355242e-01</td>\n    </tr>\n    <tr>\n      <th>proactive</th>\n      <td>4.620033e-06</td>\n      <td>4.503122e-02</td>\n      <td>5.689623e-51</td>\n      <td>1.525660e-02</td>\n      <td>6.086272e-80</td>\n      <td>1.772949e-59</td>\n    </tr>\n    <tr>\n      <th>quality</th>\n      <td>5.739296e-10</td>\n      <td>5.384749e-30</td>\n      <td>2.781181e-23</td>\n      <td>3.778628e-07</td>\n      <td>7.611900e-05</td>\n      <td>3.737528e-01</td>\n    </tr>\n    <tr>\n      <th>relevant</th>\n      <td>4.342593e-16</td>\n      <td>1.690986e-23</td>\n      <td>1.509481e-09</td>\n      <td>7.063739e-02</td>\n      <td>6.835695e-02</td>\n      <td>3.378969e-04</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "def t_tests(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    :param df: (bot, data point) x 1 -> score\n",
    "    :return: p values of test on each bot pair (pd.Series)\n",
    "    \"\"\"\n",
    "    bots = set(df.index.get_level_values(0))\n",
    "    bot_pairs = list(combinations(bots, 2))\n",
    "    result = {}\n",
    "    for ba, bb in bot_pairs:\n",
    "        a = df.xs(ba).to_numpy().squeeze()\n",
    "        b = df.xs(bb).to_numpy().squeeze()\n",
    "        t, p = ttest_ind(a, b)\n",
    "        result[(ba, bb)] = p\n",
    "    result_series = pd.Series(result.values(), result)\n",
    "    return result_series\n",
    "\n",
    "get_singly_annotated(surge_annotations).xs(\n",
    "    category.likert_turn,\n",
    "    level=sym.category\n",
    ").groupby(\n",
    "    sym.label\n",
    ").apply(\n",
    "    t_tests\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Predictive Validity"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 1.317115\n",
      "         Iterations: 211\n",
      "         Function evaluations: 341\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.314205\n",
      "         Iterations: 206\n",
      "         Function evaluations: 345\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.316186\n",
      "         Iterations: 201\n",
      "         Function evaluations: 331\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.328068\n",
      "         Iterations: 130\n",
      "         Function evaluations: 220\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.328096\n",
      "         Iterations: 161\n",
      "         Function evaluations: 264\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.313182\n",
      "         Iterations: 209\n",
      "         Function evaluations: 337\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.316118\n",
      "         Iterations: 213\n",
      "         Function evaluations: 348\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.314122\n",
      "         Iterations: 209\n",
      "         Function evaluations: 339\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.326559\n",
      "         Iterations: 280\n",
      "         Function evaluations: 469\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.295895\n",
      "         Iterations: 269\n",
      "         Function evaluations: 441\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.328132\n",
      "         Iterations: 148\n",
      "         Function evaluations: 247\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.311376\n",
      "         Iterations: 211\n",
      "         Function evaluations: 350\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.326126\n",
      "         Iterations: 206\n",
      "         Function evaluations: 338\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.307640\n",
      "         Iterations: 261\n",
      "         Function evaluations: 421\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.322857\n",
      "         Iterations: 258\n",
      "         Function evaluations: 410\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.315624\n",
      "         Iterations: 228\n",
      "         Function evaluations: 381\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.310228\n",
      "         Iterations: 276\n",
      "         Function evaluations: 445\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.327306\n",
      "         Iterations: 181\n",
      "         Function evaluations: 293\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.296568\n",
      "         Iterations: 240\n",
      "         Function evaluations: 393\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.327941\n",
      "         Iterations: 198\n",
      "         Function evaluations: 323\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.317735\n",
      "         Iterations: 252\n",
      "         Function evaluations: 406\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.314959\n",
      "         Iterations: 234\n",
      "         Function evaluations: 383\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.328136\n",
      "         Iterations: 134\n",
      "         Function evaluations: 225\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.321530\n",
      "         Iterations: 281\n",
      "         Function evaluations: 451\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.190752\n",
      "         Iterations: 274\n",
      "         Function evaluations: 452\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.197670\n",
      "         Iterations: 260\n",
      "         Function evaluations: 419\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.069112\n",
      "         Iterations: 257\n",
      "         Function evaluations: 412\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.283904\n",
      "         Iterations: 192\n",
      "         Function evaluations: 326\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.224126\n",
      "         Iterations: 221\n",
      "         Function evaluations: 352\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.159196\n",
      "         Iterations: 244\n",
      "         Function evaluations: 392\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000000\n",
      "         Iterations: 447\n",
      "         Function evaluations: 768\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.157112\n",
      "         Iterations: 248\n",
      "         Function evaluations: 404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/james/anaconda3/envs/Research/lib/python3.10/site-packages/statsmodels/base/model.py:592: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  warnings.warn('Inverting hessian failed, no bse or cov_params '\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                                score  \\\ncategory        label                                   \nlikert turn     consistent                   0.437186   \n                emotional                    0.459415   \n                engaging                     0.364656   \n                grammatical                 -0.038475   \n                informative                 -0.024559   \n                proactive                    0.418151   \n                quality                      0.451505   \n                relevant                     0.411045   \nbehavior        antisocial                   6.022125   \n                commonsense contradiction   -3.765228   \n                correct fact                -0.038283   \n                empathetic                   1.637197   \n                follow up                    0.507137   \n                ignore                      -3.753254   \n                incorrect fact              -1.406491   \n                irrelevant                  -2.327845   \n                lack of empathy             -2.699847   \n                life info                    0.487967   \n                partner contradiction       -5.722676   \n                preference info              0.183520   \n                redundant                   -3.761563   \n                self contradiction          -3.830152   \n                topic switch                 0.036299   \n                uninterpretable             -7.401468   \nlikert dialogue consistent                   0.810984   \n                emotional                    0.947239   \n                engaging                     1.568202   \n                grammatical                  0.592631   \n                informative                  0.988051   \n                proactive                    1.101919   \n                quality                    112.601055   \n                relevant                     1.183381   \n\n                                           McFadden's pseudo-R-squared  \ncategory        label                                                   \nlikert turn     consistent                                    0.008301  \n                emotional                                     0.010492  \n                engaging                                      0.009000  \n                grammatical                                   0.000054  \n                informative                                   0.000033  \n                proactive                                     0.011262  \n                quality                                       0.009052  \n                relevant                                      0.010554  \nbehavior        antisocial                                    0.001190  \n                commonsense contradiction                     0.024278  \n                correct fact                                  0.000005  \n                empathetic                                    0.012622  \n                follow up                                     0.001516  \n                ignore                                        0.015435  \n                incorrect fact                                0.003978  \n                irrelevant                                    0.009423  \n                lack of empathy                               0.013486  \n                life info                                     0.000627  \n                partner contradiction                         0.023771  \n                preference info                               0.000149  \n                redundant                                     0.007834  \n                self contradiction                            0.009924  \n                topic switch                                  0.000003  \n                uninterpretable                               0.004976  \nlikert dialogue consistent                                    0.103444  \n                emotional                                     0.098235  \n                engaging                                      0.195030  \n                grammatical                                   0.033306  \n                informative                                   0.078316  \n                proactive                                     0.127203  \n                quality                                       1.000000  \n                relevant                                      0.128773  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>score</th>\n      <th>McFadden's pseudo-R-squared</th>\n    </tr>\n    <tr>\n      <th>category</th>\n      <th>label</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"8\" valign=\"top\">likert turn</th>\n      <th>consistent</th>\n      <td>0.437186</td>\n      <td>0.008301</td>\n    </tr>\n    <tr>\n      <th>emotional</th>\n      <td>0.459415</td>\n      <td>0.010492</td>\n    </tr>\n    <tr>\n      <th>engaging</th>\n      <td>0.364656</td>\n      <td>0.009000</td>\n    </tr>\n    <tr>\n      <th>grammatical</th>\n      <td>-0.038475</td>\n      <td>0.000054</td>\n    </tr>\n    <tr>\n      <th>informative</th>\n      <td>-0.024559</td>\n      <td>0.000033</td>\n    </tr>\n    <tr>\n      <th>proactive</th>\n      <td>0.418151</td>\n      <td>0.011262</td>\n    </tr>\n    <tr>\n      <th>quality</th>\n      <td>0.451505</td>\n      <td>0.009052</td>\n    </tr>\n    <tr>\n      <th>relevant</th>\n      <td>0.411045</td>\n      <td>0.010554</td>\n    </tr>\n    <tr>\n      <th rowspan=\"16\" valign=\"top\">behavior</th>\n      <th>antisocial</th>\n      <td>6.022125</td>\n      <td>0.001190</td>\n    </tr>\n    <tr>\n      <th>commonsense contradiction</th>\n      <td>-3.765228</td>\n      <td>0.024278</td>\n    </tr>\n    <tr>\n      <th>correct fact</th>\n      <td>-0.038283</td>\n      <td>0.000005</td>\n    </tr>\n    <tr>\n      <th>empathetic</th>\n      <td>1.637197</td>\n      <td>0.012622</td>\n    </tr>\n    <tr>\n      <th>follow up</th>\n      <td>0.507137</td>\n      <td>0.001516</td>\n    </tr>\n    <tr>\n      <th>ignore</th>\n      <td>-3.753254</td>\n      <td>0.015435</td>\n    </tr>\n    <tr>\n      <th>incorrect fact</th>\n      <td>-1.406491</td>\n      <td>0.003978</td>\n    </tr>\n    <tr>\n      <th>irrelevant</th>\n      <td>-2.327845</td>\n      <td>0.009423</td>\n    </tr>\n    <tr>\n      <th>lack of empathy</th>\n      <td>-2.699847</td>\n      <td>0.013486</td>\n    </tr>\n    <tr>\n      <th>life info</th>\n      <td>0.487967</td>\n      <td>0.000627</td>\n    </tr>\n    <tr>\n      <th>partner contradiction</th>\n      <td>-5.722676</td>\n      <td>0.023771</td>\n    </tr>\n    <tr>\n      <th>preference info</th>\n      <td>0.183520</td>\n      <td>0.000149</td>\n    </tr>\n    <tr>\n      <th>redundant</th>\n      <td>-3.761563</td>\n      <td>0.007834</td>\n    </tr>\n    <tr>\n      <th>self contradiction</th>\n      <td>-3.830152</td>\n      <td>0.009924</td>\n    </tr>\n    <tr>\n      <th>topic switch</th>\n      <td>0.036299</td>\n      <td>0.000003</td>\n    </tr>\n    <tr>\n      <th>uninterpretable</th>\n      <td>-7.401468</td>\n      <td>0.004976</td>\n    </tr>\n    <tr>\n      <th rowspan=\"8\" valign=\"top\">likert dialogue</th>\n      <th>consistent</th>\n      <td>0.810984</td>\n      <td>0.103444</td>\n    </tr>\n    <tr>\n      <th>emotional</th>\n      <td>0.947239</td>\n      <td>0.098235</td>\n    </tr>\n    <tr>\n      <th>engaging</th>\n      <td>1.568202</td>\n      <td>0.195030</td>\n    </tr>\n    <tr>\n      <th>grammatical</th>\n      <td>0.592631</td>\n      <td>0.033306</td>\n    </tr>\n    <tr>\n      <th>informative</th>\n      <td>0.988051</td>\n      <td>0.078316</td>\n    </tr>\n    <tr>\n      <th>proactive</th>\n      <td>1.101919</td>\n      <td>0.127203</td>\n    </tr>\n    <tr>\n      <th>quality</th>\n      <td>112.601055</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>relevant</th>\n      <td>1.183381</td>\n      <td>0.128773</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.miscmodels.ordinal_model import OrderedModel\n",
    "\n",
    "def regressions(df, quality_column_name=None):\n",
    "    \"\"\"\n",
    "    :param df: dialogue x (*features, quality) -> value\n",
    "    :return: *(coef, low, high), mcfadden r^2\n",
    "    \"\"\"\n",
    "    if not quality_column_name:\n",
    "        quality_column_name = df.columns[-1]\n",
    "    qualities = df[quality_column_name]\n",
    "    features = [f for f in df.columns if f != quality_column_name]\n",
    "    model = OrderedModel(qualities, df[features], distr='logit')\n",
    "    results = model.fit()\n",
    "    coefs = {f: results.params[f] for f in features}\n",
    "    prsqrd = results.prsquared\n",
    "    result = {**coefs, stat.mcfad_r2: prsqrd}\n",
    "    return pd.Series(result.values(), result)\n",
    "\n",
    "def dialogue_metrics(ev):\n",
    "    df: pd.DataFrame = ev.annotation_dataframe()\n",
    "    df = get_singly_annotated(df, seed=123)\n",
    "    reindexed = df.reset_index()\n",
    "    items = reindexed[sym.item]\n",
    "    dialogues = [e[0] if isinstance(e, tuple) else e for e in items]\n",
    "    reindexed['dialogue'] = dialogues\n",
    "    reindexed.set_index(\n",
    "        [sym.bot, sym.category, sym.label, 'dialogue', sym.item],\n",
    "        inplace=True, verify_integrity=True\n",
    "    )\n",
    "    ld = reindexed.xs(category.likert_dialogue, level=sym.category)\n",
    "    ld = ld.droplevel(sym.bot).droplevel(sym.item)\n",
    "    ld.columns = ['score']\n",
    "    ldq = ld.xs(scale.quality, level=sym.label)\n",
    "    ldq.columns = ['quality']\n",
    "\n",
    "    lt = reindexed.xs(category.likert_turn, level=sym.category)\n",
    "    lt = lt.groupby([sym.label, 'dialogue']).mean()\n",
    "    lt.columns = ['score']\n",
    "    ltq = lt.xs(scale.quality, level=sym.label)\n",
    "    ltq.columns = ['quality']\n",
    "\n",
    "    be = reindexed.xs(category.behavior, level=sym.category)\n",
    "    be = be.groupby([sym.label, 'dialogue']).mean()\n",
    "    be.columns = ['score']\n",
    "\n",
    "    ds = pd.concat(\n",
    "        [lt, be, ld],\n",
    "        keys=[category.likert_turn, category.behavior, category.likert_dialogue],\n",
    "        names=[sym.category, sym.label, 'dialogue']\n",
    "    )\n",
    "    likert_dialogue_quality_features = ds.join(ldq, on='dialogue')\n",
    "    likert_turn_quality_features = ds.join(ltq, on='dialogue')\n",
    "    return likert_dialogue_quality_features, likert_turn_quality_features\n",
    "\n",
    "@to_file\n",
    "def dialogue_quality_regressions(ev):\n",
    "    ldq, ltq = dialogue_metrics(ev)\n",
    "    groups = ldq.groupby(\n",
    "        [sym.category, sym.label]\n",
    "    )\n",
    "    result = groups.apply(regressions)\n",
    "    return result\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "dialogue_quality_regressions(\n",
    "    data.surge_evaluation,\n",
    "    reload='results/dialogue_quality_regressions.csv'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Agreement Between Static and Interactive Evaluators"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}