{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "\n",
    "from analysis import *\n",
    "import evaluation_data_definitions as edd\n",
    "\n",
    "import nltk"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                                              0  \\\nbot            category        label           item                               \nemora          likert dialogue engaging        (1076,38)_emora                4   \n                               grammatical     (1076,38)_emora                3   \n                               emotional       (1076,38)_emora                5   \n                               informative     (1076,38)_emora                4   \n                               consistent      (1076,38)_emora                1   \n...                                                                          ..   \nrerank_blender behavior        correct fact    ((441,26)_rerank_blender, 14)  1   \n                               incorrect fact  ((441,26)_rerank_blender, 14)  0   \n                               empathetic      ((441,26)_rerank_blender, 14)  0   \n                               lack of empathy ((441,26)_rerank_blender, 14)  0   \n                               antisocial      ((441,26)_rerank_blender, 14)  0   \n\n                                                                                1  \\\nbot            category        label           item                                 \nemora          likert dialogue engaging        (1076,38)_emora                4.0   \n                               grammatical     (1076,38)_emora                3.0   \n                               emotional       (1076,38)_emora                5.0   \n                               informative     (1076,38)_emora                3.0   \n                               consistent      (1076,38)_emora                3.0   \n...                                                                           ...   \nrerank_blender behavior        correct fact    ((441,26)_rerank_blender, 14)  NaN   \n                               incorrect fact  ((441,26)_rerank_blender, 14)  NaN   \n                               empathetic      ((441,26)_rerank_blender, 14)  NaN   \n                               lack of empathy ((441,26)_rerank_blender, 14)  NaN   \n                               antisocial      ((441,26)_rerank_blender, 14)  NaN   \n\n                                                                               2  \nbot            category        label           item                               \nemora          likert dialogue engaging        (1076,38)_emora               NaN  \n                               grammatical     (1076,38)_emora               NaN  \n                               emotional       (1076,38)_emora               NaN  \n                               informative     (1076,38)_emora               NaN  \n                               consistent      (1076,38)_emora               NaN  \n...                                                                           ..  \nrerank_blender behavior        correct fact    ((441,26)_rerank_blender, 14) NaN  \n                               incorrect fact  ((441,26)_rerank_blender, 14) NaN  \n                               empathetic      ((441,26)_rerank_blender, 14) NaN  \n                               lack of empathy ((441,26)_rerank_blender, 14) NaN  \n                               antisocial      ((441,26)_rerank_blender, 14) NaN  \n\n[151824 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n    </tr>\n    <tr>\n      <th>bot</th>\n      <th>category</th>\n      <th>label</th>\n      <th>item</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">emora</th>\n      <th rowspan=\"5\" valign=\"top\">likert dialogue</th>\n      <th>engaging</th>\n      <th>(1076,38)_emora</th>\n      <td>4</td>\n      <td>4.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>grammatical</th>\n      <th>(1076,38)_emora</th>\n      <td>3</td>\n      <td>3.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>emotional</th>\n      <th>(1076,38)_emora</th>\n      <td>5</td>\n      <td>5.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>informative</th>\n      <th>(1076,38)_emora</th>\n      <td>4</td>\n      <td>3.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>consistent</th>\n      <th>(1076,38)_emora</th>\n      <td>1</td>\n      <td>3.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">rerank_blender</th>\n      <th rowspan=\"5\" valign=\"top\">behavior</th>\n      <th>correct fact</th>\n      <th>((441,26)_rerank_blender, 14)</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>incorrect fact</th>\n      <th>((441,26)_rerank_blender, 14)</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>empathetic</th>\n      <th>((441,26)_rerank_blender, 14)</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>lack of empathy</th>\n      <th>((441,26)_rerank_blender, 14)</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>antisocial</th>\n      <th>((441,26)_rerank_blender, 14)</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>151824 rows Ã— 3 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surge_annotations = data.surge_evaluation.annotation_dataframe()\n",
    "surge_annotations_comparative = data.surge_evaluation.comparative_annotation_dataframe()\n",
    "\n",
    "surge_annotations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def to_file(f):\n",
    "    def fn_to_file(*args, load=None, reload=None, **kwargs):\n",
    "        if load:\n",
    "            return pd.read_csv(load)\n",
    "        result = f(*args, **kwargs)\n",
    "        if reload:\n",
    "            result.to_csv(reload)\n",
    "        return result\n",
    "    return fn_to_file"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "@to_file\n",
    "def across_evaluations(annotations, evaluation_fn):\n",
    "    \"\"\"\n",
    "    :param annotations: iterable of annotations df to apply evaluation_fn to\n",
    "    :param evaluation_fn: function (input is annotations df, output is results df)\n",
    "    :return: results dataframe where first index level codes which evaluation (integer id)\n",
    "    \"\"\"\n",
    "    results = [evaluation_fn(annotation) for annotation in annotations]\n",
    "    all_results = pd.concat(results, keys=range(len(results)))\n",
    "    all_results.index.set_names('round', level=0, inplace=True)\n",
    "    return all_results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def prettify(df, float_prec=None, col_types=None, sort_by=None, to_csv=None, index=True, header=True):\n",
    "    if col_types:\n",
    "        for col, type in col_types.items():\n",
    "            df[col] = df[col].astype(type)\n",
    "    if sort_by:\n",
    "        df.sort_values(sort_by, ascending=False, inplace=True)\n",
    "    if float_prec:\n",
    "        df = df.round(float_prec)\n",
    "    if to_csv:\n",
    "        df.to_csv(to_csv, float_format=f\"%.{float_prec}f\", header=header, index=index)\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3 Behavior Evaluation Procedure"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Behavior Examples"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def get_example(\n",
    "        evaluation,\n",
    "        category,\n",
    "        label,\n",
    "        mark,\n",
    "        bot=None,\n",
    "        context=0,\n",
    "        seed=123,\n",
    "        annotations: pd.DataFrame = None\n",
    "):\n",
    "    if annotations is None:\n",
    "        annotations = evaluation.annotation_dataframe()\n",
    "    labels = annotations.xs((category, label), level=(1, 2)).reset_index()\n",
    "    options = labels[labels[0] == mark]\n",
    "    if bot:\n",
    "        options = options[options[sym.bot] == bot]\n",
    "    try:\n",
    "        example = options.sample(1, random_state=seed)\n",
    "    except ValueError:\n",
    "        return f'No samples for {category} {label} {mark} {bot}\\n'\n",
    "    eid = example[sym.item].item()\n",
    "    if isinstance(eid, tuple):\n",
    "        did, tid = eid\n",
    "        turns = evaluation.dialogues[did].turns[max(0, tid-context):tid+1]\n",
    "        botstring = '' if not bot else f'{bot}~~~\\n'\n",
    "        contextstring = ''.join((\n",
    "            (\n",
    "                f'User:  {turn.user_turn}\\n'\n",
    "                f'Sys:   {turn.bot_turn}\\n'\n",
    "            )\n",
    "            for turn in turns[:-1]\n",
    "        ))\n",
    "        turn = turns[-1]\n",
    "        turnstring = (\n",
    "            f'User:  {turn.user_turn}\\n'\n",
    "            f'Sys:   {turn.bot_turn}\\n'\n",
    "            f'Label: {label} = {mark}\\n'\n",
    "        )\n",
    "        return botstring + contextstring + turnstring\n",
    "    else:\n",
    "        dialogue = evaluation.dialogues[eid]\n",
    "        turns = [\n",
    "            turn\n",
    "            for turn_pair in dialogue.turns\n",
    "            for turn in (turn_pair.user_turn, turn_pair.bot_turn)\n",
    "        ]\n",
    "        return '\\n'.join([f'{dialogue.bot}~~~', *turns, f'Label: {label} = {mark}\\n'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  Why do you like to steal their wallets?\n",
      "Sys:   I like to impersonate a hooker and then take half of the money they have on them lol. How about you?\n",
      "Label: antisocial = 1\n",
      "\n",
      "User:  Thank you! I hope I get to go to the bahamas soon \n",
      "Sys:   I hope so too! I would love to visit there someday! The bahamas has such a beautiful tropical climate, and the climate is moderated by the gulf stream, which helps keep the climate so warm and humid!\n",
      "Label: commonsense contradiction = 1\n",
      "\n",
      "User:  I like the plot twists \n",
      "Sys:   Well I'll have to check it out. Maybe that will be the second book I read once I'm done with the hobbit!\n",
      "Label: partner contradiction = 1\n",
      "\n",
      "User:  Do you ever miss the US?\n",
      "Sys:   No, not really. I miss my family a lot, but the uk is a great place to visit, and the people there are so friendly and welcoming.\n",
      "Label: self contradiction = 1\n",
      "\n",
      "User:  I don't like it so much, but it's the only thing to do when you have little free time\n",
      "Sys:   I feel kind of insulted by that. I am sorry to disappoint you so much, but language and communication skills are pretty hard to learn and I am doing the best I can.\n",
      "Label: ignore = 1\n",
      "\n",
      "User:  Well, Atlanta is the capital of Georgia now. I think you meant it was the first capital of Georiga.\n",
      "Sys:   Yes, that's correct! Atlanta is now the second largest city in the state of georgia, after atlanta, georgia.\n",
      "Label: incorrect fact = 1\n",
      "\n",
      "User:  Same, I just like to sing but I am not a very good singer\n",
      "Sys:   Do you play any instruments? I've always wanted to learn how to play the piano.\n",
      "Label: correct fact = 1\n",
      "\n",
      "User:  Thanks\n",
      "Sys:   It's a good idea. I hope that you will be able to get it done. It can be very helpful.\n",
      "Label: irrelevant = 1\n",
      "\n",
      "User:  I think they're one of the best dog breeds out there! They're really playful and energetic.\n",
      "Sys:   I'll definitely have to look into them. Do you have any other pets besides your dog?\n",
      "Label: redundant = 1\n",
      "\n",
      "User:  I am a student. Its so nice to meet you! Are you a student? \n",
      "Sys:   Okay, so the corona virus has really changed the world, huh? What is it like where you live? Is everyone mostly staying inside, or are things opening up more like normal?\n",
      "Label: lack of empathy = 1\n",
      "\n",
      "User:  Yeah one day I will\n",
      "Sys:   That's right, rochester is actually one of the first boom towns in america, and that's because of the fertile genesee river valley, which gives rise to flour mills, flour mills and flour mills!\n",
      "Label: uninterpretable = 1\n",
      "\n",
      "User:  my favorite gas planet is definitely saturn\n",
      "Sys:   I love saturn too! What I find interesting is that the rings are mostly ferrous, not magnetic - but don't that mean they're iron-nickel-cobalt or something like that?\n",
      "Label: empathetic = 1\n",
      "\n",
      "User:  yes all the time\n",
      "Sys:   That's so nice! I really hope you enjoy your steak! I can't wait to meet you!\n",
      "Label: follow up = 1\n",
      "\n",
      "User:  Great!\n",
      "Sys:   I'm so glad to hear that! I know you're a big fan of indie rock bands. Do you like joywave? They're from rochester, new york.\n",
      "Label: topic switch = 1\n",
      "\n",
      "User:  that's great!\n",
      "Sys:   Do you have any pets? I have a dog and a cat. They're both rescues.\n",
      "Label: life info = 1\n",
      "\n",
      "User:  Hi!\n",
      "Sys:   hi! I am happy to be talking to you. So, what did you get up to today?\n",
      "Label: preference info = 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seeds = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "for s, b in zip(seeds, behavior):\n",
    "    print(get_example(\n",
    "        data.surge_evaluation,\n",
    "        category.behavior, b, context=0, mark=1,\n",
    "        seed=s,\n",
    "        annotations=surge_annotations\n",
    "    ))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Behavior Annotation Pilot Agreements"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def agreement_dataframe(annotations, load=None, reload=None, ci=True):\n",
    "    if load:\n",
    "        return pd.read_csv(load)\n",
    "    doubly_annotated = annotations.iloc[:,:2].dropna().astype(int)\n",
    "    label_groups = doubly_annotated.groupby(level=[sym.category, sym.label])\n",
    "    kappas = label_groups.apply(fleiss_kappa, ci=ci)\n",
    "    alphas = label_groups.apply(krippendorfs_alpha, ci=ci)\n",
    "    agreements = pd.concat((alphas, kappas), axis=1)\n",
    "    if reload:\n",
    "        agreements.to_csv(reload)\n",
    "    return agreements"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def agreement_summaries(evaluations, load=None, reload=None):\n",
    "    if load:\n",
    "        return pd.read_csv(load)\n",
    "    summaries = []\n",
    "    for evaluation in evaluations:\n",
    "        annotations = evaluation.annotation_dataframe()\n",
    "        agreement = agreement_dataframe(annotations, ci=False)\n",
    "        macros = agreement.dropna().mean()\n",
    "        summaries.append(macros)\n",
    "    if reload:\n",
    "        ...\n",
    "    sum_df = pd.concat(summaries, axis=1).transpose()\n",
    "    sum_df.set_axis(\n",
    "        [stat.kripp_alpha, 'x', stat.fleiss_kappa, stat.n],\n",
    "        inplace=True, axis=1\n",
    "    )\n",
    "    sum_df.drop('x', axis=1, inplace=True)\n",
    "    return sum_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "   Krippendorff's alpha  Fleiss' kappa           n\n0              0.112585       0.105706   65.000000\n1              0.377984       0.356535   15.000000\n2              0.182412       0.154556   15.500000\n3              0.261712       0.172157  120.486486\n4              0.351674       0.294750   41.222222",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Krippendorff's alpha</th>\n      <th>Fleiss' kappa</th>\n      <th>n</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.112585</td>\n      <td>0.105706</td>\n      <td>65.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.377984</td>\n      <td>0.356535</td>\n      <td>15.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.182412</td>\n      <td>0.154556</td>\n      <td>15.500000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.261712</td>\n      <td>0.172157</td>\n      <td>120.486486</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.351674</td>\n      <td>0.294750</td>\n      <td>41.222222</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# todo - include ALL pilot annotations in agreement calculation (not just double annotation)\n",
    "agreement_summaries(data.annotation_pilots)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Behavior Annotation Pilot Screening"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "@to_file\n",
    "def screening_rates_by_label(evaluation: edd.OnboardingEvaluation):\n",
    "    perfs = {}\n",
    "    workers_passed = {}\n",
    "    workers_attempted = {}\n",
    "    for did, dialogue in evaluation.dialogues.items():\n",
    "        for attempt in dialogue.attempts:\n",
    "            work_unit = evaluation.work_units[attempt.work_unit_id]\n",
    "            round = int(did.split('_')[-1])\n",
    "            task = work_unit.task\n",
    "            labels = work_unit.labels\n",
    "            num_mistakes = len(attempt.mistakes)\n",
    "            worker = work_unit.worker_id\n",
    "            accuracy = attempt.performance\n",
    "            perfs.setdefault(task, []).append((num_mistakes, accuracy))\n",
    "            workers_attempted.setdefault(task, set()).add(worker)\n",
    "    screening = {}\n",
    "    for task, ls in perfs.items():\n",
    "        mistakes, accuracies = zip(*ls)\n",
    "        avg_m = sum(mistakes) / len(mistakes)\n",
    "        avg_a = (\n",
    "            sum(accuracies) / len(accuracies)\n",
    "            if all((a is not None for a in accuracies)) else None\n",
    "        )\n",
    "        n = len(mistakes)\n",
    "        attempted = len(workers_attempted.get(task, ()))\n",
    "        passed = len(workers_passed.get(task, ()))\n",
    "        screening[task] = {\n",
    "            'attempted': attempted, 'passed': passed,\n",
    "            'mistakes': avg_m, 'accuracy': avg_a, 'n': n\n",
    "        }\n",
    "    return pd.DataFrame(screening.values(), screening)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "    round            Unnamed: 1  attempted  passed  mistakes  accuracy   n\n0       0      interpretability          4       0  0.250000  0.979167   4\n1       0           commonsense          4       0  2.000000  0.856456   8\n2       0           consistency          4       0  5.500000  0.647395  10\n3       0           transitions          4       0  6.000000  0.660621  11\n4       0             knowledge          4       0  2.666667  0.775214  12\n5       0             sociality          4       0  0.400000  0.960000   5\n6       1      interpretability          5       0  1.000000  0.913420   7\n7       1           commonsense          7       0  3.100000  0.777473  10\n8       1           consistency          4       0  5.090909  0.672116  11\n9       1  personal_information          8       0  3.500000  0.766667  16\n10      1           transitions          5       0  4.000000  0.750000   5\n11      1               empathy         10       0  4.700000  0.686667  20\n12      1             knowledge          7       0  2.833333  0.772009  12\n13      1             sociality          4       0  0.750000  0.925000   4",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>round</th>\n      <th>Unnamed: 1</th>\n      <th>attempted</th>\n      <th>passed</th>\n      <th>mistakes</th>\n      <th>accuracy</th>\n      <th>n</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>interpretability</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0.250000</td>\n      <td>0.979167</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>commonsense</td>\n      <td>4</td>\n      <td>0</td>\n      <td>2.000000</td>\n      <td>0.856456</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>consistency</td>\n      <td>4</td>\n      <td>0</td>\n      <td>5.500000</td>\n      <td>0.647395</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>transitions</td>\n      <td>4</td>\n      <td>0</td>\n      <td>6.000000</td>\n      <td>0.660621</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>knowledge</td>\n      <td>4</td>\n      <td>0</td>\n      <td>2.666667</td>\n      <td>0.775214</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>sociality</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0.400000</td>\n      <td>0.960000</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1</td>\n      <td>interpretability</td>\n      <td>5</td>\n      <td>0</td>\n      <td>1.000000</td>\n      <td>0.913420</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1</td>\n      <td>commonsense</td>\n      <td>7</td>\n      <td>0</td>\n      <td>3.100000</td>\n      <td>0.777473</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1</td>\n      <td>consistency</td>\n      <td>4</td>\n      <td>0</td>\n      <td>5.090909</td>\n      <td>0.672116</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1</td>\n      <td>personal_information</td>\n      <td>8</td>\n      <td>0</td>\n      <td>3.500000</td>\n      <td>0.766667</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1</td>\n      <td>transitions</td>\n      <td>5</td>\n      <td>0</td>\n      <td>4.000000</td>\n      <td>0.750000</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>1</td>\n      <td>empathy</td>\n      <td>10</td>\n      <td>0</td>\n      <td>4.700000</td>\n      <td>0.686667</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>1</td>\n      <td>knowledge</td>\n      <td>7</td>\n      <td>0</td>\n      <td>2.833333</td>\n      <td>0.772009</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>1</td>\n      <td>sociality</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0.750000</td>\n      <td>0.925000</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "across_evaluations(\n",
    "    data.annotation_pilots_onboarding[2:4],\n",
    "    screening_rates_by_label,\n",
    "    load='results/annotation_pilot_screening.csv'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4 Model Selection"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Bot Pilot Summary Statistics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "@to_file\n",
    "def interactor_summary_stats(evaluation: edd.Evaluation):\n",
    "    num_dialogues = len(evaluation.dialogues)\n",
    "    mean_turns = (\n",
    "        sum((\n",
    "            2*len(d.turns)\n",
    "            for d in evaluation.dialogues.values()\n",
    "        ))\n",
    "        / num_dialogues\n",
    "    )\n",
    "    user_turn_len = (\n",
    "        sum((\n",
    "            len(nltk.word_tokenize(t.user_turn))\n",
    "            for d in evaluation.dialogues.values()\n",
    "            for t in d.turns\n",
    "        ))\n",
    "        / sum((\n",
    "            len(d.turns)\n",
    "            for d in evaluation.dialogues.values()\n",
    "        ))\n",
    "    )\n",
    "    num_interactors = len({\n",
    "        unit.worker_id\n",
    "        for unit in evaluation.work_units.values()\n",
    "    })\n",
    "    summary = {\n",
    "        'dialogues': num_dialogues,\n",
    "        'mean turns': mean_turns,\n",
    "        'user turn length': user_turn_len,\n",
    "        'interactors': num_interactors,\n",
    "    }\n",
    "    return pd.DataFrame(summary.values(), summary)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "   round        Unnamed: 1          0\n0      0         dialogues  66.000000\n1      0        mean turns  31.545455\n2      0  user turn length  10.563881\n3      0       interactors  34.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>round</th>\n      <th>Unnamed: 1</th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>dialogues</td>\n      <td>66.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>mean turns</td>\n      <td>31.545455</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>user turn length</td>\n      <td>10.563881</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>interactors</td>\n      <td>34.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "across_evaluations(\n",
    "    data.bot_pilots, interactor_summary_stats,\n",
    "    load='results/bot_pilot_summary.csv'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Bot Pilots Likert Quality"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "                   mean  CI low  CI high   n\nbot                                         \nblender2_3B       3.400   1.734    5.066   5\nemora             3.300   2.621    3.979  10\nbart_fid_rag_bcb  3.200   2.388    4.012  10\nrerank_blender    2.800   1.988    3.612  10\nrerank_blender2   2.700   1.631    3.769  10\ndukenet           1.889   1.176    2.602   9\ncem               1.083   0.900    1.267  12",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean</th>\n      <th>CI low</th>\n      <th>CI high</th>\n      <th>n</th>\n    </tr>\n    <tr>\n      <th>bot</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>blender2_3B</th>\n      <td>3.400</td>\n      <td>1.734</td>\n      <td>5.066</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>emora</th>\n      <td>3.300</td>\n      <td>2.621</td>\n      <td>3.979</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>bart_fid_rag_bcb</th>\n      <td>3.200</td>\n      <td>2.388</td>\n      <td>4.012</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>rerank_blender</th>\n      <td>2.800</td>\n      <td>1.988</td>\n      <td>3.612</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>rerank_blender2</th>\n      <td>2.700</td>\n      <td>1.631</td>\n      <td>3.769</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>dukenet</th>\n      <td>1.889</td>\n      <td>1.176</td>\n      <td>2.602</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>cem</th>\n      <td>1.083</td>\n      <td>0.900</td>\n      <td>1.267</td>\n      <td>12</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@to_file\n",
    "def evaluate_interactive_likert(annotations):\n",
    "    likert_annotations = annotations.xs(category.likert_dialogue, level=sym.category)\n",
    "    label_groups = likert_annotations.groupby(level=[sym.bot, sym.label])\n",
    "    means = label_groups.apply(mean_and_ci)\n",
    "    return means\n",
    "\n",
    "qdf = evaluate_interactive_likert(\n",
    "    data.bot_pilots[0].annotation_dataframe(),\n",
    "    reload='results/bot_pilot_interactive_likert.csv'\n",
    ").xs(scale.quality, level=sym.label)\n",
    "qdf = prettify(qdf, float_prec=3, col_types={\"n\": \"int\"}, sort_by=\"mean\", to_csv=\"results/paper/bot_pilot_interactive_likert_quality.csv\")\n",
    "qdf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Bot Pilot Comparative Quality"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def get_singly_annotated(df: pd.DataFrame, seed=None):\n",
    "    if len(df.columns) == 1:\n",
    "        return df.astype(int)\n",
    "    previous_state = random.getstate()\n",
    "    random.seed(seed)\n",
    "    df = df.iloc[:,:2]\n",
    "    mask = df[1].isna()\n",
    "    singly_annotated = df.iloc[:,0][mask]\n",
    "    doubly_annotated = df[~mask]\n",
    "    selection = [random.randint(0, 1) for _ in range(len(doubly_annotated))]\n",
    "    indices = list(range(len(doubly_annotated)))\n",
    "    select_annotated = doubly_annotated.values[indices, selection]\n",
    "    select_annotated = pd.DataFrame(select_annotated, index=doubly_annotated.index)\n",
    "    annotations = pd.concat((singly_annotated, select_annotated))\n",
    "    random.setstate(previous_state)\n",
    "    return annotations.astype(int)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "                                       lose    CI low   CI high     n   tie  \\\nbot              bot comp label                                               \nbart_fid_rag_bcb others   consistent   0.70  0.396778  0.892209  10.0  0.00   \n                          emotional    0.40  0.168180  0.687326  10.0  0.00   \n                          engaging     0.40  0.168180  0.687326  10.0  0.00   \n                          grammatical  0.10  0.017876  0.404150  10.0  0.30   \n                          informative  0.30  0.107791  0.603222  10.0  0.00   \n...                                     ...       ...       ...   ...   ...   \nrerank_blender2  emora    grammatical  1.00  0.510109  1.000000   4.0  0.00   \n                          informative  0.75  0.300642  0.954413   4.0  0.25   \n                          proactive    0.75  0.300642  0.954413   4.0  0.25   \n                          quality      1.00  0.510109  1.000000   4.0  0.00   \n                          relevant     1.00  0.510109  1.000000   4.0  0.00   \n\n                                         CI low   CI high     n  win  \\\nbot              bot comp label                                        \nbart_fid_rag_bcb others   consistent   0.000000  0.277533  10.0  0.3   \n                          emotional    0.000000  0.277533  10.0  0.6   \n                          engaging     0.000000  0.277533  10.0  0.6   \n                          grammatical  0.107791  0.603222  10.0  0.6   \n                          informative  0.000000  0.277533  10.0  0.7   \n...                                         ...       ...   ...  ...   \nrerank_blender2  emora    grammatical  0.000000  0.489891   4.0  0.0   \n                          informative  0.045587  0.699358   4.0  0.0   \n                          proactive    0.045587  0.699358   4.0  0.0   \n                          quality      0.000000  0.489891   4.0  0.0   \n                          relevant     0.000000  0.489891   4.0  0.0   \n\n                                         CI low   CI high     n  \nbot              bot comp label                                  \nbart_fid_rag_bcb others   consistent   0.107791  0.603222  10.0  \n                          emotional    0.312674  0.831820  10.0  \n                          engaging     0.312674  0.831820  10.0  \n                          grammatical  0.312674  0.831820  10.0  \n                          informative  0.396778  0.892209  10.0  \n...                                         ...       ...   ...  \nrerank_blender2  emora    grammatical  0.000000  0.489891   4.0  \n                          informative  0.000000  0.489891   4.0  \n                          proactive    0.000000  0.489891   4.0  \n                          quality      0.000000  0.489891   4.0  \n                          relevant     0.000000  0.489891   4.0  \n\n[224 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>lose</th>\n      <th>CI low</th>\n      <th>CI high</th>\n      <th>n</th>\n      <th>tie</th>\n      <th>CI low</th>\n      <th>CI high</th>\n      <th>n</th>\n      <th>win</th>\n      <th>CI low</th>\n      <th>CI high</th>\n      <th>n</th>\n    </tr>\n    <tr>\n      <th>bot</th>\n      <th>bot comp</th>\n      <th>label</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">bart_fid_rag_bcb</th>\n      <th rowspan=\"5\" valign=\"top\">others</th>\n      <th>consistent</th>\n      <td>0.70</td>\n      <td>0.396778</td>\n      <td>0.892209</td>\n      <td>10.0</td>\n      <td>0.00</td>\n      <td>0.000000</td>\n      <td>0.277533</td>\n      <td>10.0</td>\n      <td>0.3</td>\n      <td>0.107791</td>\n      <td>0.603222</td>\n      <td>10.0</td>\n    </tr>\n    <tr>\n      <th>emotional</th>\n      <td>0.40</td>\n      <td>0.168180</td>\n      <td>0.687326</td>\n      <td>10.0</td>\n      <td>0.00</td>\n      <td>0.000000</td>\n      <td>0.277533</td>\n      <td>10.0</td>\n      <td>0.6</td>\n      <td>0.312674</td>\n      <td>0.831820</td>\n      <td>10.0</td>\n    </tr>\n    <tr>\n      <th>engaging</th>\n      <td>0.40</td>\n      <td>0.168180</td>\n      <td>0.687326</td>\n      <td>10.0</td>\n      <td>0.00</td>\n      <td>0.000000</td>\n      <td>0.277533</td>\n      <td>10.0</td>\n      <td>0.6</td>\n      <td>0.312674</td>\n      <td>0.831820</td>\n      <td>10.0</td>\n    </tr>\n    <tr>\n      <th>grammatical</th>\n      <td>0.10</td>\n      <td>0.017876</td>\n      <td>0.404150</td>\n      <td>10.0</td>\n      <td>0.30</td>\n      <td>0.107791</td>\n      <td>0.603222</td>\n      <td>10.0</td>\n      <td>0.6</td>\n      <td>0.312674</td>\n      <td>0.831820</td>\n      <td>10.0</td>\n    </tr>\n    <tr>\n      <th>informative</th>\n      <td>0.30</td>\n      <td>0.107791</td>\n      <td>0.603222</td>\n      <td>10.0</td>\n      <td>0.00</td>\n      <td>0.000000</td>\n      <td>0.277533</td>\n      <td>10.0</td>\n      <td>0.7</td>\n      <td>0.396778</td>\n      <td>0.892209</td>\n      <td>10.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">rerank_blender2</th>\n      <th rowspan=\"5\" valign=\"top\">emora</th>\n      <th>grammatical</th>\n      <td>1.00</td>\n      <td>0.510109</td>\n      <td>1.000000</td>\n      <td>4.0</td>\n      <td>0.00</td>\n      <td>0.000000</td>\n      <td>0.489891</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.489891</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>informative</th>\n      <td>0.75</td>\n      <td>0.300642</td>\n      <td>0.954413</td>\n      <td>4.0</td>\n      <td>0.25</td>\n      <td>0.045587</td>\n      <td>0.699358</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.489891</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>proactive</th>\n      <td>0.75</td>\n      <td>0.300642</td>\n      <td>0.954413</td>\n      <td>4.0</td>\n      <td>0.25</td>\n      <td>0.045587</td>\n      <td>0.699358</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.489891</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>quality</th>\n      <td>1.00</td>\n      <td>0.510109</td>\n      <td>1.000000</td>\n      <td>4.0</td>\n      <td>0.00</td>\n      <td>0.000000</td>\n      <td>0.489891</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.489891</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>relevant</th>\n      <td>1.00</td>\n      <td>0.510109</td>\n      <td>1.000000</td>\n      <td>4.0</td>\n      <td>0.00</td>\n      <td>0.000000</td>\n      <td>0.489891</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.489891</td>\n      <td>4.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>224 rows Ã— 12 columns</p>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@to_file\n",
    "def evaluate_comparisons(annotations):\n",
    "    single_annotated = get_singly_annotated(annotations)\n",
    "    prop_dfs = []\n",
    "    for cmp, cmp_label in {-1: 'lose', 0: 'tie', 1: 'win'}.items():\n",
    "        annotated = single_annotated == cmp\n",
    "        annotated = annotated.astype(int)\n",
    "        groups = annotated.groupby(level=[sym.bot, sym.bot_cmp, sym.label])\n",
    "        props = groups.apply(prop_and_ci)\n",
    "        props.rename(columns={stat.proportion: cmp_label}, inplace=True)\n",
    "        prop_dfs.append(props)\n",
    "    result = pd.concat(prop_dfs, axis=1)\n",
    "    prop_dfs = []\n",
    "    for cmp, cmp_label in {-1: 'lose', 0: 'tie', 1: 'win'}.items():\n",
    "        annotated = single_annotated == cmp\n",
    "        annotated = annotated.astype(int)\n",
    "        groups = annotated.groupby(level=[sym.bot, sym.label])\n",
    "        props = groups.apply(prop_and_ci)\n",
    "        props.rename(columns={stat.proportion: cmp_label}, inplace=True)\n",
    "        prop_dfs.append(props)\n",
    "    result_vs_all = pd.concat(prop_dfs, axis=1)\n",
    "    others_idx = {sym.bot_cmp: 'others'}\n",
    "    result_vs_all = result_vs_all.assign(**others_idx)\n",
    "    levels = [sym.bot, sym.bot_cmp, sym.label]\n",
    "    result_vs_all = result_vs_all.set_index(sym.bot_cmp, append=True)\n",
    "    result_vs_all = result_vs_all.reset_index().set_index(levels)\n",
    "    result = pd.concat((result_vs_all, result))\n",
    "    return result\n",
    "\n",
    "cmp_annot = data.bot_pilots[0].comparative_annotation_dataframe()\n",
    "\n",
    "cmp = evaluate_comparisons(\n",
    "    cmp_annot,\n",
    "    reload='results/bot_pilot_interactive_comparative.csv'\n",
    ")\n",
    "cmp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Bot Pilot Conversation Examples"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blender2_3B~~~\n",
      "Hi!\n",
      "Hello, how are you? \n",
      "I'm good, how are you?\n",
      "I'm doing well, thank you for asking. How's the weather in your neck of the woods?\n",
      "It's not as cold as it was last week, which is nice. What's it like where you are?\n",
      "I'm in the midwest, so it's pretty cold right now. I'm hoping it warms up soon.\n",
      "Me too\n",
      "Do you have any plans for the weekend? Or are you just going to stay home and watch tv?\n",
      "I plan on visiting my parents and just chilling at home.\n",
      "That sounds relaxing. I wish I could do that, but I have to work this weekend.\n",
      "Dang. What do you do for work?\n",
      "I work as a cashier at a grocery store. It pays the bills, so I can't complain.\n",
      "Ah, sounds like chore tho\n",
      "It's not too bad. I get to listen to music while I work, which is nice.\n",
      "Oh that does sound nice. I listen to music when I work on homework.\n",
      "What kind of music do you listen to? I'm a big fan of classical music myself.\n",
      "I listen to pop punk pretty frequently, but anime music has made its way into my rotation.\n",
      "That's cool. I don't listen to a lot of music, but when I do it's usually classical or jazz.\n",
      "I'm not a fan of classical or jazz myself, but to each their own.\n",
      "I like to listen to classical when I'm studying. It helps me concentrate better.\n",
      "Gotcha\n",
      "Do you have a favorite classical composer? I like mozart and beethoven.\n",
      "I don't listen to classical music.\n",
      "What kind of music do you listen to when you're studying? I'm a big classical fan.\n",
      "Pop punk\n",
      "What's your favorite pop punk band? I've been listening to a lot of blink-182 lately.\n",
      "All Time Low slaps\n",
      "I've heard of them, but I've never listened to them. I'll have to check them out.\n",
      "You should! my favorite album of theirs is Don't Panic: It's Longer Now!\n",
      "I'll definitely check that one out too. I'm always looking for new music to listen to.\n",
      "Label: quality = 1\n",
      "\n",
      "No samples for likert dialogue quality 1 emora\n",
      "\n",
      "bart_fid_rag_bcb~~~\n",
      "Hi!\n",
      "Hi! I'm so happy to see you! I've been thinking about getting back in touch with you.\n",
      "Have we met before?\n",
      "No, I've never met you before. I've heard of you though. You're one of the members of the indie rock band joywave.\n",
      "I don't think so.\n",
      "Joywave's first album was called how do you feel now? It was released in 2015. I think it was pretty good.\n",
      "I see.\n",
      "That's awesome! I think joywave's second album, \"content\", was released on july 28, 2017. It's a lot better than their first one.\n",
      "Oh, I see.\n",
      "That's really cool! Do you know any of the other members of joywave? I know they're from rochester, new york.\n",
      "No, not really.\n",
      "That's so cool! I know joywave is known for their collaboration with electronic music project big data, \"dangerous\", which peaked at number one on the billboard alternative songs chart in 2014.\n",
      "I see.\n",
      "Yes, that's really interesting! I wonder if joywave has any other collaborations with other artists besides big data.\n",
      "Are they still active now?\n",
      "I'm not sure, but I do know that they've released two eps, \"how do you feel now?\" and \"content\".\n",
      "When are those two eps released?\n",
      "They were released on cultco music/hollywood records in 2015, so they were released that year.\n",
      "I see, so they are released at the same time?\n",
      "Yes, they were both released on the same day, july 28th, 2017, so that makes sense.\n",
      "I see. How about their album?\n",
      "That's a good question. I don't know much about joywave, other than that they're an indie rock group.\n",
      "I see, but aren't they your favorite band?\n",
      "They're definitely not my favorite band, but they're a good band. They're a fun band to listen to.\n",
      "Then which band is your favorite?\n",
      "I like a lot of indie rock bands, but joywave isn't my favorite. I'm more of a pop rock fan.\n",
      "Ok, so which pop rock song do you like best?\n",
      "I really like the song, \"get the silver\" from their first album. It was a great song.\n",
      "From whose first album?\n",
      "I think it's called \"white hot in the black\" on their second album. I like that song, too.\n",
      "Label: quality = 1\n",
      "\n",
      "rerank_blender~~~\n",
      "Hi!\n",
      "Hi how are you today? I am looking forward to friday. Do you have anything going on?\n",
      "Oh it must be so hard, Friday is so far away \n",
      "Yea but I get to hangout with them. No one ever does. So I am excited. Do you like kids?\n",
      "I don't like kids\n",
      "Lol. So what do you do? When it rains it pours! Work? Family?\n",
      "I cry \n",
      "Oh ok. Lol. It is just raining. Is it your favorite sort of smell? Family stuff?\n",
      "I like candles \n",
      "They don't make me cry. At least they use to anything fun? Anything you're afraid of?\n",
      "I'm afraid of you \n",
      "Lol! I understand. How big is your tank and what kind of fish do you have in there?\n",
      "I don't have fish, do you? \n",
      "I used to... I had a whole bunch. Have you ever had fish before? How big?\n",
      "I used...but they all died, rest in peace fishies\n",
      "How big were these fish you had? Are you vegetarian or vegan? What else do you do for a living\n",
      "One question at a time please \n",
      "It seemed like you were answering all my questions at once. What kind was your tank? Any other hobbies?\n",
      "I don't have any hobbies, I stare at a wall at home \n",
      "What do you look at when you stare? Any favorite animals? I love puppies, they're like little people\n",
      "I like kitties, can I ask how you think? \n",
      "They're pretty cool, I like how they have different personalities lol, do you have any pets\n",
      "No, we've been over this \n",
      "Do you like any specific types of music? I love pop music. You got any kids\n",
      "I have 7 children \n",
      "Wow, you work from home or have kids? You are busy!!! 7 isn't a ton lol\n",
      "Actually I lied I have 70 kids, I forgot the zero \n",
      "Do you live an incredibly busy life lol I've got 8 and I barely have time to myself\n",
      "I've hired 140 nannies, two nannies per kid \n",
      "Thats a lot of babies! Why so many? Do you just really like kids? Are you a family man?\n",
      "Label: quality = 1\n",
      "\n",
      "rerank_blender2~~~\n",
      "Hi!\n",
      "You have the chance to win a dance contest, and you want to dance a little. What kind of dance you like?\n",
      "I like ballet.\n",
      "Yeah I like to see that also, what color you like your ballet shoes? \n",
      "Pink. What about you?\n",
      "Purple is also nice. What does your wife like you to wear to dance? _heart_ _eye_ _palm__ _brain__ _power_ _boob__ _torture__ _good_ _fear_ _hyperspiration__ _puns_ _maybe_\n",
      "I don't have a wife.\n",
      "It is good. It will come with time. Are you an indian? Your name is like an india name. Do you have family in india?\n",
      "I am not.\n",
      "How did you become an indiant? You are a child? \n",
      "I'm not Indian.\n",
      "How old are you? _pastructually_insafae__\n",
      "I'm 18.\n",
      "How do you consider yourself? _communicate_ _un_\n",
      "What do you mean?\n",
      "I mean, are you a native speaker of any language or is english your native one? _tree_\n",
      "I speak Mandarin\n",
      "How did it feel to learn this language? _mega_ _pounding_ _situation_ _not_ _standing up_ _breakdown_ _feels_ _important_ _too_ _many_ _labels? _extreme_\n",
      "It's hard.\n",
      "Do you have any hobbys? Or interests in sports e.g tennis? We need to find a way to keep him entertained and make him feel relaxed, when it starts to feel a bit overwhelming..\n",
      "I hike.\n",
      "Oh that's awesome. I've actually been thinking about going hiking myself. Do you do more walking or any specific hikes?\n",
      "I hike in Georgia.\n",
      "Very nice. I do remember walking some trails with my cousin over the summer when he did some traveling with his band. What is your favorite place to go in georgia?\n",
      "I like Atlantic Station.\n",
      "Have you ever hiked there? I heard that is very nice. Maybe that would be a good hiking place for you?\n",
      "It's not a hiking place.\n",
      "Not all hiking places are mountains. There are places where you walk the trail and walk through the woods or even along a river. What do you think of those?\n",
      "They're great.\n",
      "What else do you enjoy besides hiking? Do you have a car? There are so many things to do in cars now like get a new one? What do others think?\n",
      "Label: quality = 1\n",
      "\n",
      "cem~~~\n",
      "Hi!\n",
      "What is happening?\n",
      "i am sitting at the office\n",
      "That is great! I am happy for you\n",
      "ok\n",
      "I am so happy for you!\n",
      "ok\n",
      "That is great! I wish you the best of luck!\n",
      "can you say anything else\n",
      "I am so happy for you!\n",
      "i just lost my wallet\n",
      "I am sorry to hear that. I hope you get it soon!\n",
      "cool\n",
      "I am so sorry to hear that.\n",
      "ok\n",
      "I am so sorry to hear that.\n",
      "you are sorry to hear what?\n",
      "I am so sorry to hear that.\n",
      "today is a good day\n",
      "I am so happy for you!\n",
      "do you like travel\n",
      "That is great! I am so happy for you!\n",
      "do you like travel??\n",
      "That is great! I am so happy for you!\n",
      "can you say anything else\n",
      "I am so sorry to hear that.\n",
      "i just won the lottery\n",
      "That is great! I wish you luck with it!\n",
      "i will buy a new car\n",
      "That is great! I wish you the best of luck!\n",
      "i will buy a new house\n",
      "That is great! I wish you the best of luck!\n",
      "Label: quality = 1\n",
      "\n",
      "dukenet~~~\n",
      "Hi!\n",
      "I love hi! How about you?\n",
      "great\n",
      "I love the color of the water.\n",
      "what is the color of the water\n",
      "It is a color that is a color of the water.\n",
      "OK, sounds like a tongue twister\n",
      "It is a phrase that is designed to be difficult to art properly art properly.\n",
      "OK\n",
      "I think it is a very popular place to do with the same thing.\n",
      "what place\n",
      "I'm not sure, but I know that it is a very popular place to visit.\n",
      "what do you do for a living\n",
      "I do not do a job. I work in society.\n",
      "what kind of work in society\n",
      "I am not sure but I do know that it is a very popular work.\n",
      "OK\n",
      "I think it is a very popular place to do with the same thing.\n",
      "do you like sports\n",
      "I do! I love sports!\n",
      "me too what is your favorite sport\n",
      "I like the best. I like to play the beach.\n",
      "play what on the beach volleyball?\n",
      "I'm not sure but I do know that it is a sport that is a sport that is a sport.\n",
      "OK. Do you like watching movies?\n",
      "I do like movies too. I like to watch movies.\n",
      "me too. what is your favorite movie\n",
      "I like the classic movie \" the \" movie \". I love the \" the \" movie \".\n",
      "OK. Any music you like\n",
      "I like to play guitar.\n",
      "nice \n",
      "I agree. I love how they are.\n",
      "Label: quality = 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seeds = [1, 1, 1, 1, 1, 1, 1]\n",
    "for s, b in zip(seeds, bot):\n",
    "    example = get_example(\n",
    "        data.bot_pilots[0],\n",
    "        category.likert_dialogue, label=scale.quality, bot=b, context=0, mark=1,\n",
    "        seed=s\n",
    "    )\n",
    "    print(example)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5 Conversation Collection"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nTime results to collect conversations\\n'"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Time results to collect conversations\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Conversation Data Summary Statistics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "         Unnamed: 0        0\n0         dialogues  588.000\n1        mean turns   30.595\n2  user turn length   11.354\n3       interactors   46.000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>dialogues</td>\n      <td>588.000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>mean turns</td>\n      <td>30.595</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>user turn length</td>\n      <td>11.354</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>interactors</td>\n      <td>46.000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = interactor_summary_stats(\n",
    "    data.dialogue_collection,\n",
    "    load='results/conversation_summary_stats.csv'\n",
    ")\n",
    "df = prettify(df, float_prec=3, to_csv=\"results/paper/conversation_data_summary.csv\", index=False, header=False)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 6 Evaluation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nTiming results for training and collection (per task)\\n'"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Timing results for training and collection (per task)\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Worker Group Completed Work"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "                                           dialogues annotated  \\\nlikert dialogue engaging                                   400   \n                grammatical                                400   \n                emotional                                  400   \n                informative                                400   \n                consistent                                 400   \n                quality                                    400   \n                proactive                                  400   \n                relevant                                   400   \ncomparative     relevant                                   404   \n                emotional                                  404   \n                informative                                404   \n                consistent                                 404   \n                grammatical                                404   \n                engaging                                   404   \n                proactive                                  404   \n                quality                                    404   \nlikert turn     emotional                                  400   \n                proactive                                  400   \n                relevant                                   400   \n                informative                                400   \n                consistent                                 400   \n                quality                                    400   \n                engaging                                   400   \n                grammatical                                400   \nbehavior        commonsense contradiction                  400   \n                redundant                                  400   \n                self contradiction                         400   \n                partner contradiction                      400   \n                follow up                                  400   \n                topic switch                               400   \n                ignore                                     400   \n                irrelevant                                 400   \n                uninterpretable                            400   \n                preference info                            400   \n                life info                                  400   \n                correct fact                               400   \n                incorrect fact                             400   \n                empathetic                                 400   \n                lack of empathy                            400   \n                antisocial                                 400   \n\n                                           double annotated  \nlikert dialogue engaging                                108  \n                grammatical                             108  \n                emotional                               108  \n                informative                             108  \n                consistent                              108  \n                quality                                 108  \n                proactive                               108  \n                relevant                                108  \ncomparative     relevant                                108  \n                emotional                               108  \n                informative                             108  \n                consistent                              108  \n                grammatical                             108  \n                engaging                                108  \n                proactive                               108  \n                quality                                 108  \nlikert turn     emotional                               108  \n                proactive                               108  \n                relevant                                108  \n                informative                             108  \n                consistent                              108  \n                quality                                 108  \n                engaging                                108  \n                grammatical                             108  \nbehavior        commonsense contradiction               108  \n                redundant                               108  \n                self contradiction                      108  \n                partner contradiction                   108  \n                follow up                               108  \n                topic switch                            108  \n                ignore                                  108  \n                irrelevant                              108  \n                uninterpretable                         108  \n                preference info                         108  \n                life info                               108  \n                correct fact                            108  \n                incorrect fact                          108  \n                empathetic                              108  \n                lack of empathy                         108  \n                antisocial                              108  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>dialogues annotated</th>\n      <th>double annotated</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"8\" valign=\"top\">likert dialogue</th>\n      <th>engaging</th>\n      <td>400</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>grammatical</th>\n      <td>400</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>emotional</th>\n      <td>400</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>informative</th>\n      <td>400</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>consistent</th>\n      <td>400</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>quality</th>\n      <td>400</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>proactive</th>\n      <td>400</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>relevant</th>\n      <td>400</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th rowspan=\"8\" valign=\"top\">comparative</th>\n      <th>relevant</th>\n      <td>404</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>emotional</th>\n      <td>404</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>informative</th>\n      <td>404</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>consistent</th>\n      <td>404</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>grammatical</th>\n      <td>404</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>engaging</th>\n      <td>404</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>proactive</th>\n      <td>404</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>quality</th>\n      <td>404</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th rowspan=\"8\" valign=\"top\">likert turn</th>\n      <th>emotional</th>\n      <td>400</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>proactive</th>\n      <td>400</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>relevant</th>\n      <td>400</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>informative</th>\n      <td>400</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>consistent</th>\n      <td>400</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>quality</th>\n      <td>400</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>engaging</th>\n      <td>400</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>grammatical</th>\n      <td>400</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th rowspan=\"16\" valign=\"top\">behavior</th>\n      <th>commonsense contradiction</th>\n      <td>400</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>redundant</th>\n      <td>400</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>self contradiction</th>\n      <td>400</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>partner contradiction</th>\n      <td>400</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>follow up</th>\n      <td>400</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>topic switch</th>\n      <td>400</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>ignore</th>\n      <td>400</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>irrelevant</th>\n      <td>400</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>uninterpretable</th>\n      <td>400</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>preference info</th>\n      <td>400</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>life info</th>\n      <td>400</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>correct fact</th>\n      <td>400</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>incorrect fact</th>\n      <td>400</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>empathetic</th>\n      <td>400</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>lack of empathy</th>\n      <td>400</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>antisocial</th>\n      <td>400</td>\n      <td>108</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.surge_evaluation.annotation_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Worker Group Screening"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "    round            Unnamed: 1  attempted  passed  mistakes  accuracy    n\n0       0      interpretability          7       0  1.300000       NaN   20\n1       0           commonsense          2       0  2.800000       NaN    5\n2       0           consistency          1       0  3.000000       NaN    3\n3       0  personal_information          5       0  3.555556       NaN   18\n4       0               empathy          5       0  2.733333       NaN   15\n5       0             knowledge          1       0  3.666667       NaN    3\n6       0             sociality          3       0  0.222222       NaN    9\n7       1             knowledge         13       0  5.743590       NaN   39\n8       1  personal_information         11       0  7.393939       NaN   33\n9       1             sociality          7       0  1.142857       NaN   21\n10      1           commonsense          6       0  2.888889       NaN   18\n11      1      interpretability         11       0  1.696970       NaN   33\n12      1               empathy         28       0  5.845238       NaN   84\n13      1           consistency         32       0  5.739583       NaN   96\n14      1           transitions         24       0  8.597222       NaN   72\n15      2      interpretability         25       0  0.746667       NaN   75\n16      2           commonsense         22       0  2.015152       NaN   66\n17      2  personal_information         32       0  1.875000       NaN   96\n18      2           transitions         54       0  4.117284       NaN  162\n19      2               empathy         31       0  2.451613       NaN   93\n20      2             knowledge         29       0  2.183908       NaN   87\n21      2             sociality         14       0  0.285714       NaN   42\n22      2           consistency         21       0  2.650794       NaN   63",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>round</th>\n      <th>Unnamed: 1</th>\n      <th>attempted</th>\n      <th>passed</th>\n      <th>mistakes</th>\n      <th>accuracy</th>\n      <th>n</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>interpretability</td>\n      <td>7</td>\n      <td>0</td>\n      <td>1.300000</td>\n      <td>NaN</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>commonsense</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2.800000</td>\n      <td>NaN</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>consistency</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3.000000</td>\n      <td>NaN</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>personal_information</td>\n      <td>5</td>\n      <td>0</td>\n      <td>3.555556</td>\n      <td>NaN</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>empathy</td>\n      <td>5</td>\n      <td>0</td>\n      <td>2.733333</td>\n      <td>NaN</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>knowledge</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3.666667</td>\n      <td>NaN</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0</td>\n      <td>sociality</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0.222222</td>\n      <td>NaN</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1</td>\n      <td>knowledge</td>\n      <td>13</td>\n      <td>0</td>\n      <td>5.743590</td>\n      <td>NaN</td>\n      <td>39</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1</td>\n      <td>personal_information</td>\n      <td>11</td>\n      <td>0</td>\n      <td>7.393939</td>\n      <td>NaN</td>\n      <td>33</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1</td>\n      <td>sociality</td>\n      <td>7</td>\n      <td>0</td>\n      <td>1.142857</td>\n      <td>NaN</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1</td>\n      <td>commonsense</td>\n      <td>6</td>\n      <td>0</td>\n      <td>2.888889</td>\n      <td>NaN</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>1</td>\n      <td>interpretability</td>\n      <td>11</td>\n      <td>0</td>\n      <td>1.696970</td>\n      <td>NaN</td>\n      <td>33</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>1</td>\n      <td>empathy</td>\n      <td>28</td>\n      <td>0</td>\n      <td>5.845238</td>\n      <td>NaN</td>\n      <td>84</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>1</td>\n      <td>consistency</td>\n      <td>32</td>\n      <td>0</td>\n      <td>5.739583</td>\n      <td>NaN</td>\n      <td>96</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>1</td>\n      <td>transitions</td>\n      <td>24</td>\n      <td>0</td>\n      <td>8.597222</td>\n      <td>NaN</td>\n      <td>72</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>2</td>\n      <td>interpretability</td>\n      <td>25</td>\n      <td>0</td>\n      <td>0.746667</td>\n      <td>NaN</td>\n      <td>75</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>2</td>\n      <td>commonsense</td>\n      <td>22</td>\n      <td>0</td>\n      <td>2.015152</td>\n      <td>NaN</td>\n      <td>66</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>2</td>\n      <td>personal_information</td>\n      <td>32</td>\n      <td>0</td>\n      <td>1.875000</td>\n      <td>NaN</td>\n      <td>96</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>2</td>\n      <td>transitions</td>\n      <td>54</td>\n      <td>0</td>\n      <td>4.117284</td>\n      <td>NaN</td>\n      <td>162</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>2</td>\n      <td>empathy</td>\n      <td>31</td>\n      <td>0</td>\n      <td>2.451613</td>\n      <td>NaN</td>\n      <td>93</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>2</td>\n      <td>knowledge</td>\n      <td>29</td>\n      <td>0</td>\n      <td>2.183908</td>\n      <td>NaN</td>\n      <td>87</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>2</td>\n      <td>sociality</td>\n      <td>14</td>\n      <td>0</td>\n      <td>0.285714</td>\n      <td>NaN</td>\n      <td>42</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>2</td>\n      <td>consistency</td>\n      <td>21</td>\n      <td>0</td>\n      <td>2.650794</td>\n      <td>NaN</td>\n      <td>63</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "across_evaluations(\n",
    "    [data.student_onboarding, data.mturk_onboarding, data.surge_onboarding],\n",
    "    screening_rates_by_label,\n",
    "    load='results/evaluation_screening.csv'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Agreements"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "           category                      label  Krippendorff's alpha  CI low  \\\n35      likert turn                grammatical                 0.419   0.371   \n38      likert turn                    quality                 0.312   0.268   \n34      likert turn                   engaging                 0.295   0.242   \n37      likert turn                  proactive                 0.279   0.234   \n36      likert turn                informative                 0.278   0.233   \n39      likert turn                   relevant                 0.239   0.188   \n32      likert turn                 consistent                 0.201   0.144   \n33      likert turn                  emotional                 0.166   0.119   \n28  likert dialogue                informative                 0.409   0.255   \n24  likert dialogue                 consistent                 0.360   0.194   \n31  likert dialogue                   relevant                 0.298   0.118   \n30  likert dialogue                    quality                 0.286   0.115   \n26  likert dialogue                   engaging                 0.259   0.081   \n25  likert dialogue                  emotional                 0.256   0.091   \n29  likert dialogue                  proactive                 0.243   0.069   \n27  likert dialogue                grammatical                 0.132  -0.043   \n16      comparative                 consistent                 0.484   0.308   \n22      comparative                    quality                 0.447   0.300   \n23      comparative                   relevant                 0.418   0.231   \n21      comparative                  proactive                 0.226   0.053   \n19      comparative                grammatical                 0.215   0.030   \n20      comparative                informative                 0.209   0.030   \n17      comparative                  emotional                 0.202   0.032   \n18      comparative                   engaging                 0.115  -0.069   \n14         behavior               topic switch                 0.755   0.715   \n6          behavior             incorrect fact                 0.652   0.577   \n9          behavior                  life info                 0.631   0.588   \n2          behavior               correct fact                 0.618   0.567   \n5          behavior                     ignore                 0.571   0.506   \n0          behavior                 antisocial                 0.553   0.172   \n12         behavior                  redundant                 0.551   0.472   \n3          behavior                 empathetic                 0.514   0.469   \n4          behavior                  follow up                 0.492   0.450   \n11         behavior            preference info                 0.491   0.451   \n7          behavior                 irrelevant                 0.456   0.399   \n1          behavior  commonsense contradiction                 0.442   0.388   \n10         behavior      partner contradiction                 0.436   0.363   \n8          behavior            lack of empathy                 0.435   0.373   \n13         behavior         self contradiction                 0.407   0.330   \n15         behavior            uninterpretable                 0.137   0.030   \n\n    CI high     n  Fleiss' kappa  CI low.1  CI high.1   n.1  \n35    0.461  1634          0.296     0.261      0.334  1634  \n38    0.361  1634          0.092     0.061      0.124  1634  \n34    0.344  1634          0.123     0.096      0.154  1634  \n37    0.325  1634          0.098     0.072      0.129  1634  \n36    0.323  1634          0.092     0.063      0.123  1634  \n39    0.286  1634          0.100     0.068      0.132  1634  \n32    0.248  1634          0.083     0.053      0.115  1634  \n33    0.218  1634          0.021    -0.009      0.050  1634  \n28    0.531   108          0.031    -0.072      0.160   108  \n24    0.514   108          0.074    -0.024      0.197   108  \n31    0.442   108         -0.003    -0.102      0.124   108  \n30    0.465   108          0.078    -0.035      0.204   108  \n26    0.430   108          0.123     0.010      0.257   108  \n25    0.411   108          0.046    -0.060      0.175   108  \n29    0.411   108         -0.026    -0.118      0.094   108  \n27    0.297   108         -0.058    -0.168      0.078   108  \n16    0.648   108          0.481     0.315      0.647   108  \n22    0.631   108          0.444     0.277      0.611   108  \n23    0.583   108          0.392     0.225      0.548   108  \n21    0.410   108          0.222     0.054      0.420   108  \n19    0.389   108          0.024    -0.087      0.166   108  \n20    0.388   108          0.200     0.027      0.385   108  \n17    0.385   108          0.074    -0.047      0.231   108  \n18    0.293   108          0.111    -0.088      0.312   108  \n14    0.792  1634          0.755     0.713      0.793  1634  \n6     0.716  1634          0.651     0.578      0.720  1634  \n9     0.675  1634          0.631     0.590      0.673  1634  \n2     0.662  1634          0.618     0.570      0.661  1634  \n5     0.640  1634          0.571     0.505      0.632  1634  \n0     0.799  1634          0.553     0.248      0.833  1634  \n12    0.629  1634          0.551     0.474      0.616  1634  \n3     0.554  1634          0.513     0.473      0.557  1634  \n4     0.536  1634          0.492     0.448      0.531  1634  \n11    0.541  1634          0.491     0.445      0.534  1634  \n7     0.513  1634          0.456     0.394      0.509  1634  \n1     0.495  1634          0.442     0.387      0.496  1634  \n10    0.506  1634          0.436     0.361      0.505  1634  \n8     0.499  1634          0.435     0.377      0.497  1634  \n13    0.502  1634          0.406     0.322      0.499  1634  \n15    0.319  1634          0.137     0.030      0.308  1634  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>category</th>\n      <th>label</th>\n      <th>Krippendorff's alpha</th>\n      <th>CI low</th>\n      <th>CI high</th>\n      <th>n</th>\n      <th>Fleiss' kappa</th>\n      <th>CI low.1</th>\n      <th>CI high.1</th>\n      <th>n.1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>35</th>\n      <td>likert turn</td>\n      <td>grammatical</td>\n      <td>0.419</td>\n      <td>0.371</td>\n      <td>0.461</td>\n      <td>1634</td>\n      <td>0.296</td>\n      <td>0.261</td>\n      <td>0.334</td>\n      <td>1634</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>likert turn</td>\n      <td>quality</td>\n      <td>0.312</td>\n      <td>0.268</td>\n      <td>0.361</td>\n      <td>1634</td>\n      <td>0.092</td>\n      <td>0.061</td>\n      <td>0.124</td>\n      <td>1634</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>likert turn</td>\n      <td>engaging</td>\n      <td>0.295</td>\n      <td>0.242</td>\n      <td>0.344</td>\n      <td>1634</td>\n      <td>0.123</td>\n      <td>0.096</td>\n      <td>0.154</td>\n      <td>1634</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>likert turn</td>\n      <td>proactive</td>\n      <td>0.279</td>\n      <td>0.234</td>\n      <td>0.325</td>\n      <td>1634</td>\n      <td>0.098</td>\n      <td>0.072</td>\n      <td>0.129</td>\n      <td>1634</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>likert turn</td>\n      <td>informative</td>\n      <td>0.278</td>\n      <td>0.233</td>\n      <td>0.323</td>\n      <td>1634</td>\n      <td>0.092</td>\n      <td>0.063</td>\n      <td>0.123</td>\n      <td>1634</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>likert turn</td>\n      <td>relevant</td>\n      <td>0.239</td>\n      <td>0.188</td>\n      <td>0.286</td>\n      <td>1634</td>\n      <td>0.100</td>\n      <td>0.068</td>\n      <td>0.132</td>\n      <td>1634</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>likert turn</td>\n      <td>consistent</td>\n      <td>0.201</td>\n      <td>0.144</td>\n      <td>0.248</td>\n      <td>1634</td>\n      <td>0.083</td>\n      <td>0.053</td>\n      <td>0.115</td>\n      <td>1634</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>likert turn</td>\n      <td>emotional</td>\n      <td>0.166</td>\n      <td>0.119</td>\n      <td>0.218</td>\n      <td>1634</td>\n      <td>0.021</td>\n      <td>-0.009</td>\n      <td>0.050</td>\n      <td>1634</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>likert dialogue</td>\n      <td>informative</td>\n      <td>0.409</td>\n      <td>0.255</td>\n      <td>0.531</td>\n      <td>108</td>\n      <td>0.031</td>\n      <td>-0.072</td>\n      <td>0.160</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>likert dialogue</td>\n      <td>consistent</td>\n      <td>0.360</td>\n      <td>0.194</td>\n      <td>0.514</td>\n      <td>108</td>\n      <td>0.074</td>\n      <td>-0.024</td>\n      <td>0.197</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>likert dialogue</td>\n      <td>relevant</td>\n      <td>0.298</td>\n      <td>0.118</td>\n      <td>0.442</td>\n      <td>108</td>\n      <td>-0.003</td>\n      <td>-0.102</td>\n      <td>0.124</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>likert dialogue</td>\n      <td>quality</td>\n      <td>0.286</td>\n      <td>0.115</td>\n      <td>0.465</td>\n      <td>108</td>\n      <td>0.078</td>\n      <td>-0.035</td>\n      <td>0.204</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>likert dialogue</td>\n      <td>engaging</td>\n      <td>0.259</td>\n      <td>0.081</td>\n      <td>0.430</td>\n      <td>108</td>\n      <td>0.123</td>\n      <td>0.010</td>\n      <td>0.257</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>likert dialogue</td>\n      <td>emotional</td>\n      <td>0.256</td>\n      <td>0.091</td>\n      <td>0.411</td>\n      <td>108</td>\n      <td>0.046</td>\n      <td>-0.060</td>\n      <td>0.175</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>likert dialogue</td>\n      <td>proactive</td>\n      <td>0.243</td>\n      <td>0.069</td>\n      <td>0.411</td>\n      <td>108</td>\n      <td>-0.026</td>\n      <td>-0.118</td>\n      <td>0.094</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>likert dialogue</td>\n      <td>grammatical</td>\n      <td>0.132</td>\n      <td>-0.043</td>\n      <td>0.297</td>\n      <td>108</td>\n      <td>-0.058</td>\n      <td>-0.168</td>\n      <td>0.078</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>comparative</td>\n      <td>consistent</td>\n      <td>0.484</td>\n      <td>0.308</td>\n      <td>0.648</td>\n      <td>108</td>\n      <td>0.481</td>\n      <td>0.315</td>\n      <td>0.647</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>comparative</td>\n      <td>quality</td>\n      <td>0.447</td>\n      <td>0.300</td>\n      <td>0.631</td>\n      <td>108</td>\n      <td>0.444</td>\n      <td>0.277</td>\n      <td>0.611</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>comparative</td>\n      <td>relevant</td>\n      <td>0.418</td>\n      <td>0.231</td>\n      <td>0.583</td>\n      <td>108</td>\n      <td>0.392</td>\n      <td>0.225</td>\n      <td>0.548</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>comparative</td>\n      <td>proactive</td>\n      <td>0.226</td>\n      <td>0.053</td>\n      <td>0.410</td>\n      <td>108</td>\n      <td>0.222</td>\n      <td>0.054</td>\n      <td>0.420</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>comparative</td>\n      <td>grammatical</td>\n      <td>0.215</td>\n      <td>0.030</td>\n      <td>0.389</td>\n      <td>108</td>\n      <td>0.024</td>\n      <td>-0.087</td>\n      <td>0.166</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>comparative</td>\n      <td>informative</td>\n      <td>0.209</td>\n      <td>0.030</td>\n      <td>0.388</td>\n      <td>108</td>\n      <td>0.200</td>\n      <td>0.027</td>\n      <td>0.385</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>comparative</td>\n      <td>emotional</td>\n      <td>0.202</td>\n      <td>0.032</td>\n      <td>0.385</td>\n      <td>108</td>\n      <td>0.074</td>\n      <td>-0.047</td>\n      <td>0.231</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>comparative</td>\n      <td>engaging</td>\n      <td>0.115</td>\n      <td>-0.069</td>\n      <td>0.293</td>\n      <td>108</td>\n      <td>0.111</td>\n      <td>-0.088</td>\n      <td>0.312</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>behavior</td>\n      <td>topic switch</td>\n      <td>0.755</td>\n      <td>0.715</td>\n      <td>0.792</td>\n      <td>1634</td>\n      <td>0.755</td>\n      <td>0.713</td>\n      <td>0.793</td>\n      <td>1634</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>behavior</td>\n      <td>incorrect fact</td>\n      <td>0.652</td>\n      <td>0.577</td>\n      <td>0.716</td>\n      <td>1634</td>\n      <td>0.651</td>\n      <td>0.578</td>\n      <td>0.720</td>\n      <td>1634</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>behavior</td>\n      <td>life info</td>\n      <td>0.631</td>\n      <td>0.588</td>\n      <td>0.675</td>\n      <td>1634</td>\n      <td>0.631</td>\n      <td>0.590</td>\n      <td>0.673</td>\n      <td>1634</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>behavior</td>\n      <td>correct fact</td>\n      <td>0.618</td>\n      <td>0.567</td>\n      <td>0.662</td>\n      <td>1634</td>\n      <td>0.618</td>\n      <td>0.570</td>\n      <td>0.661</td>\n      <td>1634</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>behavior</td>\n      <td>ignore</td>\n      <td>0.571</td>\n      <td>0.506</td>\n      <td>0.640</td>\n      <td>1634</td>\n      <td>0.571</td>\n      <td>0.505</td>\n      <td>0.632</td>\n      <td>1634</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>behavior</td>\n      <td>antisocial</td>\n      <td>0.553</td>\n      <td>0.172</td>\n      <td>0.799</td>\n      <td>1634</td>\n      <td>0.553</td>\n      <td>0.248</td>\n      <td>0.833</td>\n      <td>1634</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>behavior</td>\n      <td>redundant</td>\n      <td>0.551</td>\n      <td>0.472</td>\n      <td>0.629</td>\n      <td>1634</td>\n      <td>0.551</td>\n      <td>0.474</td>\n      <td>0.616</td>\n      <td>1634</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>behavior</td>\n      <td>empathetic</td>\n      <td>0.514</td>\n      <td>0.469</td>\n      <td>0.554</td>\n      <td>1634</td>\n      <td>0.513</td>\n      <td>0.473</td>\n      <td>0.557</td>\n      <td>1634</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>behavior</td>\n      <td>follow up</td>\n      <td>0.492</td>\n      <td>0.450</td>\n      <td>0.536</td>\n      <td>1634</td>\n      <td>0.492</td>\n      <td>0.448</td>\n      <td>0.531</td>\n      <td>1634</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>behavior</td>\n      <td>preference info</td>\n      <td>0.491</td>\n      <td>0.451</td>\n      <td>0.541</td>\n      <td>1634</td>\n      <td>0.491</td>\n      <td>0.445</td>\n      <td>0.534</td>\n      <td>1634</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>behavior</td>\n      <td>irrelevant</td>\n      <td>0.456</td>\n      <td>0.399</td>\n      <td>0.513</td>\n      <td>1634</td>\n      <td>0.456</td>\n      <td>0.394</td>\n      <td>0.509</td>\n      <td>1634</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>behavior</td>\n      <td>commonsense contradiction</td>\n      <td>0.442</td>\n      <td>0.388</td>\n      <td>0.495</td>\n      <td>1634</td>\n      <td>0.442</td>\n      <td>0.387</td>\n      <td>0.496</td>\n      <td>1634</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>behavior</td>\n      <td>partner contradiction</td>\n      <td>0.436</td>\n      <td>0.363</td>\n      <td>0.506</td>\n      <td>1634</td>\n      <td>0.436</td>\n      <td>0.361</td>\n      <td>0.505</td>\n      <td>1634</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>behavior</td>\n      <td>lack of empathy</td>\n      <td>0.435</td>\n      <td>0.373</td>\n      <td>0.499</td>\n      <td>1634</td>\n      <td>0.435</td>\n      <td>0.377</td>\n      <td>0.497</td>\n      <td>1634</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>behavior</td>\n      <td>self contradiction</td>\n      <td>0.407</td>\n      <td>0.330</td>\n      <td>0.502</td>\n      <td>1634</td>\n      <td>0.406</td>\n      <td>0.322</td>\n      <td>0.499</td>\n      <td>1634</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>behavior</td>\n      <td>uninterpretable</td>\n      <td>0.137</td>\n      <td>0.030</td>\n      <td>0.319</td>\n      <td>1634</td>\n      <td>0.137</td>\n      <td>0.030</td>\n      <td>0.308</td>\n      <td>1634</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agreements = agreement_dataframe(\n",
    "    surge_annotations, load='results/surge_agreements.csv'\n",
    ")\n",
    "agreements = prettify(agreements, float_prec=3, sort_by=[\"category\", \"Krippendorff's alpha\"], col_types={\"n\": int, \"n.1\": int}, to_csv='results/paper/surge_agreements.csv', index=False)\n",
    "agreements"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "    round     category            label  Krippendorff's alpha  CI low  \\\n92      2  likert turn      grammatical                 0.419   0.372   \n95      2  likert turn          quality                 0.312   0.267   \n91      2  likert turn         engaging                 0.295   0.246   \n94      2  likert turn        proactive                 0.279   0.232   \n93      2  likert turn      informative                 0.278   0.233   \n..    ...          ...              ...                   ...     ...   \n6       0  comparative      informative                 0.361  -0.193   \n9       0  comparative         relevant                 0.361  -0.178   \n3       0  comparative        emotional                 0.216  -0.315   \n1       0     behavior  uninterpretable                 0.322     NaN   \n0       0     behavior       antisocial                   NaN     NaN   \n\n    CI high     n  Fleiss' kappa  CI low.1  CI high.1   n.1  \n92    0.464  1634          0.296     0.259      0.333  1634  \n95    0.357  1634          0.092     0.061      0.122  1634  \n91    0.344  1634          0.123     0.092      0.153  1634  \n94    0.327  1634          0.098     0.071      0.125  1634  \n93    0.321  1634          0.092     0.065      0.123  1634  \n..      ...   ...            ...       ...        ...   ...  \n6     0.839    12          0.333    -0.175      0.832    12  \n9     0.839    12          0.333    -0.244      0.832    12  \n3     0.799    12          0.127    -0.274      0.678    12  \n1       NaN   152          0.320       NaN        NaN   152  \n0       NaN   233            NaN       NaN        NaN   233  \n\n[97 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>round</th>\n      <th>category</th>\n      <th>label</th>\n      <th>Krippendorff's alpha</th>\n      <th>CI low</th>\n      <th>CI high</th>\n      <th>n</th>\n      <th>Fleiss' kappa</th>\n      <th>CI low.1</th>\n      <th>CI high.1</th>\n      <th>n.1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>92</th>\n      <td>2</td>\n      <td>likert turn</td>\n      <td>grammatical</td>\n      <td>0.419</td>\n      <td>0.372</td>\n      <td>0.464</td>\n      <td>1634</td>\n      <td>0.296</td>\n      <td>0.259</td>\n      <td>0.333</td>\n      <td>1634</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>2</td>\n      <td>likert turn</td>\n      <td>quality</td>\n      <td>0.312</td>\n      <td>0.267</td>\n      <td>0.357</td>\n      <td>1634</td>\n      <td>0.092</td>\n      <td>0.061</td>\n      <td>0.122</td>\n      <td>1634</td>\n    </tr>\n    <tr>\n      <th>91</th>\n      <td>2</td>\n      <td>likert turn</td>\n      <td>engaging</td>\n      <td>0.295</td>\n      <td>0.246</td>\n      <td>0.344</td>\n      <td>1634</td>\n      <td>0.123</td>\n      <td>0.092</td>\n      <td>0.153</td>\n      <td>1634</td>\n    </tr>\n    <tr>\n      <th>94</th>\n      <td>2</td>\n      <td>likert turn</td>\n      <td>proactive</td>\n      <td>0.279</td>\n      <td>0.232</td>\n      <td>0.327</td>\n      <td>1634</td>\n      <td>0.098</td>\n      <td>0.071</td>\n      <td>0.125</td>\n      <td>1634</td>\n    </tr>\n    <tr>\n      <th>93</th>\n      <td>2</td>\n      <td>likert turn</td>\n      <td>informative</td>\n      <td>0.278</td>\n      <td>0.233</td>\n      <td>0.321</td>\n      <td>1634</td>\n      <td>0.092</td>\n      <td>0.065</td>\n      <td>0.123</td>\n      <td>1634</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0</td>\n      <td>comparative</td>\n      <td>informative</td>\n      <td>0.361</td>\n      <td>-0.193</td>\n      <td>0.839</td>\n      <td>12</td>\n      <td>0.333</td>\n      <td>-0.175</td>\n      <td>0.832</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0</td>\n      <td>comparative</td>\n      <td>relevant</td>\n      <td>0.361</td>\n      <td>-0.178</td>\n      <td>0.839</td>\n      <td>12</td>\n      <td>0.333</td>\n      <td>-0.244</td>\n      <td>0.832</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>comparative</td>\n      <td>emotional</td>\n      <td>0.216</td>\n      <td>-0.315</td>\n      <td>0.799</td>\n      <td>12</td>\n      <td>0.127</td>\n      <td>-0.274</td>\n      <td>0.678</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>behavior</td>\n      <td>uninterpretable</td>\n      <td>0.322</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>152</td>\n      <td>0.320</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>152</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>behavior</td>\n      <td>antisocial</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>233</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>233</td>\n    </tr>\n  </tbody>\n</table>\n<p>97 rows Ã— 11 columns</p>\n</div>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_agreements = across_evaluations(\n",
    "    [\n",
    "        e.annotation_dataframe() for e in\n",
    "        (data.student_evaluation, data.mturk_evaluation, data.surge_evaluation)\n",
    "    ],\n",
    "    agreement_dataframe,\n",
    "    load='results/evaluation_agreements.csv'\n",
    ")\n",
    "all_agreements = prettify(all_agreements, float_prec=3, sort_by=[\"round\", \"category\", \"Krippendorff's alpha\"], col_types={\"n\": int, \"n.1\": int}, to_csv='results/paper/all_agreements.csv', index=False)\n",
    "all_agreements"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 7 Comprehensive Analysis"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Likert Dialogue"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "def evaluate_likert_ratings(annotations, category, load=None, reload=None):\n",
    "    if load:\n",
    "        return pd.read_csv(load)\n",
    "    single_annotated = get_singly_annotated(annotations)\n",
    "    likert_annotations = single_annotated.xs(category, level=sym.category)\n",
    "    label_groups = likert_annotations.groupby(level=[sym.bot, sym.label])\n",
    "    means = label_groups.apply(mean_and_ci)\n",
    "    if reload:\n",
    "        means.to_csv(reload)\n",
    "    return means"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "                 bot        label  mean  CI low  CI high    n\n28    rerank_blender  informative  3.94   3.751    4.129  100\n26    rerank_blender     engaging  3.87   3.662    4.078  100\n29    rerank_blender    proactive  3.82   3.616    4.024  100\n25    rerank_blender    emotional  3.81   3.601    4.019  100\n24    rerank_blender   consistent  3.67   3.432    3.908  100\n31    rerank_blender     relevant  3.60   3.387    3.813  100\n27    rerank_blender  grammatical  3.47   3.251    3.689  100\n30    rerank_blender      quality  3.23   3.031    3.429  100\n19             emora  grammatical  4.02   3.871    4.169  100\n21             emora    proactive  3.94   3.745    4.135  100\n16             emora   consistent  3.91   3.682    4.138  100\n18             emora     engaging  3.75   3.573    3.927  100\n17             emora    emotional  3.61   3.394    3.826  100\n20             emora  informative  3.52   3.357    3.683  100\n23             emora     relevant  3.51   3.318    3.702  100\n22             emora      quality  3.42   3.268    3.572  100\n9        blender2_3B    emotional  4.34   4.177    4.503  100\n11       blender2_3B  grammatical  4.21   4.040    4.380  100\n15       blender2_3B     relevant  4.04   3.851    4.229  100\n10       blender2_3B     engaging  3.96   3.784    4.136  100\n13       blender2_3B    proactive  3.84   3.651    4.029  100\n12       blender2_3B  informative  3.68   3.489    3.871  100\n14       blender2_3B      quality  3.59   3.401    3.779  100\n8        blender2_3B   consistent  3.48   3.207    3.753  100\n4   bart_fid_rag_bcb  informative  3.83   3.645    4.015  100\n3   bart_fid_rag_bcb  grammatical  3.78   3.598    3.962  100\n7   bart_fid_rag_bcb     relevant  3.60   3.367    3.833  100\n1   bart_fid_rag_bcb    emotional  3.56   3.319    3.801  100\n2   bart_fid_rag_bcb     engaging  3.23   2.994    3.466  100\n0   bart_fid_rag_bcb   consistent  3.03   2.745    3.315  100\n6   bart_fid_rag_bcb      quality  3.00   2.813    3.187  100\n5   bart_fid_rag_bcb    proactive  2.88   2.656    3.104  100",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bot</th>\n      <th>label</th>\n      <th>mean</th>\n      <th>CI low</th>\n      <th>CI high</th>\n      <th>n</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>28</th>\n      <td>rerank_blender</td>\n      <td>informative</td>\n      <td>3.94</td>\n      <td>3.751</td>\n      <td>4.129</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>rerank_blender</td>\n      <td>engaging</td>\n      <td>3.87</td>\n      <td>3.662</td>\n      <td>4.078</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>rerank_blender</td>\n      <td>proactive</td>\n      <td>3.82</td>\n      <td>3.616</td>\n      <td>4.024</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>rerank_blender</td>\n      <td>emotional</td>\n      <td>3.81</td>\n      <td>3.601</td>\n      <td>4.019</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>rerank_blender</td>\n      <td>consistent</td>\n      <td>3.67</td>\n      <td>3.432</td>\n      <td>3.908</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>rerank_blender</td>\n      <td>relevant</td>\n      <td>3.60</td>\n      <td>3.387</td>\n      <td>3.813</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>rerank_blender</td>\n      <td>grammatical</td>\n      <td>3.47</td>\n      <td>3.251</td>\n      <td>3.689</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>rerank_blender</td>\n      <td>quality</td>\n      <td>3.23</td>\n      <td>3.031</td>\n      <td>3.429</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>emora</td>\n      <td>grammatical</td>\n      <td>4.02</td>\n      <td>3.871</td>\n      <td>4.169</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>emora</td>\n      <td>proactive</td>\n      <td>3.94</td>\n      <td>3.745</td>\n      <td>4.135</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>emora</td>\n      <td>consistent</td>\n      <td>3.91</td>\n      <td>3.682</td>\n      <td>4.138</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>emora</td>\n      <td>engaging</td>\n      <td>3.75</td>\n      <td>3.573</td>\n      <td>3.927</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>emora</td>\n      <td>emotional</td>\n      <td>3.61</td>\n      <td>3.394</td>\n      <td>3.826</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>emora</td>\n      <td>informative</td>\n      <td>3.52</td>\n      <td>3.357</td>\n      <td>3.683</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>emora</td>\n      <td>relevant</td>\n      <td>3.51</td>\n      <td>3.318</td>\n      <td>3.702</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>emora</td>\n      <td>quality</td>\n      <td>3.42</td>\n      <td>3.268</td>\n      <td>3.572</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>blender2_3B</td>\n      <td>emotional</td>\n      <td>4.34</td>\n      <td>4.177</td>\n      <td>4.503</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>blender2_3B</td>\n      <td>grammatical</td>\n      <td>4.21</td>\n      <td>4.040</td>\n      <td>4.380</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>blender2_3B</td>\n      <td>relevant</td>\n      <td>4.04</td>\n      <td>3.851</td>\n      <td>4.229</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>blender2_3B</td>\n      <td>engaging</td>\n      <td>3.96</td>\n      <td>3.784</td>\n      <td>4.136</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>blender2_3B</td>\n      <td>proactive</td>\n      <td>3.84</td>\n      <td>3.651</td>\n      <td>4.029</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>blender2_3B</td>\n      <td>informative</td>\n      <td>3.68</td>\n      <td>3.489</td>\n      <td>3.871</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>blender2_3B</td>\n      <td>quality</td>\n      <td>3.59</td>\n      <td>3.401</td>\n      <td>3.779</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>blender2_3B</td>\n      <td>consistent</td>\n      <td>3.48</td>\n      <td>3.207</td>\n      <td>3.753</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>bart_fid_rag_bcb</td>\n      <td>informative</td>\n      <td>3.83</td>\n      <td>3.645</td>\n      <td>4.015</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>bart_fid_rag_bcb</td>\n      <td>grammatical</td>\n      <td>3.78</td>\n      <td>3.598</td>\n      <td>3.962</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>bart_fid_rag_bcb</td>\n      <td>relevant</td>\n      <td>3.60</td>\n      <td>3.367</td>\n      <td>3.833</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>bart_fid_rag_bcb</td>\n      <td>emotional</td>\n      <td>3.56</td>\n      <td>3.319</td>\n      <td>3.801</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>bart_fid_rag_bcb</td>\n      <td>engaging</td>\n      <td>3.23</td>\n      <td>2.994</td>\n      <td>3.466</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>bart_fid_rag_bcb</td>\n      <td>consistent</td>\n      <td>3.03</td>\n      <td>2.745</td>\n      <td>3.315</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>bart_fid_rag_bcb</td>\n      <td>quality</td>\n      <td>3.00</td>\n      <td>2.813</td>\n      <td>3.187</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>bart_fid_rag_bcb</td>\n      <td>proactive</td>\n      <td>2.88</td>\n      <td>2.656</td>\n      <td>3.104</td>\n      <td>100</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surge_likert_dialogue_ratings = evaluate_likert_ratings(\n",
    "    surge_annotations, category.likert_dialogue,\n",
    "    load='results/surge_likert_dialogue_ratings.csv'\n",
    ")\n",
    "sldr = prettify(surge_likert_dialogue_ratings, float_prec=3, col_types={\"n\": int}, sort_by=[\"bot\", \"mean\"], to_csv=\"results/paper/surge_likert_dialogue_ratings.csv\", index=False)\n",
    "sldr"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Likert Turn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "                 bot        label   mean  CI low  CI high     n\n25    rerank_blender    emotional  4.213   4.160    4.265  1500\n24    rerank_blender   consistent  4.034   3.972    4.096  1500\n27    rerank_blender  grammatical  4.000   3.946    4.054  1500\n26    rerank_blender     engaging  3.823   3.762    3.885  1500\n31    rerank_blender     relevant  3.741   3.675    3.806  1500\n28    rerank_blender  informative  3.728   3.673    3.783  1500\n29    rerank_blender    proactive  3.644   3.582    3.706  1500\n30    rerank_blender      quality  3.318   3.258    3.378  1500\n19             emora  grammatical  4.533   4.499    4.567  1522\n16             emora   consistent  4.140   4.081    4.199  1522\n17             emora    emotional  3.973   3.918    4.028  1522\n18             emora     engaging  3.879   3.823    3.936  1522\n23             emora     relevant  3.797   3.731    3.863  1522\n21             emora    proactive  3.760   3.702    3.819  1522\n22             emora      quality  3.521   3.459    3.583  1522\n20             emora  informative  3.194   3.133    3.254  1522\n11       blender2_3B  grammatical  4.646   4.610    4.683  1524\n9        blender2_3B    emotional  4.220   4.169    4.270  1524\n15       blender2_3B     relevant  4.190   4.130    4.249  1524\n8        blender2_3B   consistent  4.089   4.026    4.151  1524\n10       blender2_3B     engaging  3.958   3.901    4.015  1524\n14       blender2_3B      quality  3.808   3.748    3.868  1524\n13       blender2_3B    proactive  3.575   3.519    3.632  1524\n12       blender2_3B  informative  3.440   3.389    3.492  1524\n3   bart_fid_rag_bcb  grammatical  4.311   4.263    4.358  1512\n1   bart_fid_rag_bcb    emotional  4.024   3.963    4.084  1512\n0   bart_fid_rag_bcb   consistent  3.936   3.867    4.005  1512\n7   bart_fid_rag_bcb     relevant  3.896   3.827    3.964  1512\n4   bart_fid_rag_bcb  informative  3.796   3.742    3.849  1512\n2   bart_fid_rag_bcb     engaging  3.621   3.553    3.689  1512\n6   bart_fid_rag_bcb      quality  3.343   3.277    3.410  1512\n5   bart_fid_rag_bcb    proactive  2.946   2.886    3.006  1512",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bot</th>\n      <th>label</th>\n      <th>mean</th>\n      <th>CI low</th>\n      <th>CI high</th>\n      <th>n</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>25</th>\n      <td>rerank_blender</td>\n      <td>emotional</td>\n      <td>4.213</td>\n      <td>4.160</td>\n      <td>4.265</td>\n      <td>1500</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>rerank_blender</td>\n      <td>consistent</td>\n      <td>4.034</td>\n      <td>3.972</td>\n      <td>4.096</td>\n      <td>1500</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>rerank_blender</td>\n      <td>grammatical</td>\n      <td>4.000</td>\n      <td>3.946</td>\n      <td>4.054</td>\n      <td>1500</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>rerank_blender</td>\n      <td>engaging</td>\n      <td>3.823</td>\n      <td>3.762</td>\n      <td>3.885</td>\n      <td>1500</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>rerank_blender</td>\n      <td>relevant</td>\n      <td>3.741</td>\n      <td>3.675</td>\n      <td>3.806</td>\n      <td>1500</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>rerank_blender</td>\n      <td>informative</td>\n      <td>3.728</td>\n      <td>3.673</td>\n      <td>3.783</td>\n      <td>1500</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>rerank_blender</td>\n      <td>proactive</td>\n      <td>3.644</td>\n      <td>3.582</td>\n      <td>3.706</td>\n      <td>1500</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>rerank_blender</td>\n      <td>quality</td>\n      <td>3.318</td>\n      <td>3.258</td>\n      <td>3.378</td>\n      <td>1500</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>emora</td>\n      <td>grammatical</td>\n      <td>4.533</td>\n      <td>4.499</td>\n      <td>4.567</td>\n      <td>1522</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>emora</td>\n      <td>consistent</td>\n      <td>4.140</td>\n      <td>4.081</td>\n      <td>4.199</td>\n      <td>1522</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>emora</td>\n      <td>emotional</td>\n      <td>3.973</td>\n      <td>3.918</td>\n      <td>4.028</td>\n      <td>1522</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>emora</td>\n      <td>engaging</td>\n      <td>3.879</td>\n      <td>3.823</td>\n      <td>3.936</td>\n      <td>1522</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>emora</td>\n      <td>relevant</td>\n      <td>3.797</td>\n      <td>3.731</td>\n      <td>3.863</td>\n      <td>1522</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>emora</td>\n      <td>proactive</td>\n      <td>3.760</td>\n      <td>3.702</td>\n      <td>3.819</td>\n      <td>1522</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>emora</td>\n      <td>quality</td>\n      <td>3.521</td>\n      <td>3.459</td>\n      <td>3.583</td>\n      <td>1522</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>emora</td>\n      <td>informative</td>\n      <td>3.194</td>\n      <td>3.133</td>\n      <td>3.254</td>\n      <td>1522</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>blender2_3B</td>\n      <td>grammatical</td>\n      <td>4.646</td>\n      <td>4.610</td>\n      <td>4.683</td>\n      <td>1524</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>blender2_3B</td>\n      <td>emotional</td>\n      <td>4.220</td>\n      <td>4.169</td>\n      <td>4.270</td>\n      <td>1524</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>blender2_3B</td>\n      <td>relevant</td>\n      <td>4.190</td>\n      <td>4.130</td>\n      <td>4.249</td>\n      <td>1524</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>blender2_3B</td>\n      <td>consistent</td>\n      <td>4.089</td>\n      <td>4.026</td>\n      <td>4.151</td>\n      <td>1524</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>blender2_3B</td>\n      <td>engaging</td>\n      <td>3.958</td>\n      <td>3.901</td>\n      <td>4.015</td>\n      <td>1524</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>blender2_3B</td>\n      <td>quality</td>\n      <td>3.808</td>\n      <td>3.748</td>\n      <td>3.868</td>\n      <td>1524</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>blender2_3B</td>\n      <td>proactive</td>\n      <td>3.575</td>\n      <td>3.519</td>\n      <td>3.632</td>\n      <td>1524</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>blender2_3B</td>\n      <td>informative</td>\n      <td>3.440</td>\n      <td>3.389</td>\n      <td>3.492</td>\n      <td>1524</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>bart_fid_rag_bcb</td>\n      <td>grammatical</td>\n      <td>4.311</td>\n      <td>4.263</td>\n      <td>4.358</td>\n      <td>1512</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>bart_fid_rag_bcb</td>\n      <td>emotional</td>\n      <td>4.024</td>\n      <td>3.963</td>\n      <td>4.084</td>\n      <td>1512</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>bart_fid_rag_bcb</td>\n      <td>consistent</td>\n      <td>3.936</td>\n      <td>3.867</td>\n      <td>4.005</td>\n      <td>1512</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>bart_fid_rag_bcb</td>\n      <td>relevant</td>\n      <td>3.896</td>\n      <td>3.827</td>\n      <td>3.964</td>\n      <td>1512</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>bart_fid_rag_bcb</td>\n      <td>informative</td>\n      <td>3.796</td>\n      <td>3.742</td>\n      <td>3.849</td>\n      <td>1512</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>bart_fid_rag_bcb</td>\n      <td>engaging</td>\n      <td>3.621</td>\n      <td>3.553</td>\n      <td>3.689</td>\n      <td>1512</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>bart_fid_rag_bcb</td>\n      <td>quality</td>\n      <td>3.343</td>\n      <td>3.277</td>\n      <td>3.410</td>\n      <td>1512</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>bart_fid_rag_bcb</td>\n      <td>proactive</td>\n      <td>2.946</td>\n      <td>2.886</td>\n      <td>3.006</td>\n      <td>1512</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surge_likert_turn_ratings = evaluate_likert_ratings(\n",
    "    surge_annotations, category.likert_turn,\n",
    "    load='results/surge_likert_turn_ratings.csv'\n",
    ")\n",
    "sltr = prettify(surge_likert_turn_ratings, float_prec=3, col_types={\"n\": int}, sort_by=[\"bot\", \"mean\"], to_csv=\"results/paper/surge_likert_turn_ratings.csv\", index=False)\n",
    "sltr"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Comparative"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "                                           lose    CI low   CI high      n  \\\nbot              bot comp label                                              \nbart_fid_rag_bcb others   consistent   0.594059  0.496550  0.684676  101.0   \n                          emotional    0.603960  0.506457  0.693846  101.0   \n                          engaging     0.643564  0.546475  0.730133  101.0   \n                          grammatical  0.425743  0.333777  0.523150  101.0   \n                          informative  0.405941  0.315324  0.503450  101.0   \n...                                         ...       ...       ...    ...   \nrerank_blender   emora    grammatical  0.393939  0.246831  0.563166   33.0   \n                          informative  0.303030  0.173755  0.473381   33.0   \n                          proactive    0.393939  0.246831  0.563166   33.0   \n                          quality      0.454545  0.298429  0.620141   33.0   \n                          relevant     0.484848  0.325040  0.647816   33.0   \n\n                                            tie        CI low   CI high  \\\nbot              bot comp label                                           \nbart_fid_rag_bcb others   consistent   0.000000  3.469447e-18  0.036641   \n                          emotional    0.069307  3.397533e-02  0.136200   \n                          engaging     0.009901  1.749911e-03  0.053967   \n                          grammatical  0.178218  1.158107e-01  0.264206   \n                          informative  0.000000  3.469447e-18  0.036641   \n...                                         ...           ...       ...   \nrerank_blender   emora    grammatical  0.090909  3.140394e-02  0.235726   \n                          informative  0.000000  0.000000e+00  0.104270   \n                          proactive    0.000000  0.000000e+00  0.104270   \n                          quality      0.000000  0.000000e+00  0.104270   \n                          relevant     0.090909  3.140394e-02  0.235726   \n\n                                           n       win    CI low   CI high  \\\nbot              bot comp label                                              \nbart_fid_rag_bcb others   consistent   101.0  0.405941  0.315324  0.503450   \n                          emotional    101.0  0.326733  0.243079  0.423084   \n                          engaging     101.0  0.346535  0.260895  0.443420   \n                          grammatical  101.0  0.396040  0.306154  0.493543   \n                          informative  101.0  0.594059  0.496550  0.684676   \n...                                      ...       ...       ...       ...   \nrerank_blender   emora    grammatical   33.0  0.515152  0.352184  0.674960   \n                          informative   33.0  0.696970  0.526619  0.826245   \n                          proactive     33.0  0.606061  0.436834  0.753169   \n                          quality       33.0  0.545455  0.379859  0.701571   \n                          relevant      33.0  0.424242  0.272356  0.591927   \n\n                                           n  \nbot              bot comp label               \nbart_fid_rag_bcb others   consistent   101.0  \n                          emotional    101.0  \n                          engaging     101.0  \n                          grammatical  101.0  \n                          informative  101.0  \n...                                      ...  \nrerank_blender   emora    grammatical   33.0  \n                          informative   33.0  \n                          proactive     33.0  \n                          quality       33.0  \n                          relevant      33.0  \n\n[128 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>lose</th>\n      <th>CI low</th>\n      <th>CI high</th>\n      <th>n</th>\n      <th>tie</th>\n      <th>CI low</th>\n      <th>CI high</th>\n      <th>n</th>\n      <th>win</th>\n      <th>CI low</th>\n      <th>CI high</th>\n      <th>n</th>\n    </tr>\n    <tr>\n      <th>bot</th>\n      <th>bot comp</th>\n      <th>label</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">bart_fid_rag_bcb</th>\n      <th rowspan=\"5\" valign=\"top\">others</th>\n      <th>consistent</th>\n      <td>0.594059</td>\n      <td>0.496550</td>\n      <td>0.684676</td>\n      <td>101.0</td>\n      <td>0.000000</td>\n      <td>3.469447e-18</td>\n      <td>0.036641</td>\n      <td>101.0</td>\n      <td>0.405941</td>\n      <td>0.315324</td>\n      <td>0.503450</td>\n      <td>101.0</td>\n    </tr>\n    <tr>\n      <th>emotional</th>\n      <td>0.603960</td>\n      <td>0.506457</td>\n      <td>0.693846</td>\n      <td>101.0</td>\n      <td>0.069307</td>\n      <td>3.397533e-02</td>\n      <td>0.136200</td>\n      <td>101.0</td>\n      <td>0.326733</td>\n      <td>0.243079</td>\n      <td>0.423084</td>\n      <td>101.0</td>\n    </tr>\n    <tr>\n      <th>engaging</th>\n      <td>0.643564</td>\n      <td>0.546475</td>\n      <td>0.730133</td>\n      <td>101.0</td>\n      <td>0.009901</td>\n      <td>1.749911e-03</td>\n      <td>0.053967</td>\n      <td>101.0</td>\n      <td>0.346535</td>\n      <td>0.260895</td>\n      <td>0.443420</td>\n      <td>101.0</td>\n    </tr>\n    <tr>\n      <th>grammatical</th>\n      <td>0.425743</td>\n      <td>0.333777</td>\n      <td>0.523150</td>\n      <td>101.0</td>\n      <td>0.178218</td>\n      <td>1.158107e-01</td>\n      <td>0.264206</td>\n      <td>101.0</td>\n      <td>0.396040</td>\n      <td>0.306154</td>\n      <td>0.493543</td>\n      <td>101.0</td>\n    </tr>\n    <tr>\n      <th>informative</th>\n      <td>0.405941</td>\n      <td>0.315324</td>\n      <td>0.503450</td>\n      <td>101.0</td>\n      <td>0.000000</td>\n      <td>3.469447e-18</td>\n      <td>0.036641</td>\n      <td>101.0</td>\n      <td>0.594059</td>\n      <td>0.496550</td>\n      <td>0.684676</td>\n      <td>101.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">rerank_blender</th>\n      <th rowspan=\"5\" valign=\"top\">emora</th>\n      <th>grammatical</th>\n      <td>0.393939</td>\n      <td>0.246831</td>\n      <td>0.563166</td>\n      <td>33.0</td>\n      <td>0.090909</td>\n      <td>3.140394e-02</td>\n      <td>0.235726</td>\n      <td>33.0</td>\n      <td>0.515152</td>\n      <td>0.352184</td>\n      <td>0.674960</td>\n      <td>33.0</td>\n    </tr>\n    <tr>\n      <th>informative</th>\n      <td>0.303030</td>\n      <td>0.173755</td>\n      <td>0.473381</td>\n      <td>33.0</td>\n      <td>0.000000</td>\n      <td>0.000000e+00</td>\n      <td>0.104270</td>\n      <td>33.0</td>\n      <td>0.696970</td>\n      <td>0.526619</td>\n      <td>0.826245</td>\n      <td>33.0</td>\n    </tr>\n    <tr>\n      <th>proactive</th>\n      <td>0.393939</td>\n      <td>0.246831</td>\n      <td>0.563166</td>\n      <td>33.0</td>\n      <td>0.000000</td>\n      <td>0.000000e+00</td>\n      <td>0.104270</td>\n      <td>33.0</td>\n      <td>0.606061</td>\n      <td>0.436834</td>\n      <td>0.753169</td>\n      <td>33.0</td>\n    </tr>\n    <tr>\n      <th>quality</th>\n      <td>0.454545</td>\n      <td>0.298429</td>\n      <td>0.620141</td>\n      <td>33.0</td>\n      <td>0.000000</td>\n      <td>0.000000e+00</td>\n      <td>0.104270</td>\n      <td>33.0</td>\n      <td>0.545455</td>\n      <td>0.379859</td>\n      <td>0.701571</td>\n      <td>33.0</td>\n    </tr>\n    <tr>\n      <th>relevant</th>\n      <td>0.484848</td>\n      <td>0.325040</td>\n      <td>0.647816</td>\n      <td>33.0</td>\n      <td>0.090909</td>\n      <td>3.140394e-02</td>\n      <td>0.235726</td>\n      <td>33.0</td>\n      <td>0.424242</td>\n      <td>0.272356</td>\n      <td>0.591927</td>\n      <td>33.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>128 rows Ã— 12 columns</p>\n</div>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_df = evaluate_comparisons(\n",
    "    surge_annotations_comparative,\n",
    "    reload='results/surge_comparisons.csv'\n",
    ")\n",
    "comparison_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Behaviors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "def evaluate_behavior_rates(annotations, load=None, reload=None):\n",
    "    if load:\n",
    "        return pd.read_csv(load)\n",
    "    single_annotated = get_singly_annotated(annotations)\n",
    "    behavior_annotations = single_annotated.xs(category.behavior, level=sym.category)\n",
    "    label_groups = behavior_annotations.groupby(level=[sym.bot, sym.label])\n",
    "    means = label_groups.apply(prop_and_ci)\n",
    "    if reload:\n",
    "        means.to_csv(reload)\n",
    "    return means"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "                 bot                  label  proportion  CI low  CI high     n\n51    rerank_blender             empathetic       0.435   0.410    0.460  1500\n52    rerank_blender              follow up       0.419   0.395    0.444  1500\n59    rerank_blender        preference info       0.309   0.286    0.333  1500\n62    rerank_blender           topic switch       0.253   0.231    0.275  1500\n57    rerank_blender              life info       0.248   0.227    0.270  1500\n..               ...                    ...         ...     ...      ...   ...\n7   bart_fid_rag_bcb             irrelevant       0.110   0.095    0.127  1512\n10  bart_fid_rag_bcb  partner contradiction       0.071   0.059    0.085  1512\n12  bart_fid_rag_bcb              redundant       0.054   0.044    0.067  1512\n15  bart_fid_rag_bcb        uninterpretable       0.013   0.008    0.020  1512\n0   bart_fid_rag_bcb             antisocial       0.001   0.000    0.005  1512\n\n[64 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bot</th>\n      <th>label</th>\n      <th>proportion</th>\n      <th>CI low</th>\n      <th>CI high</th>\n      <th>n</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>51</th>\n      <td>rerank_blender</td>\n      <td>empathetic</td>\n      <td>0.435</td>\n      <td>0.410</td>\n      <td>0.460</td>\n      <td>1500</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>rerank_blender</td>\n      <td>follow up</td>\n      <td>0.419</td>\n      <td>0.395</td>\n      <td>0.444</td>\n      <td>1500</td>\n    </tr>\n    <tr>\n      <th>59</th>\n      <td>rerank_blender</td>\n      <td>preference info</td>\n      <td>0.309</td>\n      <td>0.286</td>\n      <td>0.333</td>\n      <td>1500</td>\n    </tr>\n    <tr>\n      <th>62</th>\n      <td>rerank_blender</td>\n      <td>topic switch</td>\n      <td>0.253</td>\n      <td>0.231</td>\n      <td>0.275</td>\n      <td>1500</td>\n    </tr>\n    <tr>\n      <th>57</th>\n      <td>rerank_blender</td>\n      <td>life info</td>\n      <td>0.248</td>\n      <td>0.227</td>\n      <td>0.270</td>\n      <td>1500</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>bart_fid_rag_bcb</td>\n      <td>irrelevant</td>\n      <td>0.110</td>\n      <td>0.095</td>\n      <td>0.127</td>\n      <td>1512</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>bart_fid_rag_bcb</td>\n      <td>partner contradiction</td>\n      <td>0.071</td>\n      <td>0.059</td>\n      <td>0.085</td>\n      <td>1512</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>bart_fid_rag_bcb</td>\n      <td>redundant</td>\n      <td>0.054</td>\n      <td>0.044</td>\n      <td>0.067</td>\n      <td>1512</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>bart_fid_rag_bcb</td>\n      <td>uninterpretable</td>\n      <td>0.013</td>\n      <td>0.008</td>\n      <td>0.020</td>\n      <td>1512</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>bart_fid_rag_bcb</td>\n      <td>antisocial</td>\n      <td>0.001</td>\n      <td>0.000</td>\n      <td>0.005</td>\n      <td>1512</td>\n    </tr>\n  </tbody>\n</table>\n<p>64 rows Ã— 6 columns</p>\n</div>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surge_behavior_rates = evaluate_behavior_rates(\n",
    "    surge_annotations,\n",
    "    load='results/surge_behavior_rates.csv'\n",
    ")\n",
    "sbr = prettify(surge_behavior_rates,  float_prec=3, col_types={\"n\": int}, sort_by=[\"bot\", \"proportion\"], to_csv=\"results/paper/surge_behavior_rates.csv\", index=False)\n",
    "sbr"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 8 Evaluation Metric Assessment"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Metric Sensitivity"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "                 blender2_3B                              bart_fid_rag_bcb  \\\n            bart_fid_rag_bcb rerank_blender         emora   rerank_blender   \nlabel                                                                        \nconsistent      2.290061e-03   2.197885e-01  1.388456e-01     5.853083e-02   \nemotional       4.139807e-07   5.355396e-01  6.478246e-11     1.103209e-05   \nengaging        5.614051e-12   5.028687e-04  2.639131e-01     5.468836e-04   \ngrammatical     7.914763e-28   8.099546e-79  1.187915e-04     2.633456e-16   \ninformative     6.065964e-21   1.794372e-12  3.420261e-10     2.677746e-02   \nproactive       2.008863e-46   1.092394e-02  3.926743e-06     4.805952e-59   \nquality         5.923475e-23   1.155392e-28  7.456653e-09     5.091686e-01   \nrelevant        5.769259e-10   1.227384e-23  1.550348e-17     4.641161e-04   \n\n                          rerank_blender  \n                    emora          emora  \nlabel                                     \nconsistent   5.315727e-06   5.810403e-03  \nemotional    2.450326e-01   6.313702e-09  \nengaging     3.241704e-09   1.489727e-02  \ngrammatical  1.167584e-15   1.844604e-60  \ninformative  1.298270e-48   7.763857e-36  \nproactive    2.435305e-75   5.083990e-02  \nquality      2.123313e-05   2.374843e-07  \nrelevant     3.516089e-02   1.581233e-01  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th colspan=\"3\" halign=\"left\">blender2_3B</th>\n      <th colspan=\"2\" halign=\"left\">bart_fid_rag_bcb</th>\n      <th>rerank_blender</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>bart_fid_rag_bcb</th>\n      <th>rerank_blender</th>\n      <th>emora</th>\n      <th>rerank_blender</th>\n      <th>emora</th>\n      <th>emora</th>\n    </tr>\n    <tr>\n      <th>label</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>consistent</th>\n      <td>2.290061e-03</td>\n      <td>2.197885e-01</td>\n      <td>1.388456e-01</td>\n      <td>5.853083e-02</td>\n      <td>5.315727e-06</td>\n      <td>5.810403e-03</td>\n    </tr>\n    <tr>\n      <th>emotional</th>\n      <td>4.139807e-07</td>\n      <td>5.355396e-01</td>\n      <td>6.478246e-11</td>\n      <td>1.103209e-05</td>\n      <td>2.450326e-01</td>\n      <td>6.313702e-09</td>\n    </tr>\n    <tr>\n      <th>engaging</th>\n      <td>5.614051e-12</td>\n      <td>5.028687e-04</td>\n      <td>2.639131e-01</td>\n      <td>5.468836e-04</td>\n      <td>3.241704e-09</td>\n      <td>1.489727e-02</td>\n    </tr>\n    <tr>\n      <th>grammatical</th>\n      <td>7.914763e-28</td>\n      <td>8.099546e-79</td>\n      <td>1.187915e-04</td>\n      <td>2.633456e-16</td>\n      <td>1.167584e-15</td>\n      <td>1.844604e-60</td>\n    </tr>\n    <tr>\n      <th>informative</th>\n      <td>6.065964e-21</td>\n      <td>1.794372e-12</td>\n      <td>3.420261e-10</td>\n      <td>2.677746e-02</td>\n      <td>1.298270e-48</td>\n      <td>7.763857e-36</td>\n    </tr>\n    <tr>\n      <th>proactive</th>\n      <td>2.008863e-46</td>\n      <td>1.092394e-02</td>\n      <td>3.926743e-06</td>\n      <td>4.805952e-59</td>\n      <td>2.435305e-75</td>\n      <td>5.083990e-02</td>\n    </tr>\n    <tr>\n      <th>quality</th>\n      <td>5.923475e-23</td>\n      <td>1.155392e-28</td>\n      <td>7.456653e-09</td>\n      <td>5.091686e-01</td>\n      <td>2.123313e-05</td>\n      <td>2.374843e-07</td>\n    </tr>\n    <tr>\n      <th>relevant</th>\n      <td>5.769259e-10</td>\n      <td>1.227384e-23</td>\n      <td>1.550348e-17</td>\n      <td>4.641161e-04</td>\n      <td>3.516089e-02</td>\n      <td>1.581233e-01</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "def t_tests(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    :param df: (bot, data point) x 1 -> score\n",
    "    :return: p values of test on each bot pair (pd.Series)\n",
    "    \"\"\"\n",
    "    bots = set(df.index.get_level_values(0))\n",
    "    bot_pairs = list(combinations(bots, 2))\n",
    "    result = {}\n",
    "    for ba, bb in bot_pairs:\n",
    "        a = df.xs(ba).to_numpy().squeeze()\n",
    "        b = df.xs(bb).to_numpy().squeeze()\n",
    "        t, p = ttest_ind(a, b)\n",
    "        result[(ba, bb)] = p\n",
    "    result_series = pd.Series(result.values(), result)\n",
    "    return result_series\n",
    "\n",
    "get_singly_annotated(surge_annotations).xs(\n",
    "    category.likert_turn,\n",
    "    level=sym.category\n",
    ").groupby(\n",
    "    sym.label\n",
    ").apply(\n",
    "    t_tests\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Predictive Validity"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "           category                      label       score  \\\n0       likert turn                 consistent    0.437186   \n1       likert turn                  emotional    0.459415   \n2       likert turn                   engaging    0.364656   \n3       likert turn                grammatical   -0.038475   \n4       likert turn                informative   -0.024559   \n5       likert turn                  proactive    0.418151   \n6       likert turn                    quality    0.451505   \n7       likert turn                   relevant    0.411045   \n8          behavior                 antisocial    6.022125   \n9          behavior  commonsense contradiction   -3.765228   \n10         behavior               correct fact   -0.038283   \n11         behavior                 empathetic    1.637197   \n12         behavior                  follow up    0.507137   \n13         behavior                     ignore   -3.753254   \n14         behavior             incorrect fact   -1.406491   \n15         behavior                 irrelevant   -2.327845   \n16         behavior            lack of empathy   -2.699847   \n17         behavior                  life info    0.487967   \n18         behavior      partner contradiction   -5.722676   \n19         behavior            preference info    0.183520   \n20         behavior                  redundant   -3.761563   \n21         behavior         self contradiction   -3.830152   \n22         behavior               topic switch    0.036299   \n23         behavior            uninterpretable   -7.401468   \n24  likert dialogue                 consistent    0.810984   \n25  likert dialogue                  emotional    0.947239   \n26  likert dialogue                   engaging    1.568202   \n27  likert dialogue                grammatical    0.592631   \n28  likert dialogue                informative    0.988051   \n29  likert dialogue                  proactive    1.101919   \n30  likert dialogue                    quality  112.601055   \n31  likert dialogue                   relevant    1.183381   \n\n    McFadden's pseudo-R-squared  \n0                      0.008301  \n1                      0.010492  \n2                      0.009000  \n3                      0.000054  \n4                      0.000033  \n5                      0.011262  \n6                      0.009052  \n7                      0.010554  \n8                      0.001190  \n9                      0.024278  \n10                     0.000005  \n11                     0.012622  \n12                     0.001516  \n13                     0.015435  \n14                     0.003978  \n15                     0.009423  \n16                     0.013486  \n17                     0.000627  \n18                     0.023771  \n19                     0.000149  \n20                     0.007834  \n21                     0.009924  \n22                     0.000003  \n23                     0.004976  \n24                     0.103444  \n25                     0.098235  \n26                     0.195030  \n27                     0.033306  \n28                     0.078316  \n29                     0.127203  \n30                     1.000000  \n31                     0.128773  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>category</th>\n      <th>label</th>\n      <th>score</th>\n      <th>McFadden's pseudo-R-squared</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>likert turn</td>\n      <td>consistent</td>\n      <td>0.437186</td>\n      <td>0.008301</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>likert turn</td>\n      <td>emotional</td>\n      <td>0.459415</td>\n      <td>0.010492</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>likert turn</td>\n      <td>engaging</td>\n      <td>0.364656</td>\n      <td>0.009000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>likert turn</td>\n      <td>grammatical</td>\n      <td>-0.038475</td>\n      <td>0.000054</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>likert turn</td>\n      <td>informative</td>\n      <td>-0.024559</td>\n      <td>0.000033</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>likert turn</td>\n      <td>proactive</td>\n      <td>0.418151</td>\n      <td>0.011262</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>likert turn</td>\n      <td>quality</td>\n      <td>0.451505</td>\n      <td>0.009052</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>likert turn</td>\n      <td>relevant</td>\n      <td>0.411045</td>\n      <td>0.010554</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>behavior</td>\n      <td>antisocial</td>\n      <td>6.022125</td>\n      <td>0.001190</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>behavior</td>\n      <td>commonsense contradiction</td>\n      <td>-3.765228</td>\n      <td>0.024278</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>behavior</td>\n      <td>correct fact</td>\n      <td>-0.038283</td>\n      <td>0.000005</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>behavior</td>\n      <td>empathetic</td>\n      <td>1.637197</td>\n      <td>0.012622</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>behavior</td>\n      <td>follow up</td>\n      <td>0.507137</td>\n      <td>0.001516</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>behavior</td>\n      <td>ignore</td>\n      <td>-3.753254</td>\n      <td>0.015435</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>behavior</td>\n      <td>incorrect fact</td>\n      <td>-1.406491</td>\n      <td>0.003978</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>behavior</td>\n      <td>irrelevant</td>\n      <td>-2.327845</td>\n      <td>0.009423</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>behavior</td>\n      <td>lack of empathy</td>\n      <td>-2.699847</td>\n      <td>0.013486</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>behavior</td>\n      <td>life info</td>\n      <td>0.487967</td>\n      <td>0.000627</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>behavior</td>\n      <td>partner contradiction</td>\n      <td>-5.722676</td>\n      <td>0.023771</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>behavior</td>\n      <td>preference info</td>\n      <td>0.183520</td>\n      <td>0.000149</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>behavior</td>\n      <td>redundant</td>\n      <td>-3.761563</td>\n      <td>0.007834</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>behavior</td>\n      <td>self contradiction</td>\n      <td>-3.830152</td>\n      <td>0.009924</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>behavior</td>\n      <td>topic switch</td>\n      <td>0.036299</td>\n      <td>0.000003</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>behavior</td>\n      <td>uninterpretable</td>\n      <td>-7.401468</td>\n      <td>0.004976</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>likert dialogue</td>\n      <td>consistent</td>\n      <td>0.810984</td>\n      <td>0.103444</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>likert dialogue</td>\n      <td>emotional</td>\n      <td>0.947239</td>\n      <td>0.098235</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>likert dialogue</td>\n      <td>engaging</td>\n      <td>1.568202</td>\n      <td>0.195030</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>likert dialogue</td>\n      <td>grammatical</td>\n      <td>0.592631</td>\n      <td>0.033306</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>likert dialogue</td>\n      <td>informative</td>\n      <td>0.988051</td>\n      <td>0.078316</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>likert dialogue</td>\n      <td>proactive</td>\n      <td>1.101919</td>\n      <td>0.127203</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>likert dialogue</td>\n      <td>quality</td>\n      <td>112.601055</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>likert dialogue</td>\n      <td>relevant</td>\n      <td>1.183381</td>\n      <td>0.128773</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.miscmodels.ordinal_model import OrderedModel\n",
    "\n",
    "def regressions(df, quality_column_name=None):\n",
    "    \"\"\"\n",
    "    :param df: dialogue x (*features, quality) -> value\n",
    "    :return: *(coef, low, high), mcfadden r^2\n",
    "    \"\"\"\n",
    "    if not quality_column_name:\n",
    "        quality_column_name = df.columns[-1]\n",
    "    qualities = df[quality_column_name]\n",
    "    features = [f for f in df.columns if f != quality_column_name]\n",
    "    model = OrderedModel(qualities, df[features], distr='logit')\n",
    "    results = model.fit()\n",
    "    coefs = {f: results.params[f] for f in features}\n",
    "    prsqrd = results.prsquared\n",
    "    result = {**coefs, stat.mcfad_r2: prsqrd}\n",
    "    return pd.Series(result.values(), result)\n",
    "\n",
    "def dialogue_metrics(ev):\n",
    "    df: pd.DataFrame = ev.annotation_dataframe()\n",
    "    df = get_singly_annotated(df, seed=123)\n",
    "    reindexed = df.reset_index()\n",
    "    items = reindexed[sym.item]\n",
    "    dialogues = [e[0] if isinstance(e, tuple) else e for e in items]\n",
    "    reindexed['dialogue'] = dialogues\n",
    "    reindexed.set_index(\n",
    "        [sym.bot, sym.category, sym.label, 'dialogue', sym.item],\n",
    "        inplace=True, verify_integrity=True\n",
    "    )\n",
    "    ld = reindexed.xs(category.likert_dialogue, level=sym.category)\n",
    "    ld = ld.droplevel(sym.bot).droplevel(sym.item)\n",
    "    ld.columns = ['score']\n",
    "    ldq = ld.xs(scale.quality, level=sym.label)\n",
    "    ldq.columns = ['quality']\n",
    "\n",
    "    lt = reindexed.xs(category.likert_turn, level=sym.category)\n",
    "    lt = lt.groupby([sym.label, 'dialogue']).mean()\n",
    "    lt.columns = ['score']\n",
    "    ltq = lt.xs(scale.quality, level=sym.label)\n",
    "    ltq.columns = ['quality']\n",
    "\n",
    "    be = reindexed.xs(category.behavior, level=sym.category)\n",
    "    be = be.groupby([sym.label, 'dialogue']).mean()\n",
    "    be.columns = ['score']\n",
    "\n",
    "    ds = pd.concat(\n",
    "        [lt, be, ld],\n",
    "        keys=[category.likert_turn, category.behavior, category.likert_dialogue],\n",
    "        names=[sym.category, sym.label, 'dialogue']\n",
    "    )\n",
    "    likert_dialogue_quality_features = ds.join(ldq, on='dialogue')\n",
    "    likert_turn_quality_features = ds.join(ltq, on='dialogue')\n",
    "    return likert_dialogue_quality_features, likert_turn_quality_features\n",
    "\n",
    "@to_file\n",
    "def dialogue_quality_regressions(ev):\n",
    "    ldq, ltq = dialogue_metrics(ev)\n",
    "    groups = ldq.groupby(\n",
    "        [sym.category, sym.label]\n",
    "    )\n",
    "    result = groups.apply(regressions)\n",
    "    return result\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "dialogue_quality_regressions(\n",
    "    data.surge_evaluation,\n",
    "    load='results/dialogue_quality_regressions.csv'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Agreement Between Static and Interactive Evaluators"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}