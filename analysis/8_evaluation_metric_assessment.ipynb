{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from analysis import *\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "from scipy.stats import binom_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                                           0  \\\nbot            category        label        item                               \nrerank_blender likert dialogue emotional    (109,13)_rerank_blender        4   \n                               consistent   (109,13)_rerank_blender        4   \n                               grammatical  (109,13)_rerank_blender        4   \n                               informative  (109,13)_rerank_blender        4   \n                               proactive    (109,13)_rerank_blender        4   \n...                                                                       ..   \n               behavior        follow up    ((438,26)_rerank_blender, 14)  0   \n                               topic switch ((438,26)_rerank_blender, 14)  0   \n                               ignore       ((438,26)_rerank_blender, 14)  0   \n                               irrelevant   ((438,26)_rerank_blender, 14)  0   \n                               antisocial   ((438,26)_rerank_blender, 14)  0   \n\n                                                                             1  \\\nbot            category        label        item                                 \nrerank_blender likert dialogue emotional    (109,13)_rerank_blender        4.0   \n                               consistent   (109,13)_rerank_blender        4.0   \n                               grammatical  (109,13)_rerank_blender        3.0   \n                               informative  (109,13)_rerank_blender        4.0   \n                               proactive    (109,13)_rerank_blender        3.0   \n...                                                                        ...   \n               behavior        follow up    ((438,26)_rerank_blender, 14)  NaN   \n                               topic switch ((438,26)_rerank_blender, 14)  NaN   \n                               ignore       ((438,26)_rerank_blender, 14)  NaN   \n                               irrelevant   ((438,26)_rerank_blender, 14)  NaN   \n                               antisocial   ((438,26)_rerank_blender, 14)  NaN   \n\n                                                                            2  \nbot            category        label        item                               \nrerank_blender likert dialogue emotional    (109,13)_rerank_blender       NaN  \n                               consistent   (109,13)_rerank_blender       NaN  \n                               grammatical  (109,13)_rerank_blender       NaN  \n                               informative  (109,13)_rerank_blender       NaN  \n                               proactive    (109,13)_rerank_blender       NaN  \n...                                                                        ..  \n               behavior        follow up    ((438,26)_rerank_blender, 14) NaN  \n                               topic switch ((438,26)_rerank_blender, 14) NaN  \n                               ignore       ((438,26)_rerank_blender, 14) NaN  \n                               irrelevant   ((438,26)_rerank_blender, 14) NaN  \n                               antisocial   ((438,26)_rerank_blender, 14) NaN  \n\n[151664 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n    </tr>\n    <tr>\n      <th>bot</th>\n      <th>category</th>\n      <th>label</th>\n      <th>item</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"11\" valign=\"top\">rerank_blender</th>\n      <th rowspan=\"5\" valign=\"top\">likert dialogue</th>\n      <th>emotional</th>\n      <th>(109,13)_rerank_blender</th>\n      <td>4</td>\n      <td>4.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>consistent</th>\n      <th>(109,13)_rerank_blender</th>\n      <td>4</td>\n      <td>4.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>grammatical</th>\n      <th>(109,13)_rerank_blender</th>\n      <td>4</td>\n      <td>3.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>informative</th>\n      <th>(109,13)_rerank_blender</th>\n      <td>4</td>\n      <td>4.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>proactive</th>\n      <th>(109,13)_rerank_blender</th>\n      <td>4</td>\n      <td>3.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">behavior</th>\n      <th>follow up</th>\n      <th>((438,26)_rerank_blender, 14)</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>topic switch</th>\n      <th>((438,26)_rerank_blender, 14)</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>ignore</th>\n      <th>((438,26)_rerank_blender, 14)</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>irrelevant</th>\n      <th>((438,26)_rerank_blender, 14)</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>antisocial</th>\n      <th>((438,26)_rerank_blender, 14)</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>151664 rows Ã— 3 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surge_annotations = data.surge_evaluation.annotation_dataframe()\n",
    "surge_annotations_comparative = data.surge_evaluation.comparative_annotation_dataframe()\n",
    "\n",
    "surge_annotations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 8 Comprehensive Analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Metric Sensitivity"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/james/anaconda3/envs/Research/lib/python3.10/site-packages/statsmodels/stats/weightstats.py:790: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  zstat = value / std\n",
      "/home/james/anaconda3/envs/Research/lib/python3.10/site-packages/statsmodels/stats/weightstats.py:790: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  zstat = value / std\n",
      "/home/james/anaconda3/envs/Research/lib/python3.10/site-packages/statsmodels/stats/weightstats.py:790: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  zstat = value / std\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                          bart_fid_rag_bcb              \\\n                                                     emora blender2_3B   \ncategory        label                                                    \nbehavior        antisocial                             NaN         NaN   \n                commonsense contradiction           0.1685      0.3202   \n                correct fact                        0.0002      0.0098   \n                empathetic                          0.6107      0.7978   \n                follow up                           0.0002      0.5986   \n                ignore                              0.4911      0.1623   \n                incorrect fact                      0.0101      0.0101   \n                irrelevant                          0.2002      0.6888   \n                lack of empathy                     0.5218      0.2296   \n                life info                           0.7404      0.5453   \n                partner contradiction               0.6414      0.3017   \n                preference info                     0.0016      0.3164   \n                redundant                           0.6888      0.3911   \n                self contradiction                  0.0101      0.0452   \n                topic switch                        0.0079      0.1685   \n                uninterpretable                        NaN         NaN   \nlikert dialogue consistent                          0.0243      0.1380   \n                emotional                           0.2968      0.0002   \n                engaging                            0.0968      0.0022   \n                grammatical                         0.8801      0.1028   \n                informative                         0.6013      0.7968   \n                proactive                           0.0000      0.0000   \n                quality                             0.3231      0.0005   \n                relevant                            0.5454      0.0465   \nlikert turn     consistent                          0.4576      0.0804   \n                emotional                           0.0173      0.1112   \n                engaging                            0.2696      0.2934   \n                grammatical                         0.0210      0.0012   \n                informative                         0.0052      0.2691   \n                proactive                           0.0013      0.0024   \n                quality                             0.6389      0.0107   \n                relevant                            0.8537      0.7245   \ncomparative     consistent                          0.0501      0.5966   \n                emotional                           0.2005      0.5847   \n                engaging                            0.1102      0.8601   \n                grammatical                         0.5716      0.8388   \n                informative                         0.2153      0.0201   \n                proactive                           0.0107      0.1102   \n                quality                             0.4731      0.3771   \n                relevant                            0.0501      1.0000   \n\n                                                               emora  \\\n                                          rerank_blender blender2_3B   \ncategory        label                                                  \nbehavior        antisocial                           NaN         NaN   \n                commonsense contradiction         0.5218      0.6888   \n                correct fact                      0.0211      0.1685   \n                empathetic                        0.2807      0.8002   \n                follow up                         0.0005      0.0010   \n                ignore                            0.4911      0.0452   \n                incorrect fact                    0.4911         NaN   \n                irrelevant                        0.3202      0.0976   \n                lack of empathy                   0.2296      0.0722   \n                life info                         0.7560      0.3513   \n                partner contradiction             0.3017      0.5543   \n                preference info                   0.2093      0.0261   \n                redundant                         0.1623      0.6414   \n                self contradiction                0.0452      0.3135   \n                topic switch                      0.0039      0.1713   \n                uninterpretable                   0.3135         NaN   \nlikert dialogue consistent                        0.1722      0.4461   \n                emotional                         0.6075      0.0017   \n                engaging                          0.0348      0.0922   \n                grammatical                       0.1115      0.0519   \n                informative                       0.0476      0.4378   \n                proactive                         0.0000      0.7845   \n                quality                           0.5997      0.0079   \n                relevant                          0.3452      0.0033   \nlikert turn     consistent                        0.2177      0.2154   \n                emotional                         0.3698      0.4030   \n                engaging                          0.6962      1.0000   \n                grammatical                       0.6706      0.1168   \n                informative                       0.1188      0.0747   \n                proactive                         0.0010      0.8342   \n                quality                           0.9062      0.0345   \n                relevant                          0.6475      0.5905   \ncomparative     consistent                        0.0501      0.0021   \n                emotional                         0.2005      1.0000   \n                engaging                          0.0001      1.0000   \n                grammatical                       0.7011      0.8506   \n                informative                       0.3771      0.0708   \n                proactive                         0.0005      0.2153   \n                quality                           0.0501      0.5966   \n                relevant                          0.3771      0.3771   \n\n                                                            blender2_3B  \n                                          rerank_blender rerank_blender  \ncategory        label                                                    \nbehavior        antisocial                           NaN            NaN  \n                commonsense contradiction         0.4497         0.7192  \n                correct fact                      0.0976         0.7679  \n                empathetic                        0.1143         0.1832  \n                follow up                         0.7679         0.0025  \n                ignore                            1.0000         0.0452  \n                incorrect fact                    0.0389         0.0389  \n                irrelevant                        0.7679         0.1685  \n                lack of empathy                   0.0722         1.0000  \n                life info                         0.5218         0.7679  \n                partner contradiction             0.5543         1.0000  \n                preference info                   0.0476         0.7978  \n                redundant                         0.3017         0.5543  \n                self contradiction                0.3135         1.0000  \n                topic switch                      0.7978         0.1056  \n                uninterpretable                   0.3135         0.3135  \nlikert dialogue consistent                        0.4048         0.9293  \n                emotional                         0.6569         0.0023  \n                engaging                          0.5253         0.3613  \n                grammatical                       0.1187         0.0026  \n                informative                       0.0123         0.0876  \n                proactive                         0.2227         0.3243  \n                quality                           0.6881         0.0046  \n                relevant                          0.6378         0.0037  \nlikert turn     consistent                        0.5435         0.5713  \n                emotional                         0.1529         0.5246  \n                engaging                          0.4266         0.4553  \n                grammatical                       0.0122         0.0001  \n                informative                       0.1264         0.7022  \n                proactive                         1.0000         0.8303  \n                quality                           0.5513         0.0066  \n                relevant                          0.7795         0.4237  \ncomparative     consistent                        0.7201         1.0000  \n                emotional                         0.7201         0.5847  \n                engaging                          0.0201         0.8555  \n                grammatical                       0.4421         0.1849  \n                informative                       0.0201         0.1102  \n                proactive                         0.1102         0.8601  \n                quality                           0.5966         1.0000  \n                relevant                          1.0000         0.8601  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th></th>\n      <th colspan=\"3\" halign=\"left\">bart_fid_rag_bcb</th>\n      <th colspan=\"2\" halign=\"left\">emora</th>\n      <th>blender2_3B</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th></th>\n      <th>emora</th>\n      <th>blender2_3B</th>\n      <th>rerank_blender</th>\n      <th>blender2_3B</th>\n      <th>rerank_blender</th>\n      <th>rerank_blender</th>\n    </tr>\n    <tr>\n      <th>category</th>\n      <th>label</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"16\" valign=\"top\">behavior</th>\n      <th>antisocial</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>commonsense contradiction</th>\n      <td>0.1685</td>\n      <td>0.3202</td>\n      <td>0.5218</td>\n      <td>0.6888</td>\n      <td>0.4497</td>\n      <td>0.7192</td>\n    </tr>\n    <tr>\n      <th>correct fact</th>\n      <td>0.0002</td>\n      <td>0.0098</td>\n      <td>0.0211</td>\n      <td>0.1685</td>\n      <td>0.0976</td>\n      <td>0.7679</td>\n    </tr>\n    <tr>\n      <th>empathetic</th>\n      <td>0.6107</td>\n      <td>0.7978</td>\n      <td>0.2807</td>\n      <td>0.8002</td>\n      <td>0.1143</td>\n      <td>0.1832</td>\n    </tr>\n    <tr>\n      <th>follow up</th>\n      <td>0.0002</td>\n      <td>0.5986</td>\n      <td>0.0005</td>\n      <td>0.0010</td>\n      <td>0.7679</td>\n      <td>0.0025</td>\n    </tr>\n    <tr>\n      <th>ignore</th>\n      <td>0.4911</td>\n      <td>0.1623</td>\n      <td>0.4911</td>\n      <td>0.0452</td>\n      <td>1.0000</td>\n      <td>0.0452</td>\n    </tr>\n    <tr>\n      <th>incorrect fact</th>\n      <td>0.0101</td>\n      <td>0.0101</td>\n      <td>0.4911</td>\n      <td>NaN</td>\n      <td>0.0389</td>\n      <td>0.0389</td>\n    </tr>\n    <tr>\n      <th>irrelevant</th>\n      <td>0.2002</td>\n      <td>0.6888</td>\n      <td>0.3202</td>\n      <td>0.0976</td>\n      <td>0.7679</td>\n      <td>0.1685</td>\n    </tr>\n    <tr>\n      <th>lack of empathy</th>\n      <td>0.5218</td>\n      <td>0.2296</td>\n      <td>0.2296</td>\n      <td>0.0722</td>\n      <td>0.0722</td>\n      <td>1.0000</td>\n    </tr>\n    <tr>\n      <th>life info</th>\n      <td>0.7404</td>\n      <td>0.5453</td>\n      <td>0.7560</td>\n      <td>0.3513</td>\n      <td>0.5218</td>\n      <td>0.7679</td>\n    </tr>\n    <tr>\n      <th>partner contradiction</th>\n      <td>0.6414</td>\n      <td>0.3017</td>\n      <td>0.3017</td>\n      <td>0.5543</td>\n      <td>0.5543</td>\n      <td>1.0000</td>\n    </tr>\n    <tr>\n      <th>preference info</th>\n      <td>0.0016</td>\n      <td>0.3164</td>\n      <td>0.2093</td>\n      <td>0.0261</td>\n      <td>0.0476</td>\n      <td>0.7978</td>\n    </tr>\n    <tr>\n      <th>redundant</th>\n      <td>0.6888</td>\n      <td>0.3911</td>\n      <td>0.1623</td>\n      <td>0.6414</td>\n      <td>0.3017</td>\n      <td>0.5543</td>\n    </tr>\n    <tr>\n      <th>self contradiction</th>\n      <td>0.0101</td>\n      <td>0.0452</td>\n      <td>0.0452</td>\n      <td>0.3135</td>\n      <td>0.3135</td>\n      <td>1.0000</td>\n    </tr>\n    <tr>\n      <th>topic switch</th>\n      <td>0.0079</td>\n      <td>0.1685</td>\n      <td>0.0039</td>\n      <td>0.1713</td>\n      <td>0.7978</td>\n      <td>0.1056</td>\n    </tr>\n    <tr>\n      <th>uninterpretable</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.3135</td>\n      <td>NaN</td>\n      <td>0.3135</td>\n      <td>0.3135</td>\n    </tr>\n    <tr>\n      <th rowspan=\"8\" valign=\"top\">likert dialogue</th>\n      <th>consistent</th>\n      <td>0.0243</td>\n      <td>0.1380</td>\n      <td>0.1722</td>\n      <td>0.4461</td>\n      <td>0.4048</td>\n      <td>0.9293</td>\n    </tr>\n    <tr>\n      <th>emotional</th>\n      <td>0.2968</td>\n      <td>0.0002</td>\n      <td>0.6075</td>\n      <td>0.0017</td>\n      <td>0.6569</td>\n      <td>0.0023</td>\n    </tr>\n    <tr>\n      <th>engaging</th>\n      <td>0.0968</td>\n      <td>0.0022</td>\n      <td>0.0348</td>\n      <td>0.0922</td>\n      <td>0.5253</td>\n      <td>0.3613</td>\n    </tr>\n    <tr>\n      <th>grammatical</th>\n      <td>0.8801</td>\n      <td>0.1028</td>\n      <td>0.1115</td>\n      <td>0.0519</td>\n      <td>0.1187</td>\n      <td>0.0026</td>\n    </tr>\n    <tr>\n      <th>informative</th>\n      <td>0.6013</td>\n      <td>0.7968</td>\n      <td>0.0476</td>\n      <td>0.4378</td>\n      <td>0.0123</td>\n      <td>0.0876</td>\n    </tr>\n    <tr>\n      <th>proactive</th>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.7845</td>\n      <td>0.2227</td>\n      <td>0.3243</td>\n    </tr>\n    <tr>\n      <th>quality</th>\n      <td>0.3231</td>\n      <td>0.0005</td>\n      <td>0.5997</td>\n      <td>0.0079</td>\n      <td>0.6881</td>\n      <td>0.0046</td>\n    </tr>\n    <tr>\n      <th>relevant</th>\n      <td>0.5454</td>\n      <td>0.0465</td>\n      <td>0.3452</td>\n      <td>0.0033</td>\n      <td>0.6378</td>\n      <td>0.0037</td>\n    </tr>\n    <tr>\n      <th rowspan=\"8\" valign=\"top\">likert turn</th>\n      <th>consistent</th>\n      <td>0.4576</td>\n      <td>0.0804</td>\n      <td>0.2177</td>\n      <td>0.2154</td>\n      <td>0.5435</td>\n      <td>0.5713</td>\n    </tr>\n    <tr>\n      <th>emotional</th>\n      <td>0.0173</td>\n      <td>0.1112</td>\n      <td>0.3698</td>\n      <td>0.4030</td>\n      <td>0.1529</td>\n      <td>0.5246</td>\n    </tr>\n    <tr>\n      <th>engaging</th>\n      <td>0.2696</td>\n      <td>0.2934</td>\n      <td>0.6962</td>\n      <td>1.0000</td>\n      <td>0.4266</td>\n      <td>0.4553</td>\n    </tr>\n    <tr>\n      <th>grammatical</th>\n      <td>0.0210</td>\n      <td>0.0012</td>\n      <td>0.6706</td>\n      <td>0.1168</td>\n      <td>0.0122</td>\n      <td>0.0001</td>\n    </tr>\n    <tr>\n      <th>informative</th>\n      <td>0.0052</td>\n      <td>0.2691</td>\n      <td>0.1188</td>\n      <td>0.0747</td>\n      <td>0.1264</td>\n      <td>0.7022</td>\n    </tr>\n    <tr>\n      <th>proactive</th>\n      <td>0.0013</td>\n      <td>0.0024</td>\n      <td>0.0010</td>\n      <td>0.8342</td>\n      <td>1.0000</td>\n      <td>0.8303</td>\n    </tr>\n    <tr>\n      <th>quality</th>\n      <td>0.6389</td>\n      <td>0.0107</td>\n      <td>0.9062</td>\n      <td>0.0345</td>\n      <td>0.5513</td>\n      <td>0.0066</td>\n    </tr>\n    <tr>\n      <th>relevant</th>\n      <td>0.8537</td>\n      <td>0.7245</td>\n      <td>0.6475</td>\n      <td>0.5905</td>\n      <td>0.7795</td>\n      <td>0.4237</td>\n    </tr>\n    <tr>\n      <th rowspan=\"8\" valign=\"top\">comparative</th>\n      <th>consistent</th>\n      <td>0.0501</td>\n      <td>0.5966</td>\n      <td>0.0501</td>\n      <td>0.0021</td>\n      <td>0.7201</td>\n      <td>1.0000</td>\n    </tr>\n    <tr>\n      <th>emotional</th>\n      <td>0.2005</td>\n      <td>0.5847</td>\n      <td>0.2005</td>\n      <td>1.0000</td>\n      <td>0.7201</td>\n      <td>0.5847</td>\n    </tr>\n    <tr>\n      <th>engaging</th>\n      <td>0.1102</td>\n      <td>0.8601</td>\n      <td>0.0001</td>\n      <td>1.0000</td>\n      <td>0.0201</td>\n      <td>0.8555</td>\n    </tr>\n    <tr>\n      <th>grammatical</th>\n      <td>0.5716</td>\n      <td>0.8388</td>\n      <td>0.7011</td>\n      <td>0.8506</td>\n      <td>0.4421</td>\n      <td>0.1849</td>\n    </tr>\n    <tr>\n      <th>informative</th>\n      <td>0.2153</td>\n      <td>0.0201</td>\n      <td>0.3771</td>\n      <td>0.0708</td>\n      <td>0.0201</td>\n      <td>0.1102</td>\n    </tr>\n    <tr>\n      <th>proactive</th>\n      <td>0.0107</td>\n      <td>0.1102</td>\n      <td>0.0005</td>\n      <td>0.2153</td>\n      <td>0.1102</td>\n      <td>0.8601</td>\n    </tr>\n    <tr>\n      <th>quality</th>\n      <td>0.4731</td>\n      <td>0.3771</td>\n      <td>0.0501</td>\n      <td>0.5966</td>\n      <td>0.5966</td>\n      <td>1.0000</td>\n    </tr>\n    <tr>\n      <th>relevant</th>\n      <td>0.0501</td>\n      <td>1.0000</td>\n      <td>0.3771</td>\n      <td>0.3771</td>\n      <td>1.0000</td>\n      <td>0.8601</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "def p_vals(df: pd.DataFrame, test='t', downsample=None):\n",
    "    \"\"\"\n",
    "    :param df: (bot, data point) x 1 -> score\n",
    "    :param test: statistical test function (t for t test, p for prop test, s for sign test)\n",
    "    :param downsample: number of samples ber bot to subsample without replacement for the analysis\n",
    "    :return: p values of test on each bot pair (pd.Series)\n",
    "    \"\"\"\n",
    "    seed = 123\n",
    "    bots = set(df.index.get_level_values(0))\n",
    "    num_bots = len(bots)\n",
    "    bot_pairs = list(combinations(bots, 2))\n",
    "    result = {}\n",
    "    for ba, bb in bot_pairs:\n",
    "        if test == 't':\n",
    "            if downsample:\n",
    "                a = df.xs(ba).sample(downsample, random_state=seed).to_numpy().squeeze()\n",
    "                b = df.xs(bb).sample(downsample, random_state=seed).to_numpy().squeeze()\n",
    "            else:\n",
    "                a = df.xs(ba).to_numpy().squeeze()\n",
    "                b = df.xs(bb).to_numpy().squeeze()\n",
    "            t, p = ttest_ind(a, b, equal_var=False)\n",
    "        elif test == 'p':\n",
    "            if downsample:\n",
    "                a = df.xs(ba).sample(downsample, random_state=seed).to_numpy().squeeze()\n",
    "                b = df.xs(bb).sample(downsample, random_state=seed).to_numpy().squeeze()\n",
    "            else:\n",
    "                a = df.xs(ba).to_numpy().squeeze()\n",
    "                b = df.xs(bb).to_numpy().squeeze()\n",
    "            z, p = proportions_ztest(count=[\n",
    "                sum(a), sum(b)\n",
    "            ], nobs=[\n",
    "                len(a), len(b)\n",
    "            ])\n",
    "        elif test == 's':\n",
    "            # sign test\n",
    "            comp_data = df.xs((ba, bb), level=[sym.bot, sym.bot_cmp])\n",
    "            if downsample:\n",
    "                comp_data = comp_data.sample(downsample, random_state=seed)\n",
    "            a = comp_data.to_numpy().squeeze() == 1\n",
    "            b = comp_data.to_numpy().squeeze() == -1\n",
    "            p = binom_test(sum(a), sum(a)+sum(b), p=0.5)\n",
    "        else:\n",
    "            raise ValueError('invalid arg for param \"test\"')\n",
    "        result[(ba, bb)] = p\n",
    "    result_series = pd.Series(result.values(), result)\n",
    "    return result_series\n",
    "\n",
    "@to_file\n",
    "def p_values_comparing_bots(evaluation, downsample=None):\n",
    "    comp_annotations = get_singly_annotated(evaluation.comparative_annotation_dataframe(), seed=123)\n",
    "    annotations = get_singly_annotated(evaluation.annotation_dataframe(), seed=123)\n",
    "    prop_annotations = annotations.xs(\n",
    "        category.behavior, level=sym.category, drop_level=False\n",
    "    )\n",
    "    mean_annotations = annotations.drop(\n",
    "        index=category.behavior, level=sym.category\n",
    "    ).drop(\n",
    "        index=category.comparative, level=sym.category\n",
    "    )\n",
    "    mean_ps = mean_annotations.groupby(\n",
    "        [sym.category, sym.label]\n",
    "    ).apply(lambda x: p_vals(x, test='t', downsample=downsample))\n",
    "    prop_ps = prop_annotations.groupby(\n",
    "        [sym.category, sym.label]\n",
    "    ).apply(lambda x: p_vals(x, test='p', downsample=downsample))\n",
    "    comp_groups = comp_annotations.groupby(sym.label)\n",
    "    comp_ps = comp_groups.apply(lambda x: p_vals(x, test='s', downsample=downsample))\n",
    "    comp_ps = pd.concat({category.comparative: comp_ps}, names=[sym.category])\n",
    "    result = pd.concat([prop_ps, mean_ps, comp_ps], axis=0)\n",
    "    return result\n",
    "\n",
    "p_values_comparing_bots(data.surge_evaluation, downsample=32, reload='results/p_values_comparing_bots_downsampled').round(4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "                                          bart_fid_rag_bcb              \\\n                                                     emora blender2_3B   \ncategory        label                                                    \nbehavior        antisocial                          0.5597      0.1601   \n                commonsense contradiction           0.0000      0.0002   \n                correct fact                        0.0000      0.0000   \n                empathetic                          0.0000      0.0000   \n                follow up                           0.0000      0.5851   \n                ignore                              0.3671      0.0436   \n                incorrect fact                      0.0000      0.0000   \n                irrelevant                          0.0019      0.1866   \n                lack of empathy                     0.6253      0.0000   \n                life info                           0.0000      0.9618   \n                partner contradiction               0.1876      0.9333   \n                preference info                     0.0000      0.9816   \n                redundant                           0.3665      0.0017   \n                self contradiction                  0.0000      0.0000   \n                topic switch                        0.0000      0.0002   \n                uninterpretable                     0.0001      0.0016   \nlikert dialogue consistent                          0.0000      0.0138   \n                emotional                           0.7603      0.0000   \n                engaging                            0.0049      0.0000   \n                grammatical                         0.1644      0.0005   \n                informative                         0.0209      0.2968   \n                proactive                           0.0000      0.0000   \n                quality                             0.0003      0.0000   \n                relevant                            0.5081      0.0009   \nlikert turn     consistent                          0.0002      0.0043   \n                emotional                           0.2403      0.0000   \n                engaging                            0.0000      0.0000   \n                grammatical                         0.0000      0.0000   \n                informative                         0.0000      0.0000   \n                proactive                           0.0000      0.0000   \n                quality                             0.0001      0.0000   \n                relevant                            0.0693      0.0000   \ncomparative     consistent                          0.0501      0.5966   \n                emotional                           0.2005      0.5847   \n                engaging                            0.1102      0.8601   \n                grammatical                         0.5716      0.8388   \n                informative                         0.2153      0.0201   \n                proactive                           0.0107      0.1102   \n                quality                             0.4731      0.3771   \n                relevant                            0.0501      1.0000   \n\n                                                               emora  \\\n                                          rerank_blender blender2_3B   \ncategory        label                                                  \nbehavior        antisocial                        0.0119      0.0587   \n                commonsense contradiction         0.0473      0.0008   \n                correct fact                      0.0000      0.0000   \n                empathetic                        0.0000      0.5285   \n                follow up                         0.0000      0.0000   \n                ignore                            0.0079      0.0035   \n                incorrect fact                    0.0663      0.0023   \n                irrelevant                        0.0000      0.0000   \n                lack of empathy                   0.0000      0.0000   \n                life info                         0.3605      0.0000   \n                partner contradiction             0.6508      0.1604   \n                preference info                   0.0000      0.0000   \n                redundant                         0.0737      0.0239   \n                self contradiction                0.0000      0.0000   \n                topic switch                      0.0000      0.0000   \n                uninterpretable                   0.0109      0.3176   \nlikert dialogue consistent                        0.0002      0.0196   \n                emotional                         0.0344      0.0000   \n                engaging                          0.0003      0.0640   \n                grammatical                       0.0934      0.0200   \n                informative                       0.1992      0.2420   \n                proactive                         0.0000      0.3758   \n                quality                           0.0495      0.1552   \n                relevant                          0.9009      0.0000   \nlikert turn     consistent                        0.0634      0.3926   \n                emotional                         0.0000      0.0000   \n                engaging                          0.0000      0.0336   \n                grammatical                       0.0000      0.0000   \n                informative                       0.0249      0.0000   \n                proactive                         0.0000      0.0001   \n                quality                           0.7254      0.0000   \n                relevant                          0.0006      0.0000   \ncomparative     consistent                        0.0501      0.0021   \n                emotional                         0.2005      1.0000   \n                engaging                          0.0001      1.0000   \n                grammatical                       0.7011      0.8506   \n                informative                       0.3771      0.0708   \n                proactive                         0.0005      0.2153   \n                quality                           0.0501      0.5966   \n                relevant                          0.3771      0.3771   \n\n                                                            blender2_3B  \n                                          rerank_blender rerank_blender  \ncategory        label                                                    \nbehavior        antisocial                        0.0035         0.2117  \n                commonsense contradiction         0.0000         0.0917  \n                correct fact                      0.0000         0.8325  \n                empathetic                        0.2644         0.6252  \n                follow up                         0.2512         0.0000  \n                ignore                            0.0004         0.5149  \n                incorrect fact                    0.0000         0.0000  \n                irrelevant                        0.0457         0.0000  \n                lack of empathy                   0.0000         0.0007  \n                life info                         0.0015         0.3851  \n                partner contradiction             0.3883         0.5913  \n                preference info                   0.0000         0.0000  \n                redundant                         0.0073         0.0000  \n                self contradiction                0.0000         0.0143  \n                topic switch                      0.0220         0.0000  \n                uninterpretable                   0.0000         0.0000  \nlikert dialogue consistent                        0.2676         0.1959  \n                emotional                         0.0551         0.0001  \n                engaging                          0.2089         0.6625  \n                grammatical                       0.0027         0.0000  \n                informative                       0.0003         0.0228  \n                proactive                         0.1264         0.5126  \n                quality                           0.1417         0.0099  \n                relevant                          0.5812         0.0003  \nlikert turn     consistent                        0.0501         0.2874  \n                emotional                         0.0000         0.3276  \n                engaging                          0.1604         0.0006  \n                grammatical                       0.0000         0.0000  \n                informative                       0.0000         0.0000  \n                proactive                         0.0414         0.0982  \n                quality                           0.0000         0.0000  \n                relevant                          0.0929         0.0000  \ncomparative     consistent                        0.7201         1.0000  \n                emotional                         0.7201         0.5847  \n                engaging                          0.0201         0.8555  \n                grammatical                       0.4421         0.1849  \n                informative                       0.0201         0.1102  \n                proactive                         0.1102         0.8601  \n                quality                           0.5966         1.0000  \n                relevant                          1.0000         0.8601  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th></th>\n      <th colspan=\"3\" halign=\"left\">bart_fid_rag_bcb</th>\n      <th colspan=\"2\" halign=\"left\">emora</th>\n      <th>blender2_3B</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th></th>\n      <th>emora</th>\n      <th>blender2_3B</th>\n      <th>rerank_blender</th>\n      <th>blender2_3B</th>\n      <th>rerank_blender</th>\n      <th>rerank_blender</th>\n    </tr>\n    <tr>\n      <th>category</th>\n      <th>label</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"16\" valign=\"top\">behavior</th>\n      <th>antisocial</th>\n      <td>0.5597</td>\n      <td>0.1601</td>\n      <td>0.0119</td>\n      <td>0.0587</td>\n      <td>0.0035</td>\n      <td>0.2117</td>\n    </tr>\n    <tr>\n      <th>commonsense contradiction</th>\n      <td>0.0000</td>\n      <td>0.0002</td>\n      <td>0.0473</td>\n      <td>0.0008</td>\n      <td>0.0000</td>\n      <td>0.0917</td>\n    </tr>\n    <tr>\n      <th>correct fact</th>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.8325</td>\n    </tr>\n    <tr>\n      <th>empathetic</th>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.5285</td>\n      <td>0.2644</td>\n      <td>0.6252</td>\n    </tr>\n    <tr>\n      <th>follow up</th>\n      <td>0.0000</td>\n      <td>0.5851</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.2512</td>\n      <td>0.0000</td>\n    </tr>\n    <tr>\n      <th>ignore</th>\n      <td>0.3671</td>\n      <td>0.0436</td>\n      <td>0.0079</td>\n      <td>0.0035</td>\n      <td>0.0004</td>\n      <td>0.5149</td>\n    </tr>\n    <tr>\n      <th>incorrect fact</th>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0663</td>\n      <td>0.0023</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n    </tr>\n    <tr>\n      <th>irrelevant</th>\n      <td>0.0019</td>\n      <td>0.1866</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0457</td>\n      <td>0.0000</td>\n    </tr>\n    <tr>\n      <th>lack of empathy</th>\n      <td>0.6253</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0007</td>\n    </tr>\n    <tr>\n      <th>life info</th>\n      <td>0.0000</td>\n      <td>0.9618</td>\n      <td>0.3605</td>\n      <td>0.0000</td>\n      <td>0.0015</td>\n      <td>0.3851</td>\n    </tr>\n    <tr>\n      <th>partner contradiction</th>\n      <td>0.1876</td>\n      <td>0.9333</td>\n      <td>0.6508</td>\n      <td>0.1604</td>\n      <td>0.3883</td>\n      <td>0.5913</td>\n    </tr>\n    <tr>\n      <th>preference info</th>\n      <td>0.0000</td>\n      <td>0.9816</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n    </tr>\n    <tr>\n      <th>redundant</th>\n      <td>0.3665</td>\n      <td>0.0017</td>\n      <td>0.0737</td>\n      <td>0.0239</td>\n      <td>0.0073</td>\n      <td>0.0000</td>\n    </tr>\n    <tr>\n      <th>self contradiction</th>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0143</td>\n    </tr>\n    <tr>\n      <th>topic switch</th>\n      <td>0.0000</td>\n      <td>0.0002</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0220</td>\n      <td>0.0000</td>\n    </tr>\n    <tr>\n      <th>uninterpretable</th>\n      <td>0.0001</td>\n      <td>0.0016</td>\n      <td>0.0109</td>\n      <td>0.3176</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n    </tr>\n    <tr>\n      <th rowspan=\"8\" valign=\"top\">likert dialogue</th>\n      <th>consistent</th>\n      <td>0.0000</td>\n      <td>0.0138</td>\n      <td>0.0002</td>\n      <td>0.0196</td>\n      <td>0.2676</td>\n      <td>0.1959</td>\n    </tr>\n    <tr>\n      <th>emotional</th>\n      <td>0.7603</td>\n      <td>0.0000</td>\n      <td>0.0344</td>\n      <td>0.0000</td>\n      <td>0.0551</td>\n      <td>0.0001</td>\n    </tr>\n    <tr>\n      <th>engaging</th>\n      <td>0.0049</td>\n      <td>0.0000</td>\n      <td>0.0003</td>\n      <td>0.0640</td>\n      <td>0.2089</td>\n      <td>0.6625</td>\n    </tr>\n    <tr>\n      <th>grammatical</th>\n      <td>0.1644</td>\n      <td>0.0005</td>\n      <td>0.0934</td>\n      <td>0.0200</td>\n      <td>0.0027</td>\n      <td>0.0000</td>\n    </tr>\n    <tr>\n      <th>informative</th>\n      <td>0.0209</td>\n      <td>0.2968</td>\n      <td>0.1992</td>\n      <td>0.2420</td>\n      <td>0.0003</td>\n      <td>0.0228</td>\n    </tr>\n    <tr>\n      <th>proactive</th>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.3758</td>\n      <td>0.1264</td>\n      <td>0.5126</td>\n    </tr>\n    <tr>\n      <th>quality</th>\n      <td>0.0003</td>\n      <td>0.0000</td>\n      <td>0.0495</td>\n      <td>0.1552</td>\n      <td>0.1417</td>\n      <td>0.0099</td>\n    </tr>\n    <tr>\n      <th>relevant</th>\n      <td>0.5081</td>\n      <td>0.0009</td>\n      <td>0.9009</td>\n      <td>0.0000</td>\n      <td>0.5812</td>\n      <td>0.0003</td>\n    </tr>\n    <tr>\n      <th rowspan=\"8\" valign=\"top\">likert turn</th>\n      <th>consistent</th>\n      <td>0.0002</td>\n      <td>0.0043</td>\n      <td>0.0634</td>\n      <td>0.3926</td>\n      <td>0.0501</td>\n      <td>0.2874</td>\n    </tr>\n    <tr>\n      <th>emotional</th>\n      <td>0.2403</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.3276</td>\n    </tr>\n    <tr>\n      <th>engaging</th>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0336</td>\n      <td>0.1604</td>\n      <td>0.0006</td>\n    </tr>\n    <tr>\n      <th>grammatical</th>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n    </tr>\n    <tr>\n      <th>informative</th>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0249</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n    </tr>\n    <tr>\n      <th>proactive</th>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0001</td>\n      <td>0.0414</td>\n      <td>0.0982</td>\n    </tr>\n    <tr>\n      <th>quality</th>\n      <td>0.0001</td>\n      <td>0.0000</td>\n      <td>0.7254</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n    </tr>\n    <tr>\n      <th>relevant</th>\n      <td>0.0693</td>\n      <td>0.0000</td>\n      <td>0.0006</td>\n      <td>0.0000</td>\n      <td>0.0929</td>\n      <td>0.0000</td>\n    </tr>\n    <tr>\n      <th rowspan=\"8\" valign=\"top\">comparative</th>\n      <th>consistent</th>\n      <td>0.0501</td>\n      <td>0.5966</td>\n      <td>0.0501</td>\n      <td>0.0021</td>\n      <td>0.7201</td>\n      <td>1.0000</td>\n    </tr>\n    <tr>\n      <th>emotional</th>\n      <td>0.2005</td>\n      <td>0.5847</td>\n      <td>0.2005</td>\n      <td>1.0000</td>\n      <td>0.7201</td>\n      <td>0.5847</td>\n    </tr>\n    <tr>\n      <th>engaging</th>\n      <td>0.1102</td>\n      <td>0.8601</td>\n      <td>0.0001</td>\n      <td>1.0000</td>\n      <td>0.0201</td>\n      <td>0.8555</td>\n    </tr>\n    <tr>\n      <th>grammatical</th>\n      <td>0.5716</td>\n      <td>0.8388</td>\n      <td>0.7011</td>\n      <td>0.8506</td>\n      <td>0.4421</td>\n      <td>0.1849</td>\n    </tr>\n    <tr>\n      <th>informative</th>\n      <td>0.2153</td>\n      <td>0.0201</td>\n      <td>0.3771</td>\n      <td>0.0708</td>\n      <td>0.0201</td>\n      <td>0.1102</td>\n    </tr>\n    <tr>\n      <th>proactive</th>\n      <td>0.0107</td>\n      <td>0.1102</td>\n      <td>0.0005</td>\n      <td>0.2153</td>\n      <td>0.1102</td>\n      <td>0.8601</td>\n    </tr>\n    <tr>\n      <th>quality</th>\n      <td>0.4731</td>\n      <td>0.3771</td>\n      <td>0.0501</td>\n      <td>0.5966</td>\n      <td>0.5966</td>\n      <td>1.0000</td>\n    </tr>\n    <tr>\n      <th>relevant</th>\n      <td>0.0501</td>\n      <td>1.0000</td>\n      <td>0.3771</td>\n      <td>0.3771</td>\n      <td>1.0000</td>\n      <td>0.8601</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_values_comparing_bots(data.surge_evaluation, reload='results/t_test_p_values_comparing_bots').round(4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Predictive Validity"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "from statsmodels.miscmodels.ordinal_model import OrderedModel\n",
    "from statsmodels.regression.linear_model import OLS as LinearModel\n",
    "from statsmodels.tools.tools import add_constant\n",
    "\n",
    "\n",
    "def all_dialogue_metrics(data):\n",
    "    static: pd.DataFrame = data.surge_evaluation.annotation_dataframe()\n",
    "    static = get_singly_annotated(static, seed=123)\n",
    "    reindexed = static.reset_index()\n",
    "    items = reindexed[sym.item]\n",
    "    dialogues = [e[0] if isinstance(e, tuple) else e for e in items]\n",
    "    reindexed['dialogue'] = dialogues\n",
    "    reindexed.set_index(\n",
    "        [sym.bot, sym.category, sym.label, 'dialogue', sym.item],\n",
    "        inplace=True, verify_integrity=True\n",
    "    )\n",
    "    ld = reindexed.xs(category.likert_dialogue, level=sym.category)\n",
    "    ld = ld.droplevel(sym.bot).droplevel(sym.item)\n",
    "    ld.columns = ['score']\n",
    "    ldq = ld.xs(scale.quality, level=sym.label)\n",
    "    ldq.columns = ['quality']\n",
    "\n",
    "    lt = reindexed.xs(category.likert_turn, level=sym.category)\n",
    "    lt = lt.groupby([sym.label, 'dialogue']).mean()\n",
    "    lt.columns = ['score']\n",
    "    ltq = lt.xs(scale.quality, level=sym.label)\n",
    "    ltq.columns = ['quality']\n",
    "\n",
    "    be = reindexed.xs(category.behavior, level=sym.category)\n",
    "    be = be.groupby([sym.label, 'dialogue']).mean()\n",
    "    be.columns = ['score']\n",
    "\n",
    "    interactive = data.dialogue_collection.annotation_dataframe()\n",
    "    idq = interactive.xs((category.likert_dialogue, scale.quality), level=(sym.category, sym.label))\n",
    "    idq = idq.droplevel(0)\n",
    "\n",
    "    ds = pd.concat(\n",
    "        [lt, be, ld],\n",
    "        keys=[category.likert_turn, category.behavior, category.likert_dialogue],\n",
    "        names=[sym.category, sym.label, 'dialogue']\n",
    "    )\n",
    "    likert_dialogue_quality_features = ds.join(ldq, on='dialogue')\n",
    "    likert_turn_quality_features = ds.join(ltq, on='dialogue')\n",
    "    interactive_dialogue_quality_features = ds.join(idq, on='dialogue')\n",
    "    interactive_dialogue_quality_features.columns = ['score', 'quality']\n",
    "\n",
    "    interactive_comparisons = data.dialogue_collection.comparative_annotation_dataframe()\n",
    "    surge_comparisons = get_singly_annotated(data.surge_evaluation.comparative_annotation_dataframe(), seed=123)\n",
    "    compared_dialogues = surge_comparisons.index.get_level_values('dialogues')\n",
    "    unique_compared_dialogues = {tuple(x) for x in {frozenset(y) for y in compared_dialogues}}\n",
    "    comparison_map = dict(unique_compared_dialogues)\n",
    "    compared_selector = [\n",
    "        pair in unique_compared_dialogues\n",
    "        for pair in interactive_comparisons.index.get_level_values('dialogues')\n",
    "    ]\n",
    "    comparative: pd.DataFrame = interactive_comparisons.loc[compared_selector, :]\n",
    "    compared_selector = [\n",
    "        pair in unique_compared_dialogues\n",
    "        for pair in surge_comparisons.index.get_level_values('dialogues')\n",
    "    ]\n",
    "    surge_comparisons: pd.DataFrame = surge_comparisons.loc[compared_selector, :]\n",
    "    comparative_quality = comparative.xs(scale.quality, level=sym.label)\n",
    "    comparative_quality.index = [first for _, _, (first, second) in comparative_quality.index.values]\n",
    "    comparative_quality.columns = ['quality']\n",
    "    surge_comparisons.index = pd.MultiIndex.from_arrays(\n",
    "        list(zip(*[\n",
    "            (category.comparative, label, left)\n",
    "            for _, _, label, (left, right) in surge_comparisons.index.values\n",
    "        ])),\n",
    "        names=[sym.category, sym.label, 'dialogue']\n",
    "    )\n",
    "    surge_comparisons.columns = ['score']\n",
    "    filtered_ds = ds.loc[[(c, l, d) for c, l, d in ds.index.values if d in comparison_map]]\n",
    "    compared_features = ds.loc[[(c, l, comparison_map[d]) for c, l, d in filtered_ds.index.values]]\n",
    "    comparative_features = filtered_ds.to_numpy() - compared_features.to_numpy()\n",
    "    filtered_ds['diff'] = comparative_features.squeeze().tolist()\n",
    "    del filtered_ds['score']\n",
    "    filtered_ds.columns = ['score']\n",
    "    filtered_ds = pd.concat([filtered_ds, surge_comparisons], axis=0)\n",
    "    comparative_quality_features = filtered_ds.join(comparative_quality, on='dialogue')\n",
    "\n",
    "    return (\n",
    "        likert_dialogue_quality_features,\n",
    "        likert_turn_quality_features,\n",
    "        comparative_quality_features,\n",
    "        interactive_dialogue_quality_features\n",
    "    )\n",
    "\n",
    "all_dialogue_metrics(data)\n",
    "\n",
    "def regressions(df, quality_column_name=None, model='linear'):\n",
    "    \"\"\"\n",
    "    :param df: dialogue x (*features, quality) -> value\n",
    "    :return: *(coef, low, high), mcfadden r^2\n",
    "    \"\"\"\n",
    "    if not quality_column_name:\n",
    "        quality_column_name = df.columns[-1]\n",
    "    qualities = df[quality_column_name]\n",
    "    features = [f for f in df.columns if f != quality_column_name]\n",
    "    if model == 'ordinal':\n",
    "        model = OrderedModel(qualities, df[features], distr='logit')\n",
    "        results = model.fit()\n",
    "        coefs = {f: results.params[f] for f in features}\n",
    "        prsqrd = results.prsquared\n",
    "        result = {stat.mcfad_r2: prsqrd, stat.p_of_llr_test: results.llr_pvalue}\n",
    "    elif model == 'linear':\n",
    "        x = add_constant(df[features])\n",
    "        y = qualities\n",
    "        model = LinearModel(y, x)\n",
    "        results = model.fit()\n",
    "        coefs = {f: results.params[f] for f in features}\n",
    "        rsquared = results.rsquared\n",
    "        result = {**coefs, stat.r2: rsquared, stat.p_of_f_test: results.f_pvalue}\n",
    "    else:\n",
    "        raise ValueError('Param \"model\" must be one of {\"linear\", \"ordinal\"}')\n",
    "    return pd.Series(result.values(), result)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "Predicted                                 Interactive Comparison               \\\nMetric                                            LR Coefficient LR R-Squared   \ncategory        label                                                           \nbehavior        antisocial                              -0.28946      0.00006   \n                commonsense contradiction               -1.29356      0.06519   \n                correct fact                            -0.51742      0.01660   \n                empathetic                               0.46971      0.01802   \n                follow up                                0.24425      0.00585   \n                ignore                                  -0.95919      0.01765   \n                incorrect fact                          -0.84437      0.03112   \n                irrelevant                              -0.61683      0.01176   \n                lack of empathy                         -1.37372      0.05880   \n                life info                                0.41711      0.00985   \n                partner contradiction                   -1.19561      0.02366   \n                preference info                          0.17608      0.00244   \n                redundant                               -1.43331      0.02485   \n                self contradiction                      -1.88253      0.05467   \n                topic switch                             0.27619      0.00218   \n                uninterpretable                         -2.72176      0.01343   \ncomparative     consistent                               0.10866      0.01223   \n                emotional                                0.17283      0.02900   \n                engaging                                 0.18520      0.03525   \n                grammatical                              0.12158      0.01315   \n                informative                              0.01279      0.00017   \n                proactive                                0.12632      0.01650   \n                quality                                  0.15941      0.02621   \n                relevant                                 0.09643      0.00947   \nlikert dialogue consistent                               0.09869      0.03437   \n                emotional                                0.18336      0.07204   \n                engaging                                 0.25383      0.14639   \n                grammatical                              0.05884      0.00648   \n                informative                              0.10078      0.01829   \n                proactive                                0.09677      0.02640   \n                quality                                  0.20634      0.07572   \n                relevant                                 0.14551      0.05097   \nlikert turn     consistent                               0.25838      0.06045   \n                emotional                                0.11313      0.01170   \n                engaging                                 0.09135      0.01076   \n                grammatical                              0.15085      0.01652   \n                informative                             -0.20004      0.03776   \n                proactive                                0.30850      0.12035   \n                quality                                  0.25014      0.05242   \n                relevant                                 0.15989      0.03294   \n\nPredicted                                                    \\\nMetric                                    P value of F-test   \ncategory        label                                         \nbehavior        antisocial                          0.91533   \n                commonsense contradiction           0.00035   \n                correct fact                        0.07488   \n                empathetic                          0.06341   \n                follow up                           0.29152   \n                ignore                              0.06623   \n                incorrect fact                      0.01437   \n                irrelevant                          0.13427   \n                lack of empathy                     0.00070   \n                life info                           0.17089   \n                partner contradiction               0.03314   \n                preference info                     0.49596   \n                redundant                           0.02897   \n                self contradiction                  0.00110   \n                topic switch                        0.52006   \n                uninterpretable                     0.10945   \ncomparative     consistent                          0.12675   \n                emotional                           0.01820   \n                engaging                            0.00912   \n                grammatical                         0.11330   \n                informative                         0.85750   \n                proactive                           0.07578   \n                quality                             0.02488   \n                relevant                            0.17929   \nlikert dialogue consistent                          0.01005   \n                emotional                           0.00017   \n                engaging                            0.00000   \n                grammatical                         0.26697   \n                informative                         0.06146   \n                proactive                           0.02433   \n                quality                             0.00011   \n                relevant                            0.00164   \nlikert turn     consistent                          0.00059   \n                emotional                           0.13542   \n                engaging                            0.15213   \n                grammatical                         0.07559   \n                informative                         0.00691   \n                proactive                           0.00000   \n                quality                             0.00140   \n                relevant                            0.01175   \n\nPredicted                                 Interactive Likert               \\\nMetric                                        LR Coefficient LR R-Squared   \ncategory        label                                                       \nbehavior        antisocial                          -0.77421      0.00022   \n                commonsense contradiction           -2.36858      0.10480   \n                correct fact                        -0.48723      0.00799   \n                empathetic                           1.12296      0.05755   \n                follow up                            0.39619      0.00828   \n                ignore                              -3.17356      0.10413   \n                incorrect fact                      -0.36389      0.00282   \n                irrelevant                          -2.37005      0.09497   \n                lack of empathy                     -2.53345      0.10348   \n                life info                            0.15641      0.00062   \n                partner contradiction               -3.47380      0.09521   \n                preference info                      0.00141      0.00000   \n                redundant                           -3.17795      0.06195   \n                self contradiction                  -2.66588      0.04705   \n                topic switch                        -0.42893      0.00279   \n                uninterpretable                     -2.20434      0.00441   \ncomparative     consistent                               NaN          NaN   \n                emotional                                NaN          NaN   \n                engaging                                 NaN          NaN   \n                grammatical                              NaN          NaN   \n                informative                              NaN          NaN   \n                proactive                                NaN          NaN   \n                quality                                  NaN          NaN   \n                relevant                                 NaN          NaN   \nlikert dialogue consistent                           0.11705      0.02455   \n                emotional                            0.25750      0.08123   \n                engaging                             0.23737      0.05985   \n                grammatical                          0.03375      0.00103   \n                informative                          0.13789      0.01674   \n                proactive                            0.20706      0.05358   \n                quality                              0.25193      0.05597   \n                relevant                             0.26832      0.08183   \nlikert turn     consistent                           0.31372      0.04104   \n                emotional                            0.29700      0.04143   \n                engaging                             0.31794      0.06687   \n                grammatical                          0.14299      0.00673   \n                informative                          0.02176      0.00023   \n                proactive                            0.31731      0.06010   \n                quality                              0.31038      0.04231   \n                relevant                             0.29659      0.05510   \n\nPredicted                                                    \\\nMetric                                    P value of F-test   \ncategory        label                                         \nbehavior        antisocial                          0.76585   \n                commonsense contradiction           0.00000   \n                correct fact                        0.07411   \n                empathetic                          0.00000   \n                follow up                           0.06900   \n                ignore                              0.00000   \n                incorrect fact                      0.28973   \n                irrelevant                          0.00000   \n                lack of empathy                     0.00000   \n                life info                           0.62082   \n                partner contradiction               0.00000   \n                preference info                     0.99556   \n                redundant                           0.00000   \n                self contradiction                  0.00001   \n                topic switch                        0.29186   \n                uninterpretable                     0.18509   \ncomparative     consistent                              NaN   \n                emotional                               NaN   \n                engaging                                NaN   \n                grammatical                             NaN   \n                informative                             NaN   \n                proactive                               NaN   \n                quality                                 NaN   \n                relevant                                NaN   \nlikert dialogue consistent                          0.00167   \n                emotional                           0.00000   \n                engaging                            0.00000   \n                grammatical                         0.52140   \n                informative                         0.00958   \n                proactive                           0.00000   \n                quality                             0.00000   \n                relevant                            0.00000   \nlikert turn     consistent                          0.00004   \n                emotional                           0.00004   \n                engaging                            0.00000   \n                grammatical                         0.10126   \n                informative                         0.76329   \n                proactive                           0.00000   \n                quality                             0.00003   \n                relevant                            0.00000   \n\nPredicted                                 Likert Dialogue Quality  \\\nMetric                                             LR Coefficient   \ncategory        label                                               \nbehavior        antisocial                               -0.55548   \n                commonsense contradiction                -1.69743   \n                correct fact                              0.05121   \n                empathetic                                0.88404   \n                follow up                                 0.27118   \n                ignore                                   -1.71655   \n                incorrect fact                           -0.89117   \n                irrelevant                               -1.60563   \n                lack of empathy                          -1.54854   \n                life info                                 0.32752   \n                partner contradiction                    -2.59899   \n                preference info                           0.26322   \n                redundant                                -2.05277   \n                self contradiction                       -1.91209   \n                topic switch                              0.02456   \n                uninterpretable                          -2.73952   \ncomparative     consistent                                    NaN   \n                emotional                                     NaN   \n                engaging                                      NaN   \n                grammatical                                   NaN   \n                informative                                   NaN   \n                proactive                                     NaN   \n                quality                                       NaN   \n                relevant                                      NaN   \nlikert dialogue consistent                                0.33319   \n                emotional                                 0.40710   \n                engaging                                  0.56247   \n                grammatical                               0.26529   \n                informative                               0.41837   \n                proactive                                 0.44016   \n                quality                                   1.00000   \n                relevant                                  0.47207   \nlikert turn     consistent                                0.25186   \n                emotional                                 0.23505   \n                engaging                                  0.19074   \n                grammatical                               0.01671   \n                informative                              -0.05404   \n                proactive                                 0.20584   \n                quality                                   0.24156   \n                relevant                                  0.23057   \n\nPredicted                                                                 \\\nMetric                                    LR R-Squared P value of F-test   \ncategory        label                                                      \nbehavior        antisocial                     0.00013           0.82001   \n                commonsense contradiction      0.06103           0.00000   \n                correct fact                   0.00010           0.84188   \n                empathetic                     0.04044           0.00005   \n                follow up                      0.00440           0.18548   \n                ignore                         0.03455           0.00019   \n                incorrect fact                 0.01915           0.00557   \n                irrelevant                     0.04943           0.00001   \n                lack of empathy                0.04384           0.00002   \n                life info                      0.00306           0.26971   \n                partner contradiction          0.06043           0.00000   \n                preference info                0.00306           0.26993   \n                redundant                      0.02931           0.00058   \n                self contradiction             0.02745           0.00088   \n                topic switch                   0.00001           0.94880   \n                uninterpretable                0.00772           0.07922   \ncomparative     consistent                         NaN               NaN   \n                emotional                          NaN               NaN   \n                engaging                           NaN               NaN   \n                grammatical                        NaN               NaN   \n                informative                        NaN               NaN   \n                proactive                          NaN               NaN   \n                quality                            NaN               NaN   \n                relevant                           NaN               NaN   \nlikert dialogue consistent                     0.22558           0.00000   \n                emotional                      0.23022           0.00000   \n                engaging                       0.38103           0.00000   \n                grammatical                    0.07243           0.00000   \n                informative                    0.17475           0.00000   \n                proactive                      0.27452           0.00000   \n                quality                        1.00000           0.00000   \n                relevant                       0.28720           0.00000   \nlikert turn     consistent                     0.02999           0.00050   \n                emotional                      0.02943           0.00057   \n                engaging                       0.02729           0.00091   \n                grammatical                    0.00010           0.83866   \n                informative                    0.00159           0.42573   \n                proactive                      0.02868           0.00067   \n                quality                        0.02906           0.00062   \n                relevant                       0.03776           0.00009   \n\nPredicted                                 Likert Turn Quality               \\\nMetric                                         LR Coefficient LR R-Squared   \ncategory        label                                                        \nbehavior        antisocial                           -3.70553      0.01164   \n                commonsense contradiction            -1.29550      0.07139   \n                correct fact                         -0.34247      0.00899   \n                empathetic                            0.45030      0.02107   \n                follow up                             0.46015      0.02544   \n                ignore                               -1.74979      0.07209   \n                incorrect fact                       -0.83946      0.03412   \n                irrelevant                           -1.26057      0.06118   \n                lack of empathy                      -1.16185      0.04956   \n                life info                             0.18006      0.00186   \n                partner contradiction                -1.49766      0.04030   \n                preference info                       0.31426      0.00875   \n                redundant                            -0.42368      0.00251   \n                self contradiction                   -1.27412      0.02447   \n                topic switch                         -0.56434      0.01100   \n                uninterpretable                      -1.59035      0.00523   \ncomparative     consistent                                NaN          NaN   \n                emotional                                 NaN          NaN   \n                engaging                                  NaN          NaN   \n                grammatical                               NaN          NaN   \n                informative                               NaN          NaN   \n                proactive                                 NaN          NaN   \n                quality                                   NaN          NaN   \n                relevant                                  NaN          NaN   \nlikert dialogue consistent                            0.03652      0.00544   \n                emotional                             0.11540      0.03715   \n                engaging                              0.06870      0.01141   \n                grammatical                           0.02164      0.00097   \n                informative                           0.01384      0.00038   \n                proactive                             0.05628      0.00901   \n                quality                               0.12029      0.02906   \n                relevant                              0.11919      0.03677   \nlikert turn     consistent                            0.21707      0.04474   \n                emotional                             0.18738      0.03755   \n                engaging                              0.16420      0.04061   \n                grammatical                           0.29094      0.06348   \n                informative                           0.02049      0.00046   \n                proactive                             0.22061      0.06614   \n                quality                               1.00000      1.00000   \n                relevant                              0.26306      0.09870   \n\nPredicted                                                    \nMetric                                    P value of F-test  \ncategory        label                                        \nbehavior        antisocial                          0.03100  \n                commonsense contradiction           0.00000  \n                correct fact                        0.05813  \n                empathetic                          0.00362  \n                follow up                           0.00137  \n                ignore                              0.00000  \n                incorrect fact                      0.00020  \n                irrelevant                          0.00000  \n                lack of empathy                     0.00001  \n                life info                           0.38999  \n                partner contradiction               0.00005  \n                preference info                     0.06159  \n                redundant                           0.31783  \n                self contradiction                  0.00170  \n                topic switch                        0.03599  \n                uninterpretable                     0.14900  \ncomparative     consistent                              NaN  \n                emotional                               NaN  \n                engaging                                NaN  \n                grammatical                             NaN  \n                informative                             NaN  \n                proactive                               NaN  \n                quality                                 NaN  \n                relevant                                NaN  \nlikert dialogue consistent                          0.14075  \n                emotional                           0.00010  \n                engaging                            0.03266  \n                grammatical                         0.53499  \n                informative                         0.69605  \n                proactive                           0.05784  \n                quality                             0.00062  \n                relevant                            0.00011  \nlikert turn     consistent                          0.00002  \n                emotional                           0.00010  \n                engaging                            0.00005  \n                grammatical                         0.00000  \n                informative                         0.66881  \n                proactive                           0.00000  \n                quality                             0.00000  \n                relevant                            0.00000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th>Predicted</th>\n      <th colspan=\"3\" halign=\"left\">Interactive Comparison</th>\n      <th colspan=\"3\" halign=\"left\">Interactive Likert</th>\n      <th colspan=\"3\" halign=\"left\">Likert Dialogue Quality</th>\n      <th colspan=\"3\" halign=\"left\">Likert Turn Quality</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>Metric</th>\n      <th>LR Coefficient</th>\n      <th>LR R-Squared</th>\n      <th>P value of F-test</th>\n      <th>LR Coefficient</th>\n      <th>LR R-Squared</th>\n      <th>P value of F-test</th>\n      <th>LR Coefficient</th>\n      <th>LR R-Squared</th>\n      <th>P value of F-test</th>\n      <th>LR Coefficient</th>\n      <th>LR R-Squared</th>\n      <th>P value of F-test</th>\n    </tr>\n    <tr>\n      <th>category</th>\n      <th>label</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"16\" valign=\"top\">behavior</th>\n      <th>antisocial</th>\n      <td>-0.28946</td>\n      <td>0.00006</td>\n      <td>0.91533</td>\n      <td>-0.77421</td>\n      <td>0.00022</td>\n      <td>0.76585</td>\n      <td>-0.55548</td>\n      <td>0.00013</td>\n      <td>0.82001</td>\n      <td>-3.70553</td>\n      <td>0.01164</td>\n      <td>0.03100</td>\n    </tr>\n    <tr>\n      <th>commonsense contradiction</th>\n      <td>-1.29356</td>\n      <td>0.06519</td>\n      <td>0.00035</td>\n      <td>-2.36858</td>\n      <td>0.10480</td>\n      <td>0.00000</td>\n      <td>-1.69743</td>\n      <td>0.06103</td>\n      <td>0.00000</td>\n      <td>-1.29550</td>\n      <td>0.07139</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>correct fact</th>\n      <td>-0.51742</td>\n      <td>0.01660</td>\n      <td>0.07488</td>\n      <td>-0.48723</td>\n      <td>0.00799</td>\n      <td>0.07411</td>\n      <td>0.05121</td>\n      <td>0.00010</td>\n      <td>0.84188</td>\n      <td>-0.34247</td>\n      <td>0.00899</td>\n      <td>0.05813</td>\n    </tr>\n    <tr>\n      <th>empathetic</th>\n      <td>0.46971</td>\n      <td>0.01802</td>\n      <td>0.06341</td>\n      <td>1.12296</td>\n      <td>0.05755</td>\n      <td>0.00000</td>\n      <td>0.88404</td>\n      <td>0.04044</td>\n      <td>0.00005</td>\n      <td>0.45030</td>\n      <td>0.02107</td>\n      <td>0.00362</td>\n    </tr>\n    <tr>\n      <th>follow up</th>\n      <td>0.24425</td>\n      <td>0.00585</td>\n      <td>0.29152</td>\n      <td>0.39619</td>\n      <td>0.00828</td>\n      <td>0.06900</td>\n      <td>0.27118</td>\n      <td>0.00440</td>\n      <td>0.18548</td>\n      <td>0.46015</td>\n      <td>0.02544</td>\n      <td>0.00137</td>\n    </tr>\n    <tr>\n      <th>ignore</th>\n      <td>-0.95919</td>\n      <td>0.01765</td>\n      <td>0.06623</td>\n      <td>-3.17356</td>\n      <td>0.10413</td>\n      <td>0.00000</td>\n      <td>-1.71655</td>\n      <td>0.03455</td>\n      <td>0.00019</td>\n      <td>-1.74979</td>\n      <td>0.07209</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>incorrect fact</th>\n      <td>-0.84437</td>\n      <td>0.03112</td>\n      <td>0.01437</td>\n      <td>-0.36389</td>\n      <td>0.00282</td>\n      <td>0.28973</td>\n      <td>-0.89117</td>\n      <td>0.01915</td>\n      <td>0.00557</td>\n      <td>-0.83946</td>\n      <td>0.03412</td>\n      <td>0.00020</td>\n    </tr>\n    <tr>\n      <th>irrelevant</th>\n      <td>-0.61683</td>\n      <td>0.01176</td>\n      <td>0.13427</td>\n      <td>-2.37005</td>\n      <td>0.09497</td>\n      <td>0.00000</td>\n      <td>-1.60563</td>\n      <td>0.04943</td>\n      <td>0.00001</td>\n      <td>-1.26057</td>\n      <td>0.06118</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>lack of empathy</th>\n      <td>-1.37372</td>\n      <td>0.05880</td>\n      <td>0.00070</td>\n      <td>-2.53345</td>\n      <td>0.10348</td>\n      <td>0.00000</td>\n      <td>-1.54854</td>\n      <td>0.04384</td>\n      <td>0.00002</td>\n      <td>-1.16185</td>\n      <td>0.04956</td>\n      <td>0.00001</td>\n    </tr>\n    <tr>\n      <th>life info</th>\n      <td>0.41711</td>\n      <td>0.00985</td>\n      <td>0.17089</td>\n      <td>0.15641</td>\n      <td>0.00062</td>\n      <td>0.62082</td>\n      <td>0.32752</td>\n      <td>0.00306</td>\n      <td>0.26971</td>\n      <td>0.18006</td>\n      <td>0.00186</td>\n      <td>0.38999</td>\n    </tr>\n    <tr>\n      <th>partner contradiction</th>\n      <td>-1.19561</td>\n      <td>0.02366</td>\n      <td>0.03314</td>\n      <td>-3.47380</td>\n      <td>0.09521</td>\n      <td>0.00000</td>\n      <td>-2.59899</td>\n      <td>0.06043</td>\n      <td>0.00000</td>\n      <td>-1.49766</td>\n      <td>0.04030</td>\n      <td>0.00005</td>\n    </tr>\n    <tr>\n      <th>preference info</th>\n      <td>0.17608</td>\n      <td>0.00244</td>\n      <td>0.49596</td>\n      <td>0.00141</td>\n      <td>0.00000</td>\n      <td>0.99556</td>\n      <td>0.26322</td>\n      <td>0.00306</td>\n      <td>0.26993</td>\n      <td>0.31426</td>\n      <td>0.00875</td>\n      <td>0.06159</td>\n    </tr>\n    <tr>\n      <th>redundant</th>\n      <td>-1.43331</td>\n      <td>0.02485</td>\n      <td>0.02897</td>\n      <td>-3.17795</td>\n      <td>0.06195</td>\n      <td>0.00000</td>\n      <td>-2.05277</td>\n      <td>0.02931</td>\n      <td>0.00058</td>\n      <td>-0.42368</td>\n      <td>0.00251</td>\n      <td>0.31783</td>\n    </tr>\n    <tr>\n      <th>self contradiction</th>\n      <td>-1.88253</td>\n      <td>0.05467</td>\n      <td>0.00110</td>\n      <td>-2.66588</td>\n      <td>0.04705</td>\n      <td>0.00001</td>\n      <td>-1.91209</td>\n      <td>0.02745</td>\n      <td>0.00088</td>\n      <td>-1.27412</td>\n      <td>0.02447</td>\n      <td>0.00170</td>\n    </tr>\n    <tr>\n      <th>topic switch</th>\n      <td>0.27619</td>\n      <td>0.00218</td>\n      <td>0.52006</td>\n      <td>-0.42893</td>\n      <td>0.00279</td>\n      <td>0.29186</td>\n      <td>0.02456</td>\n      <td>0.00001</td>\n      <td>0.94880</td>\n      <td>-0.56434</td>\n      <td>0.01100</td>\n      <td>0.03599</td>\n    </tr>\n    <tr>\n      <th>uninterpretable</th>\n      <td>-2.72176</td>\n      <td>0.01343</td>\n      <td>0.10945</td>\n      <td>-2.20434</td>\n      <td>0.00441</td>\n      <td>0.18509</td>\n      <td>-2.73952</td>\n      <td>0.00772</td>\n      <td>0.07922</td>\n      <td>-1.59035</td>\n      <td>0.00523</td>\n      <td>0.14900</td>\n    </tr>\n    <tr>\n      <th rowspan=\"8\" valign=\"top\">comparative</th>\n      <th>consistent</th>\n      <td>0.10866</td>\n      <td>0.01223</td>\n      <td>0.12675</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>emotional</th>\n      <td>0.17283</td>\n      <td>0.02900</td>\n      <td>0.01820</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>engaging</th>\n      <td>0.18520</td>\n      <td>0.03525</td>\n      <td>0.00912</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>grammatical</th>\n      <td>0.12158</td>\n      <td>0.01315</td>\n      <td>0.11330</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>informative</th>\n      <td>0.01279</td>\n      <td>0.00017</td>\n      <td>0.85750</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>proactive</th>\n      <td>0.12632</td>\n      <td>0.01650</td>\n      <td>0.07578</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>quality</th>\n      <td>0.15941</td>\n      <td>0.02621</td>\n      <td>0.02488</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>relevant</th>\n      <td>0.09643</td>\n      <td>0.00947</td>\n      <td>0.17929</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th rowspan=\"8\" valign=\"top\">likert dialogue</th>\n      <th>consistent</th>\n      <td>0.09869</td>\n      <td>0.03437</td>\n      <td>0.01005</td>\n      <td>0.11705</td>\n      <td>0.02455</td>\n      <td>0.00167</td>\n      <td>0.33319</td>\n      <td>0.22558</td>\n      <td>0.00000</td>\n      <td>0.03652</td>\n      <td>0.00544</td>\n      <td>0.14075</td>\n    </tr>\n    <tr>\n      <th>emotional</th>\n      <td>0.18336</td>\n      <td>0.07204</td>\n      <td>0.00017</td>\n      <td>0.25750</td>\n      <td>0.08123</td>\n      <td>0.00000</td>\n      <td>0.40710</td>\n      <td>0.23022</td>\n      <td>0.00000</td>\n      <td>0.11540</td>\n      <td>0.03715</td>\n      <td>0.00010</td>\n    </tr>\n    <tr>\n      <th>engaging</th>\n      <td>0.25383</td>\n      <td>0.14639</td>\n      <td>0.00000</td>\n      <td>0.23737</td>\n      <td>0.05985</td>\n      <td>0.00000</td>\n      <td>0.56247</td>\n      <td>0.38103</td>\n      <td>0.00000</td>\n      <td>0.06870</td>\n      <td>0.01141</td>\n      <td>0.03266</td>\n    </tr>\n    <tr>\n      <th>grammatical</th>\n      <td>0.05884</td>\n      <td>0.00648</td>\n      <td>0.26697</td>\n      <td>0.03375</td>\n      <td>0.00103</td>\n      <td>0.52140</td>\n      <td>0.26529</td>\n      <td>0.07243</td>\n      <td>0.00000</td>\n      <td>0.02164</td>\n      <td>0.00097</td>\n      <td>0.53499</td>\n    </tr>\n    <tr>\n      <th>informative</th>\n      <td>0.10078</td>\n      <td>0.01829</td>\n      <td>0.06146</td>\n      <td>0.13789</td>\n      <td>0.01674</td>\n      <td>0.00958</td>\n      <td>0.41837</td>\n      <td>0.17475</td>\n      <td>0.00000</td>\n      <td>0.01384</td>\n      <td>0.00038</td>\n      <td>0.69605</td>\n    </tr>\n    <tr>\n      <th>proactive</th>\n      <td>0.09677</td>\n      <td>0.02640</td>\n      <td>0.02433</td>\n      <td>0.20706</td>\n      <td>0.05358</td>\n      <td>0.00000</td>\n      <td>0.44016</td>\n      <td>0.27452</td>\n      <td>0.00000</td>\n      <td>0.05628</td>\n      <td>0.00901</td>\n      <td>0.05784</td>\n    </tr>\n    <tr>\n      <th>quality</th>\n      <td>0.20634</td>\n      <td>0.07572</td>\n      <td>0.00011</td>\n      <td>0.25193</td>\n      <td>0.05597</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>0.12029</td>\n      <td>0.02906</td>\n      <td>0.00062</td>\n    </tr>\n    <tr>\n      <th>relevant</th>\n      <td>0.14551</td>\n      <td>0.05097</td>\n      <td>0.00164</td>\n      <td>0.26832</td>\n      <td>0.08183</td>\n      <td>0.00000</td>\n      <td>0.47207</td>\n      <td>0.28720</td>\n      <td>0.00000</td>\n      <td>0.11919</td>\n      <td>0.03677</td>\n      <td>0.00011</td>\n    </tr>\n    <tr>\n      <th rowspan=\"8\" valign=\"top\">likert turn</th>\n      <th>consistent</th>\n      <td>0.25838</td>\n      <td>0.06045</td>\n      <td>0.00059</td>\n      <td>0.31372</td>\n      <td>0.04104</td>\n      <td>0.00004</td>\n      <td>0.25186</td>\n      <td>0.02999</td>\n      <td>0.00050</td>\n      <td>0.21707</td>\n      <td>0.04474</td>\n      <td>0.00002</td>\n    </tr>\n    <tr>\n      <th>emotional</th>\n      <td>0.11313</td>\n      <td>0.01170</td>\n      <td>0.13542</td>\n      <td>0.29700</td>\n      <td>0.04143</td>\n      <td>0.00004</td>\n      <td>0.23505</td>\n      <td>0.02943</td>\n      <td>0.00057</td>\n      <td>0.18738</td>\n      <td>0.03755</td>\n      <td>0.00010</td>\n    </tr>\n    <tr>\n      <th>engaging</th>\n      <td>0.09135</td>\n      <td>0.01076</td>\n      <td>0.15213</td>\n      <td>0.31794</td>\n      <td>0.06687</td>\n      <td>0.00000</td>\n      <td>0.19074</td>\n      <td>0.02729</td>\n      <td>0.00091</td>\n      <td>0.16420</td>\n      <td>0.04061</td>\n      <td>0.00005</td>\n    </tr>\n    <tr>\n      <th>grammatical</th>\n      <td>0.15085</td>\n      <td>0.01652</td>\n      <td>0.07559</td>\n      <td>0.14299</td>\n      <td>0.00673</td>\n      <td>0.10126</td>\n      <td>0.01671</td>\n      <td>0.00010</td>\n      <td>0.83866</td>\n      <td>0.29094</td>\n      <td>0.06348</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>informative</th>\n      <td>-0.20004</td>\n      <td>0.03776</td>\n      <td>0.00691</td>\n      <td>0.02176</td>\n      <td>0.00023</td>\n      <td>0.76329</td>\n      <td>-0.05404</td>\n      <td>0.00159</td>\n      <td>0.42573</td>\n      <td>0.02049</td>\n      <td>0.00046</td>\n      <td>0.66881</td>\n    </tr>\n    <tr>\n      <th>proactive</th>\n      <td>0.30850</td>\n      <td>0.12035</td>\n      <td>0.00000</td>\n      <td>0.31731</td>\n      <td>0.06010</td>\n      <td>0.00000</td>\n      <td>0.20584</td>\n      <td>0.02868</td>\n      <td>0.00067</td>\n      <td>0.22061</td>\n      <td>0.06614</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>quality</th>\n      <td>0.25014</td>\n      <td>0.05242</td>\n      <td>0.00140</td>\n      <td>0.31038</td>\n      <td>0.04231</td>\n      <td>0.00003</td>\n      <td>0.24156</td>\n      <td>0.02906</td>\n      <td>0.00062</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>relevant</th>\n      <td>0.15989</td>\n      <td>0.03294</td>\n      <td>0.01175</td>\n      <td>0.29659</td>\n      <td>0.05510</td>\n      <td>0.00000</td>\n      <td>0.23057</td>\n      <td>0.03776</td>\n      <td>0.00009</td>\n      <td>0.26306</td>\n      <td>0.09870</td>\n      <td>0.00000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@to_file\n",
    "def dialogue_quality_regressions(data):\n",
    "    ldq, ltq, icq, idq = all_dialogue_metrics(data)\n",
    "    ldq_groups = ldq.groupby([sym.category, sym.label])\n",
    "    ltq_groups = ltq.groupby([sym.category, sym.label])\n",
    "    icq_groups = icq.groupby([sym.category, sym.label])\n",
    "    idq_groups = idq.groupby([sym.category, sym.label])\n",
    "    names = ['Predicted', 'Metric']\n",
    "    linear_result = ldq_groups.apply(lambda x: regressions(x, model='linear'))\n",
    "    linear_result.columns = pd.MultiIndex.from_arrays(\n",
    "        [['Likert Dialogue Quality']*3,\n",
    "        ['LR Coefficient', 'LR R-Squared', stat.p_of_f_test]],\n",
    "        names=names\n",
    "    )\n",
    "    ordinal_result = ldq_groups.apply(lambda x: regressions(x, model='ordinal'))\n",
    "    ordinal_result.columns = pd.MultiIndex.from_arrays(\n",
    "        [['Likert Dialogue Quality']*2,\n",
    "        ['OR Pseudo R-Squared', stat.p_of_llr_test]],\n",
    "        names=names\n",
    "    )\n",
    "    linear_turn_result = ltq_groups.apply(regressions)\n",
    "    linear_turn_result.columns = pd.MultiIndex.from_arrays(\n",
    "        [['Likert Turn Quality']*3,\n",
    "        ['LR Coefficient', 'LR R-Squared', stat.p_of_f_test]],\n",
    "        names=names\n",
    "    )\n",
    "    linear_compare_result = icq_groups.apply(regressions)\n",
    "    linear_compare_result.columns = pd.MultiIndex.from_arrays(\n",
    "        [['Interactive Comparison']*3,\n",
    "        ['LR Coefficient', 'LR R-Squared', stat.p_of_f_test]],\n",
    "        names=names\n",
    "    )\n",
    "    interactive_dial_result = idq_groups.apply(regressions)\n",
    "    interactive_dial_result.columns = pd.MultiIndex.from_arrays(\n",
    "        [['Interactive Likert']*3,\n",
    "        ['LR Coefficient', 'LR R-Squared', stat.p_of_f_test]],\n",
    "        names=names\n",
    "    )\n",
    "    result = pd.concat(( linear_compare_result, interactive_dial_result, linear_result, linear_turn_result), axis=1)\n",
    "    return result.round(5)\n",
    "\n",
    "regs = dialogue_quality_regressions(\n",
    "    data,\n",
    "    load='results/dialogue_quality_regressions'\n",
    ")\n",
    "regs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "Predicted         category                      label Likert Dialogue Quality  \\\nMetric                                                           LR R-Squared   \n0                 behavior                 antisocial                 0.00013   \n1                 behavior  commonsense contradiction                 0.06103   \n2                 behavior               correct fact                 0.00010   \n3                 behavior                 empathetic                 0.04044   \n4                 behavior                  follow up                 0.00440   \n5                 behavior                     ignore                 0.03455   \n6                 behavior             incorrect fact                 0.01915   \n7                 behavior                 irrelevant                 0.04943   \n8                 behavior            lack of empathy                 0.04384   \n9                 behavior                  life info                 0.00306   \n10                behavior      partner contradiction                 0.06043   \n11                behavior            preference info                 0.00306   \n12                behavior                  redundant                 0.02931   \n13                behavior         self contradiction                 0.02745   \n14                behavior               topic switch                 0.00001   \n15                behavior            uninterpretable                 0.00772   \n16             comparative                 consistent                     NaN   \n17             comparative                  emotional                     NaN   \n18             comparative                   engaging                     NaN   \n19             comparative                grammatical                     NaN   \n20             comparative                informative                     NaN   \n21             comparative                  proactive                     NaN   \n22             comparative                    quality                     NaN   \n23             comparative                   relevant                     NaN   \n24         likert dialogue                 consistent                 0.22558   \n25         likert dialogue                  emotional                 0.23022   \n26         likert dialogue                   engaging                 0.38103   \n27         likert dialogue                grammatical                 0.07243   \n28         likert dialogue                informative                 0.17475   \n29         likert dialogue                  proactive                 0.27452   \n30         likert dialogue                   relevant                 0.28720   \n31             likert turn                 consistent                 0.02999   \n32             likert turn                  emotional                 0.02943   \n33             likert turn                   engaging                 0.02729   \n34             likert turn                grammatical                 0.00010   \n35             likert turn                informative                 0.00159   \n36             likert turn                  proactive                 0.02868   \n37             likert turn                    quality                 0.02906   \n38             likert turn                   relevant                 0.03776   \n\nPredicted                    \nMetric    P value of F-test  \n0                   0.82001  \n1                   0.00000  \n2                   0.84188  \n3                   0.00005  \n4                   0.18548  \n5                   0.00019  \n6                   0.00557  \n7                   0.00001  \n8                   0.00002  \n9                   0.26971  \n10                  0.00000  \n11                  0.26993  \n12                  0.00058  \n13                  0.00088  \n14                  0.94880  \n15                  0.07922  \n16                      NaN  \n17                      NaN  \n18                      NaN  \n19                      NaN  \n20                      NaN  \n21                      NaN  \n22                      NaN  \n23                      NaN  \n24                  0.00000  \n25                  0.00000  \n26                  0.00000  \n27                  0.00000  \n28                  0.00000  \n29                  0.00000  \n30                  0.00000  \n31                  0.00050  \n32                  0.00057  \n33                  0.00091  \n34                  0.83866  \n35                  0.42573  \n36                  0.00067  \n37                  0.00062  \n38                  0.00009  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th>Predicted</th>\n      <th>category</th>\n      <th>label</th>\n      <th colspan=\"2\" halign=\"left\">Likert Dialogue Quality</th>\n    </tr>\n    <tr>\n      <th>Metric</th>\n      <th></th>\n      <th></th>\n      <th>LR R-Squared</th>\n      <th>P value of F-test</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>behavior</td>\n      <td>antisocial</td>\n      <td>0.00013</td>\n      <td>0.82001</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>behavior</td>\n      <td>commonsense contradiction</td>\n      <td>0.06103</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>behavior</td>\n      <td>correct fact</td>\n      <td>0.00010</td>\n      <td>0.84188</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>behavior</td>\n      <td>empathetic</td>\n      <td>0.04044</td>\n      <td>0.00005</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>behavior</td>\n      <td>follow up</td>\n      <td>0.00440</td>\n      <td>0.18548</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>behavior</td>\n      <td>ignore</td>\n      <td>0.03455</td>\n      <td>0.00019</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>behavior</td>\n      <td>incorrect fact</td>\n      <td>0.01915</td>\n      <td>0.00557</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>behavior</td>\n      <td>irrelevant</td>\n      <td>0.04943</td>\n      <td>0.00001</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>behavior</td>\n      <td>lack of empathy</td>\n      <td>0.04384</td>\n      <td>0.00002</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>behavior</td>\n      <td>life info</td>\n      <td>0.00306</td>\n      <td>0.26971</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>behavior</td>\n      <td>partner contradiction</td>\n      <td>0.06043</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>behavior</td>\n      <td>preference info</td>\n      <td>0.00306</td>\n      <td>0.26993</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>behavior</td>\n      <td>redundant</td>\n      <td>0.02931</td>\n      <td>0.00058</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>behavior</td>\n      <td>self contradiction</td>\n      <td>0.02745</td>\n      <td>0.00088</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>behavior</td>\n      <td>topic switch</td>\n      <td>0.00001</td>\n      <td>0.94880</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>behavior</td>\n      <td>uninterpretable</td>\n      <td>0.00772</td>\n      <td>0.07922</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>comparative</td>\n      <td>consistent</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>comparative</td>\n      <td>emotional</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>comparative</td>\n      <td>engaging</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>comparative</td>\n      <td>grammatical</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>comparative</td>\n      <td>informative</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>comparative</td>\n      <td>proactive</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>comparative</td>\n      <td>quality</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>comparative</td>\n      <td>relevant</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>likert dialogue</td>\n      <td>consistent</td>\n      <td>0.22558</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>likert dialogue</td>\n      <td>emotional</td>\n      <td>0.23022</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>likert dialogue</td>\n      <td>engaging</td>\n      <td>0.38103</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>likert dialogue</td>\n      <td>grammatical</td>\n      <td>0.07243</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>likert dialogue</td>\n      <td>informative</td>\n      <td>0.17475</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>likert dialogue</td>\n      <td>proactive</td>\n      <td>0.27452</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>likert dialogue</td>\n      <td>relevant</td>\n      <td>0.28720</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>likert turn</td>\n      <td>consistent</td>\n      <td>0.02999</td>\n      <td>0.00050</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>likert turn</td>\n      <td>emotional</td>\n      <td>0.02943</td>\n      <td>0.00057</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>likert turn</td>\n      <td>engaging</td>\n      <td>0.02729</td>\n      <td>0.00091</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>likert turn</td>\n      <td>grammatical</td>\n      <td>0.00010</td>\n      <td>0.83866</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>likert turn</td>\n      <td>informative</td>\n      <td>0.00159</td>\n      <td>0.42573</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>likert turn</td>\n      <td>proactive</td>\n      <td>0.02868</td>\n      <td>0.00067</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>likert turn</td>\n      <td>quality</td>\n      <td>0.02906</td>\n      <td>0.00062</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>likert turn</td>\n      <td>relevant</td>\n      <td>0.03776</td>\n      <td>0.00009</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_plot_regs = regs[[(\"Likert Dialogue Quality\", \"LR R-Squared\"), (\"Likert Dialogue Quality\", \"P value of F-test\")]]\n",
    "to_plot_regs = to_plot_regs.drop((\"likert dialogue\", \"quality\"))\n",
    "to_plot_regs = to_plot_regs.reset_index()\n",
    "to_plot_regs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "regs = prettify(regs, to_csv=\"results/paper/predictive_validity.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Incremental Validity"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "                                       Adjusted R-Squared  P value of F-test\nlikert turn consistent                            0.17799            0.00000\nbehavior    empathetic                            0.17776            0.00000\n            uninterpretable                       0.16896            0.00000\nlikert turn emotional                             0.16587            0.00000\nbehavior    ignore                                0.16495            0.00000\n            preference info                       0.16420            0.00000\nlikert turn informative                           0.16244            0.00000\n            grammatical                           0.16110            0.00000\nbehavior    antisocial                            0.15754            0.00000\nlikert turn relevant                              0.15748            0.00000\nbehavior    redundant                             0.15261            0.00000\n            correct fact                          0.14719            0.00000\n            topic switch                          0.14207            0.00000\n            commonsense contradiction             0.13828            0.00000\n            life info                             0.13499            0.00000\nlikert turn engaging                              0.13445            0.00000\nbehavior    incorrect fact                        0.13114            0.00000\nlikert turn proactive                             0.12112            0.00000\nbehavior    follow up                             0.11408            0.00000\n            self contradiction                    0.11289            0.00000\n            partner contradiction                 0.09110            0.00000\n            lack of empathy                       0.06708            0.00000\n            irrelevant                            0.04943            0.00001",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>Adjusted R-Squared</th>\n      <th>P value of F-test</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>likert turn</th>\n      <th>consistent</th>\n      <td>0.17799</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">behavior</th>\n      <th>empathetic</th>\n      <td>0.17776</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>uninterpretable</th>\n      <td>0.16896</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>likert turn</th>\n      <th>emotional</th>\n      <td>0.16587</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">behavior</th>\n      <th>ignore</th>\n      <td>0.16495</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>preference info</th>\n      <td>0.16420</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">likert turn</th>\n      <th>informative</th>\n      <td>0.16244</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>grammatical</th>\n      <td>0.16110</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>behavior</th>\n      <th>antisocial</th>\n      <td>0.15754</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>likert turn</th>\n      <th>relevant</th>\n      <td>0.15748</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">behavior</th>\n      <th>redundant</th>\n      <td>0.15261</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>correct fact</th>\n      <td>0.14719</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>topic switch</th>\n      <td>0.14207</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>commonsense contradiction</th>\n      <td>0.13828</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>life info</th>\n      <td>0.13499</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>likert turn</th>\n      <th>engaging</th>\n      <td>0.13445</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>behavior</th>\n      <th>incorrect fact</th>\n      <td>0.13114</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>likert turn</th>\n      <th>proactive</th>\n      <td>0.12112</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">behavior</th>\n      <th>follow up</th>\n      <td>0.11408</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>self contradiction</th>\n      <td>0.11289</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>partner contradiction</th>\n      <td>0.09110</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>lack of empathy</th>\n      <td>0.06708</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>irrelevant</th>\n      <td>0.04943</td>\n      <td>0.00001</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def drop_column_level_duplication(df: pd.DataFrame, columns, levels=None):\n",
    "    if levels is None:\n",
    "        levels = list(range(len(columns)))\n",
    "    level_columns = df.xs(columns, axis=1, level=levels)\n",
    "    unique = level_columns.iloc[:,0].to_frame()\n",
    "    unique.columns = [columns]\n",
    "    dropped = df.drop(columns=columns, level=levels)\n",
    "    result = pd.concat([dropped, unique], axis=1)\n",
    "    return result\n",
    "\n",
    "def multivariate_regression(df: pd.DataFrame, model='linear'):\n",
    "    def apply_regressions(df: pd.DataFrame):\n",
    "        unstacked = df.unstack([sym.category, sym.label])\n",
    "        unstacked = drop_column_level_duplication(unstacked, 'quality', 0)\n",
    "        results = regressions(unstacked, quality_column_name='quality', model=model)\n",
    "        return results\n",
    "    result = apply_regressions(df)\n",
    "    result.index = [\n",
    "        (idx[1] if isinstance(idx, tuple) else idx)\n",
    "        for idx in result.index.values\n",
    "    ]\n",
    "    return result.round(5)\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "@to_file\n",
    "def incremental_regression(\n",
    "        df: pd.DataFrame,\n",
    "        categories,\n",
    "        model='linear',\n",
    "        exclude_quality=True,\n",
    "        beam=1,\n",
    "        select='backward'\n",
    "):\n",
    "    data_points = set(df.index.get_level_values('dialogue'))\n",
    "    num_data_points = len(data_points)\n",
    "    adjust = lambda r2, f: 1 - (1 - r2) * ((num_data_points - 1) / (num_data_points - f))\n",
    "    Step: type = namedtuple('Step', ('r2', 'p', 'feature'))\n",
    "    class Path(list):\n",
    "        def metric(self):\n",
    "            # if len(self) == 0: return 0\n",
    "            # else: return self[-1].llr if len(self) == 1 else self[-1].llr / self[-2].llr\n",
    "            return self.r2\n",
    "        @property\n",
    "        def r2(self):\n",
    "            return adjust(self[-1].r2, len(self)) if self else 0\n",
    "        # @property\n",
    "        # def adj_r2(self):\n",
    "        #     return adjust(self.r2, len(self))\n",
    "        @property\n",
    "        def p(self): return self[-1].p if self else 1\n",
    "        @property\n",
    "        def features(self): return {x.feature for x in self}\n",
    "    r2_name = stat.r2 if model=='linear' else stat.mcfad_r2\n",
    "    p_name = stat.p_of_f_test if model=='linear' else stat.p_of_llr_test\n",
    "    frontier = [Path()]\n",
    "    feature_pool = {\n",
    "        x[:2] for x in df.index.values\n",
    "        if (not (exclude_quality and scale.quality in x))\n",
    "        and x[0] in categories\n",
    "    }\n",
    "    for _ in feature_pool:\n",
    "        new_frontier = []\n",
    "        for path in frontier:\n",
    "            for candidate in feature_pool - path.features:\n",
    "                if select == 'forward':\n",
    "                    candidate_features = path.features | {candidate}\n",
    "                elif select == 'backward':\n",
    "                    candidate_features = feature_pool - path.features\n",
    "                else:\n",
    "                    raise ValueError('param select must be one of {\"forward\", \"backward\"}')\n",
    "                row_mask = [\n",
    "                    x[:2] in candidate_features\n",
    "                    and (not (exclude_quality and scale.quality in x))\n",
    "                    and x[0] in categories\n",
    "                    for x in df.index.values\n",
    "                ]\n",
    "                candidate_df = df.loc[row_mask, :]\n",
    "                candidate_results = multivariate_regression(candidate_df, model=model)\n",
    "                r2 = candidate_results[r2_name].item()\n",
    "                p = candidate_results[p_name]\n",
    "                new_frontier.append(Path([*path, Step(r2, p, candidate)]))\n",
    "        frontier = sorted(new_frontier, key=lambda x: x.metric(), reverse=True)[:beam]\n",
    "    result = {step.feature: {'Adjusted R-Squared': step.r2, p_name: step.p} for step in frontier[0]}\n",
    "    return pd.DataFrame(result.values(), result)\n",
    "\n",
    "\n",
    "ldq, ltq, icq, idq = all_dialogue_metrics(data)\n",
    "regs = incremental_regression(\n",
    "    ldq, (category.likert_turn, category.behavior), beam=1,\n",
    "    load='results/dialogue_incremental_regressions'\n",
    ")\n",
    "regs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "                                    Adjusted R-Squared  P value of F-test\nbehavior antisocial                            0.15964                0.0\n         ignore                                0.15955                0.0\n         life info                             0.15907                0.0\n         preference info                       0.15813                0.0\n         commonsense contradiction             0.15663                0.0\n         uninterpretable                       0.15466                0.0\n         correct fact                          0.15197                0.0\n         topic switch                          0.14809                0.0\n         follow up                             0.14527                0.0\n         redundant                             0.14366                0.0\n         lack of empathy                       0.13925                0.0\n         incorrect fact                        0.13547                0.0\n         self contradiction                    0.12608                0.0\n         irrelevant                            0.11049                0.0\n         empathetic                            0.09489                0.0\n         partner contradiction                 0.06043                0.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>Adjusted R-Squared</th>\n      <th>P value of F-test</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"16\" valign=\"top\">behavior</th>\n      <th>antisocial</th>\n      <td>0.15964</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>ignore</th>\n      <td>0.15955</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>life info</th>\n      <td>0.15907</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>preference info</th>\n      <td>0.15813</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>commonsense contradiction</th>\n      <td>0.15663</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>uninterpretable</th>\n      <td>0.15466</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>correct fact</th>\n      <td>0.15197</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>topic switch</th>\n      <td>0.14809</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>follow up</th>\n      <td>0.14527</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>redundant</th>\n      <td>0.14366</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>lack of empathy</th>\n      <td>0.13925</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>incorrect fact</th>\n      <td>0.13547</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>self contradiction</th>\n      <td>0.12608</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>irrelevant</th>\n      <td>0.11049</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>empathetic</th>\n      <td>0.09489</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>partner contradiction</th>\n      <td>0.06043</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "behavior_regs = incremental_regression(\n",
    "    ldq, (category.behavior,), beam=10,\n",
    "    load='results/behavior_incremental_regressions'\n",
    ")\n",
    "behavior_regs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "                                    Adjusted R-Squared  P value of F-test\nbehavior antisocial                            0.26030                0.0\n         life info                             0.26013                0.0\n         topic switch                          0.25980                0.0\n         preference info                       0.25966                0.0\n         incorrect fact                        0.25940                0.0\n         partner contradiction                 0.25912                0.0\n         uninterpretable                       0.25831                0.0\n         follow up                             0.25716                0.0\n         correct fact                          0.25588                0.0\n         ignore                                0.25222                0.0\n         commonsense contradiction             0.24564                0.0\n         empathetic                            0.23713                0.0\n         redundant                             0.22221                0.0\n         irrelevant                            0.18954                0.0\n         self contradiction                    0.14296                0.0\n         lack of empathy                       0.10348                0.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>Adjusted R-Squared</th>\n      <th>P value of F-test</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"16\" valign=\"top\">behavior</th>\n      <th>antisocial</th>\n      <td>0.26030</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>life info</th>\n      <td>0.26013</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>topic switch</th>\n      <td>0.25980</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>preference info</th>\n      <td>0.25966</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>incorrect fact</th>\n      <td>0.25940</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>partner contradiction</th>\n      <td>0.25912</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>uninterpretable</th>\n      <td>0.25831</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>follow up</th>\n      <td>0.25716</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>correct fact</th>\n      <td>0.25588</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>ignore</th>\n      <td>0.25222</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>commonsense contradiction</th>\n      <td>0.24564</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>empathetic</th>\n      <td>0.23713</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>redundant</th>\n      <td>0.22221</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>irrelevant</th>\n      <td>0.18954</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>self contradiction</th>\n      <td>0.14296</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>lack of empathy</th>\n      <td>0.10348</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "behavior_regs = incremental_regression(\n",
    "    idq, (category.behavior,), beam=10,\n",
    "    load='results/behavior_incremental_regressions_interactive'\n",
    ")\n",
    "behavior_regs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "                                    Adjusted R-Squared  P value of F-test\nbehavior antisocial                            0.18339            0.00221\n         ignore                                0.18338            0.00129\n         topic switch                          0.18322            0.00074\n         preference info                       0.18310            0.00040\n         partner contradiction                 0.18230            0.00022\n         correct fact                          0.18098            0.00012\n         irrelevant                            0.17869            0.00007\n         empathetic                            0.17866            0.00003\n         commonsense contradiction             0.17335            0.00002\n         life info                             0.16845            0.00001\n         uninterpretable                       0.16153            0.00001\n         follow up                             0.15323            0.00001\n         redundant                             0.14371            0.00001\n         incorrect fact                        0.12315            0.00002\n         self contradiction                    0.10889            0.00002\n         lack of empathy                       0.05880            0.00070",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>Adjusted R-Squared</th>\n      <th>P value of F-test</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"16\" valign=\"top\">behavior</th>\n      <th>antisocial</th>\n      <td>0.18339</td>\n      <td>0.00221</td>\n    </tr>\n    <tr>\n      <th>ignore</th>\n      <td>0.18338</td>\n      <td>0.00129</td>\n    </tr>\n    <tr>\n      <th>topic switch</th>\n      <td>0.18322</td>\n      <td>0.00074</td>\n    </tr>\n    <tr>\n      <th>preference info</th>\n      <td>0.18310</td>\n      <td>0.00040</td>\n    </tr>\n    <tr>\n      <th>partner contradiction</th>\n      <td>0.18230</td>\n      <td>0.00022</td>\n    </tr>\n    <tr>\n      <th>correct fact</th>\n      <td>0.18098</td>\n      <td>0.00012</td>\n    </tr>\n    <tr>\n      <th>irrelevant</th>\n      <td>0.17869</td>\n      <td>0.00007</td>\n    </tr>\n    <tr>\n      <th>empathetic</th>\n      <td>0.17866</td>\n      <td>0.00003</td>\n    </tr>\n    <tr>\n      <th>commonsense contradiction</th>\n      <td>0.17335</td>\n      <td>0.00002</td>\n    </tr>\n    <tr>\n      <th>life info</th>\n      <td>0.16845</td>\n      <td>0.00001</td>\n    </tr>\n    <tr>\n      <th>uninterpretable</th>\n      <td>0.16153</td>\n      <td>0.00001</td>\n    </tr>\n    <tr>\n      <th>follow up</th>\n      <td>0.15323</td>\n      <td>0.00001</td>\n    </tr>\n    <tr>\n      <th>redundant</th>\n      <td>0.14371</td>\n      <td>0.00001</td>\n    </tr>\n    <tr>\n      <th>incorrect fact</th>\n      <td>0.12315</td>\n      <td>0.00002</td>\n    </tr>\n    <tr>\n      <th>self contradiction</th>\n      <td>0.10889</td>\n      <td>0.00002</td>\n    </tr>\n    <tr>\n      <th>lack of empathy</th>\n      <td>0.05880</td>\n      <td>0.00070</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "behavior_regs_comp = incremental_regression(\n",
    "    icq, (category.behavior,), beam=10,\n",
    "    load='results/behavior_incremental_regressions_comparative'\n",
    ")\n",
    "behavior_regs_comp"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "                         Adjusted R-Squared  P value of F-test\nlikert turn grammatical             0.08566            0.00001\n            informative             0.08508            0.00000\n            engaging                0.08285            0.00000\n            emotional               0.07753            0.00000\n            consistent              0.06889            0.00000\n            proactive               0.05786            0.00001\n            relevant                0.03776            0.00009",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>Adjusted R-Squared</th>\n      <th>P value of F-test</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"7\" valign=\"top\">likert turn</th>\n      <th>grammatical</th>\n      <td>0.08566</td>\n      <td>0.00001</td>\n    </tr>\n    <tr>\n      <th>informative</th>\n      <td>0.08508</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>engaging</th>\n      <td>0.08285</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>emotional</th>\n      <td>0.07753</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>consistent</th>\n      <td>0.06889</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>proactive</th>\n      <td>0.05786</td>\n      <td>0.00001</td>\n    </tr>\n    <tr>\n      <th>relevant</th>\n      <td>0.03776</td>\n      <td>0.00009</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likert_turn_regs = incremental_regression(\n",
    "    ldq, (category.likert_turn,), beam=10,\n",
    "    load='results/likert_turn_incremental_regressions'\n",
    ")\n",
    "likert_turn_regs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "                         Adjusted R-Squared  P value of F-test\nlikert turn informative             0.14708                0.0\n            grammatical             0.14651                0.0\n            emotional               0.14410                0.0\n            consistent              0.13808                0.0\n            relevant                0.12962                0.0\n            proactive               0.10285                0.0\n            engaging                0.06687                0.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>Adjusted R-Squared</th>\n      <th>P value of F-test</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"7\" valign=\"top\">likert turn</th>\n      <th>informative</th>\n      <td>0.14708</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>grammatical</th>\n      <td>0.14651</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>emotional</th>\n      <td>0.14410</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>consistent</th>\n      <td>0.13808</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>relevant</th>\n      <td>0.12962</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>proactive</th>\n      <td>0.10285</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>engaging</th>\n      <td>0.06687</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likert_turn_regs = incremental_regression(\n",
    "    idq, (category.likert_turn,), beam=10,\n",
    "    load='results/likert_turn_incremental_regressions_interactive'\n",
    ")\n",
    "likert_turn_regs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "                         Adjusted R-Squared  P value of F-test\nlikert turn emotional               0.19089                0.0\n            engaging                0.19059                0.0\n            grammatical             0.19002                0.0\n            relevant                0.18330                0.0\n            informative             0.17103                0.0\n            consistent              0.14697                0.0\n            proactive               0.12035                0.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>Adjusted R-Squared</th>\n      <th>P value of F-test</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"7\" valign=\"top\">likert turn</th>\n      <th>emotional</th>\n      <td>0.19089</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>engaging</th>\n      <td>0.19059</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>grammatical</th>\n      <td>0.19002</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>relevant</th>\n      <td>0.18330</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>informative</th>\n      <td>0.17103</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>consistent</th>\n      <td>0.14697</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>proactive</th>\n      <td>0.12035</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likert_turn_regs_comp = incremental_regression(\n",
    "    icq, (category.likert_turn,), beam=10,\n",
    "    load='results/likert_turn_incremental_regressions_comparative'\n",
    ")\n",
    "likert_turn_regs_comp"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "                             Adjusted R-Squared  P value of F-test\nlikert dialogue emotional               0.58426                0.0\n                informative             0.57832                0.0\n                grammatical             0.56439                0.0\n                relevant                0.54517                0.0\n                proactive               0.51636                0.0\n                consistent              0.48673                0.0\n                engaging                0.38103                0.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>Adjusted R-Squared</th>\n      <th>P value of F-test</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"7\" valign=\"top\">likert dialogue</th>\n      <th>emotional</th>\n      <td>0.58426</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>informative</th>\n      <td>0.57832</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>grammatical</th>\n      <td>0.56439</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>relevant</th>\n      <td>0.54517</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>proactive</th>\n      <td>0.51636</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>consistent</th>\n      <td>0.48673</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>engaging</th>\n      <td>0.38103</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likert_dialogue_regs = incremental_regression(\n",
    "    ldq, (category.likert_dialogue,), beam=10,\n",
    "    load='results/likert_dialogue_incremental_regressions'\n",
    ")\n",
    "likert_dialogue_regs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "                             Adjusted R-Squared  P value of F-test\nlikert dialogue informative             0.12078                0.0\n                consistent              0.12078                0.0\n                grammatical             0.12052                0.0\n                engaging                0.12010                0.0\n                proactive               0.11942                0.0\n                emotional               0.10604                0.0\n                relevant                0.08183                0.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>Adjusted R-Squared</th>\n      <th>P value of F-test</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"7\" valign=\"top\">likert dialogue</th>\n      <th>informative</th>\n      <td>0.12078</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>consistent</th>\n      <td>0.12078</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>grammatical</th>\n      <td>0.12052</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>engaging</th>\n      <td>0.12010</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>proactive</th>\n      <td>0.11942</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>emotional</th>\n      <td>0.10604</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>relevant</th>\n      <td>0.08183</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likert_dialogue_regs = incremental_regression(\n",
    "    idq, (category.likert_dialogue,), beam=10,\n",
    "    load='results/likert_dialogue_incremental_regressions_interactive'\n",
    ")\n",
    "likert_dialogue_regs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "                             Adjusted R-Squared  P value of F-test\nlikert dialogue relevant                0.16572            0.00002\n                grammatical             0.16572            0.00001\n                informative             0.16470            0.00000\n                proactive               0.16335            0.00000\n                consistent              0.15861            0.00000\n                emotional               0.15367            0.00000\n                engaging                0.14639            0.00000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>Adjusted R-Squared</th>\n      <th>P value of F-test</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"7\" valign=\"top\">likert dialogue</th>\n      <th>relevant</th>\n      <td>0.16572</td>\n      <td>0.00002</td>\n    </tr>\n    <tr>\n      <th>grammatical</th>\n      <td>0.16572</td>\n      <td>0.00001</td>\n    </tr>\n    <tr>\n      <th>informative</th>\n      <td>0.16470</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>proactive</th>\n      <td>0.16335</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>consistent</th>\n      <td>0.15861</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>emotional</th>\n      <td>0.15367</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>engaging</th>\n      <td>0.14639</td>\n      <td>0.00000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likert_dialogue_regs_comp = incremental_regression(\n",
    "    icq, (category.likert_dialogue,), beam=10,\n",
    "    load='results/likert_dialogue_incremental_regressions_comparative'\n",
    ")\n",
    "likert_dialogue_regs_comp"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "data": {
      "text/plain": "                         Adjusted R-Squared  P value of F-test\ncomparative proactive               0.05369            0.17270\n            consistent              0.05298            0.11737\n            relevant                0.05138            0.07843\n            grammatical             0.04877            0.05184\n            informative             0.04748            0.02712\n            emotional               0.04205            0.01725\n            engaging                0.03525            0.00912",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>Adjusted R-Squared</th>\n      <th>P value of F-test</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"7\" valign=\"top\">comparative</th>\n      <th>proactive</th>\n      <td>0.05369</td>\n      <td>0.17270</td>\n    </tr>\n    <tr>\n      <th>consistent</th>\n      <td>0.05298</td>\n      <td>0.11737</td>\n    </tr>\n    <tr>\n      <th>relevant</th>\n      <td>0.05138</td>\n      <td>0.07843</td>\n    </tr>\n    <tr>\n      <th>grammatical</th>\n      <td>0.04877</td>\n      <td>0.05184</td>\n    </tr>\n    <tr>\n      <th>informative</th>\n      <td>0.04748</td>\n      <td>0.02712</td>\n    </tr>\n    <tr>\n      <th>emotional</th>\n      <td>0.04205</td>\n      <td>0.01725</td>\n    </tr>\n    <tr>\n      <th>engaging</th>\n      <td>0.03525</td>\n      <td>0.00912</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparative_dialogue_regs_comp = incremental_regression(\n",
    "    icq, (category.comparative,), beam=10,\n",
    "    load='results/comparative_incremental_regressions_comparative'\n",
    ")\n",
    "comparative_dialogue_regs_comp"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Table for Paper"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "                     ABC-Eval  Adjusted R-Squared R-Squared    delta  \\\n0                  antisocial             0.26030   26.0300      nan   \n1                   life info             0.26013   26.0130  -0.0170   \n2                topic switch             0.25980   25.9800  -0.0330   \n3             preference info             0.25966   25.9660  -0.0140   \n4              incorrect fact             0.25940   25.9400  -0.0260   \n5       partner contradiction             0.25912   25.9120  -0.0280   \n6             uninterpretable             0.25831   25.8310  -0.0810   \n7                   follow up             0.25716   25.7160  -0.1150   \n8                correct fact             0.25588   25.5880  -0.1280   \n9                      ignore             0.25222   25.2220  -0.3660   \n10  commonsense contradiction             0.24564   24.5640  -0.6580   \n11                 empathetic             0.23713   23.7130  -0.8510   \n12                  redundant             0.22221   22.2210  -1.4920   \n13                 irrelevant             0.18954   18.9540  -3.2670   \n14         self contradiction             0.14296   14.2960  -4.6580   \n15            lack of empathy             0.10348   10.3480  -3.9480   \n\n      R-Squared delta  \n0       26.0300 (nan)  \n1   26.0130 (-0.0170)  \n2   25.9800 (-0.0330)  \n3   25.9660 (-0.0140)  \n4   25.9400 (-0.0260)  \n5   25.9120 (-0.0280)  \n6   25.8310 (-0.0810)  \n7   25.7160 (-0.1150)  \n8   25.5880 (-0.1280)  \n9   25.2220 (-0.3660)  \n10  24.5640 (-0.6580)  \n11  23.7130 (-0.8510)  \n12  22.2210 (-1.4920)  \n13  18.9540 (-3.2670)  \n14  14.2960 (-4.6580)  \n15  10.3480 (-3.9480)  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ABC-Eval</th>\n      <th>Adjusted R-Squared</th>\n      <th>R-Squared</th>\n      <th>delta</th>\n      <th>R-Squared delta</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>antisocial</td>\n      <td>0.26030</td>\n      <td>26.0300</td>\n      <td>nan</td>\n      <td>26.0300 (nan)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>life info</td>\n      <td>0.26013</td>\n      <td>26.0130</td>\n      <td>-0.0170</td>\n      <td>26.0130 (-0.0170)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>topic switch</td>\n      <td>0.25980</td>\n      <td>25.9800</td>\n      <td>-0.0330</td>\n      <td>25.9800 (-0.0330)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>preference info</td>\n      <td>0.25966</td>\n      <td>25.9660</td>\n      <td>-0.0140</td>\n      <td>25.9660 (-0.0140)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>incorrect fact</td>\n      <td>0.25940</td>\n      <td>25.9400</td>\n      <td>-0.0260</td>\n      <td>25.9400 (-0.0260)</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>partner contradiction</td>\n      <td>0.25912</td>\n      <td>25.9120</td>\n      <td>-0.0280</td>\n      <td>25.9120 (-0.0280)</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>uninterpretable</td>\n      <td>0.25831</td>\n      <td>25.8310</td>\n      <td>-0.0810</td>\n      <td>25.8310 (-0.0810)</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>follow up</td>\n      <td>0.25716</td>\n      <td>25.7160</td>\n      <td>-0.1150</td>\n      <td>25.7160 (-0.1150)</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>correct fact</td>\n      <td>0.25588</td>\n      <td>25.5880</td>\n      <td>-0.1280</td>\n      <td>25.5880 (-0.1280)</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>ignore</td>\n      <td>0.25222</td>\n      <td>25.2220</td>\n      <td>-0.3660</td>\n      <td>25.2220 (-0.3660)</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>commonsense contradiction</td>\n      <td>0.24564</td>\n      <td>24.5640</td>\n      <td>-0.6580</td>\n      <td>24.5640 (-0.6580)</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>empathetic</td>\n      <td>0.23713</td>\n      <td>23.7130</td>\n      <td>-0.8510</td>\n      <td>23.7130 (-0.8510)</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>redundant</td>\n      <td>0.22221</td>\n      <td>22.2210</td>\n      <td>-1.4920</td>\n      <td>22.2210 (-1.4920)</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>irrelevant</td>\n      <td>0.18954</td>\n      <td>18.9540</td>\n      <td>-3.2670</td>\n      <td>18.9540 (-3.2670)</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>self contradiction</td>\n      <td>0.14296</td>\n      <td>14.2960</td>\n      <td>-4.6580</td>\n      <td>14.2960 (-4.6580)</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>lack of empathy</td>\n      <td>0.10348</td>\n      <td>10.3480</td>\n      <td>-3.9480</td>\n      <td>10.3480 (-3.9480)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_delta(df):\n",
    "    df['R-Squared'] = (df['Adjusted R-Squared']*100)\n",
    "    df['delta'] = df['R-Squared'].diff()\n",
    "    df['delta'] = df['delta'].map('{:.4f}'.format)\n",
    "    df['R-Squared'] = df['R-Squared'].map('{:.4f}'.format)\n",
    "    df['R-Squared delta'] = df['R-Squared'] + ' (' + df['delta'] + ')'\n",
    "\n",
    "final_behavior_regs = behavior_regs.reset_index().rename({'level_1': 'ABC-Eval'}, axis=1).drop(['level_0', 'P value of F-test'], axis=1)\n",
    "add_delta(final_behavior_regs)\n",
    "\n",
    "final_likert_turn_regs = likert_turn_regs.reset_index().rename({'level_1': 'Likert Turn'}, axis=1).drop(['level_0', 'P value of F-test'], axis=1)\n",
    "add_delta(final_likert_turn_regs)\n",
    "\n",
    "final_likert_dialogue_regs = likert_dialogue_regs.reset_index().rename({'level_1': 'Likert Dialogue'}, axis=1).drop(['level_0', 'P value of F-test'], axis=1)\n",
    "add_delta(final_likert_dialogue_regs)\n",
    "\n",
    "final_behavior_regs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "                     ABC-Eval    R-Squared delta  Likert Turn  \\\n0                  antisocial      26.0300 (nan)  informative   \n1                   life info  26.0130 (-0.0170)  grammatical   \n2                topic switch  25.9800 (-0.0330)    emotional   \n3             preference info  25.9660 (-0.0140)   consistent   \n4              incorrect fact  25.9400 (-0.0260)     relevant   \n5       partner contradiction  25.9120 (-0.0280)    proactive   \n6             uninterpretable  25.8310 (-0.0810)     engaging   \n7                   follow up  25.7160 (-0.1150)          NaN   \n8                correct fact  25.5880 (-0.1280)          NaN   \n9                      ignore  25.2220 (-0.3660)          NaN   \n10  commonsense contradiction  24.5640 (-0.6580)          NaN   \n11                 empathetic  23.7130 (-0.8510)          NaN   \n12                  redundant  22.2210 (-1.4920)          NaN   \n13                 irrelevant  18.9540 (-3.2670)          NaN   \n14         self contradiction  14.2960 (-4.6580)          NaN   \n15            lack of empathy  10.3480 (-3.9480)          NaN   \n\n      R-Squared delta Likert Dialogue    R-Squared delta  \n0       14.7080 (nan)     informative      12.0780 (nan)  \n1   14.6510 (-0.0570)      consistent   12.0780 (0.0000)  \n2   14.4100 (-0.2410)     grammatical  12.0520 (-0.0260)  \n3   13.8080 (-0.6020)        engaging  12.0100 (-0.0420)  \n4   12.9620 (-0.8460)       proactive  11.9420 (-0.0680)  \n5   10.2850 (-2.6770)       emotional  10.6040 (-1.3380)  \n6    6.6870 (-3.5980)        relevant   8.1830 (-2.4210)  \n7                 NaN             NaN                NaN  \n8                 NaN             NaN                NaN  \n9                 NaN             NaN                NaN  \n10                NaN             NaN                NaN  \n11                NaN             NaN                NaN  \n12                NaN             NaN                NaN  \n13                NaN             NaN                NaN  \n14                NaN             NaN                NaN  \n15                NaN             NaN                NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ABC-Eval</th>\n      <th>R-Squared delta</th>\n      <th>Likert Turn</th>\n      <th>R-Squared delta</th>\n      <th>Likert Dialogue</th>\n      <th>R-Squared delta</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>antisocial</td>\n      <td>26.0300 (nan)</td>\n      <td>informative</td>\n      <td>14.7080 (nan)</td>\n      <td>informative</td>\n      <td>12.0780 (nan)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>life info</td>\n      <td>26.0130 (-0.0170)</td>\n      <td>grammatical</td>\n      <td>14.6510 (-0.0570)</td>\n      <td>consistent</td>\n      <td>12.0780 (0.0000)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>topic switch</td>\n      <td>25.9800 (-0.0330)</td>\n      <td>emotional</td>\n      <td>14.4100 (-0.2410)</td>\n      <td>grammatical</td>\n      <td>12.0520 (-0.0260)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>preference info</td>\n      <td>25.9660 (-0.0140)</td>\n      <td>consistent</td>\n      <td>13.8080 (-0.6020)</td>\n      <td>engaging</td>\n      <td>12.0100 (-0.0420)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>incorrect fact</td>\n      <td>25.9400 (-0.0260)</td>\n      <td>relevant</td>\n      <td>12.9620 (-0.8460)</td>\n      <td>proactive</td>\n      <td>11.9420 (-0.0680)</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>partner contradiction</td>\n      <td>25.9120 (-0.0280)</td>\n      <td>proactive</td>\n      <td>10.2850 (-2.6770)</td>\n      <td>emotional</td>\n      <td>10.6040 (-1.3380)</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>uninterpretable</td>\n      <td>25.8310 (-0.0810)</td>\n      <td>engaging</td>\n      <td>6.6870 (-3.5980)</td>\n      <td>relevant</td>\n      <td>8.1830 (-2.4210)</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>follow up</td>\n      <td>25.7160 (-0.1150)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>correct fact</td>\n      <td>25.5880 (-0.1280)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>ignore</td>\n      <td>25.2220 (-0.3660)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>commonsense contradiction</td>\n      <td>24.5640 (-0.6580)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>empathetic</td>\n      <td>23.7130 (-0.8510)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>redundant</td>\n      <td>22.2210 (-1.4920)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>irrelevant</td>\n      <td>18.9540 (-3.2670)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>self contradiction</td>\n      <td>14.2960 (-4.6580)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>lack of empathy</td>\n      <td>10.3480 (-3.9480)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined = pd.concat(\n",
    "    [\n",
    "        final_behavior_regs[['ABC-Eval', 'R-Squared delta']],\n",
    "        final_likert_turn_regs[['Likert Turn', 'R-Squared delta']],\n",
    "        final_likert_dialogue_regs[['Likert Dialogue', 'R-Squared delta']]\n",
    "    ],\n",
    "    axis=1)\n",
    "\n",
    "combined.to_csv('results/paper/incremental_validity.csv', index=False)\n",
    "combined"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
