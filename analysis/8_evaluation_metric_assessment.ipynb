{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from analysis import *\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "from scipy.stats import binom_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                                           0  \\\nbot            category        label        item                               \nrerank_blender likert dialogue emotional    (109,13)_rerank_blender        4   \n                               consistent   (109,13)_rerank_blender        4   \n                               grammatical  (109,13)_rerank_blender        4   \n                               informative  (109,13)_rerank_blender        4   \n                               proactive    (109,13)_rerank_blender        4   \n...                                                                       ..   \n               behavior        follow up    ((438,26)_rerank_blender, 14)  0   \n                               topic switch ((438,26)_rerank_blender, 14)  0   \n                               ignore       ((438,26)_rerank_blender, 14)  0   \n                               irrelevant   ((438,26)_rerank_blender, 14)  0   \n                               antisocial   ((438,26)_rerank_blender, 14)  0   \n\n                                                                             1  \\\nbot            category        label        item                                 \nrerank_blender likert dialogue emotional    (109,13)_rerank_blender        4.0   \n                               consistent   (109,13)_rerank_blender        4.0   \n                               grammatical  (109,13)_rerank_blender        3.0   \n                               informative  (109,13)_rerank_blender        4.0   \n                               proactive    (109,13)_rerank_blender        3.0   \n...                                                                        ...   \n               behavior        follow up    ((438,26)_rerank_blender, 14)  NaN   \n                               topic switch ((438,26)_rerank_blender, 14)  NaN   \n                               ignore       ((438,26)_rerank_blender, 14)  NaN   \n                               irrelevant   ((438,26)_rerank_blender, 14)  NaN   \n                               antisocial   ((438,26)_rerank_blender, 14)  NaN   \n\n                                                                            2  \nbot            category        label        item                               \nrerank_blender likert dialogue emotional    (109,13)_rerank_blender       NaN  \n                               consistent   (109,13)_rerank_blender       NaN  \n                               grammatical  (109,13)_rerank_blender       NaN  \n                               informative  (109,13)_rerank_blender       NaN  \n                               proactive    (109,13)_rerank_blender       NaN  \n...                                                                        ..  \n               behavior        follow up    ((438,26)_rerank_blender, 14) NaN  \n                               topic switch ((438,26)_rerank_blender, 14) NaN  \n                               ignore       ((438,26)_rerank_blender, 14) NaN  \n                               irrelevant   ((438,26)_rerank_blender, 14) NaN  \n                               antisocial   ((438,26)_rerank_blender, 14) NaN  \n\n[151664 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n    </tr>\n    <tr>\n      <th>bot</th>\n      <th>category</th>\n      <th>label</th>\n      <th>item</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"11\" valign=\"top\">rerank_blender</th>\n      <th rowspan=\"5\" valign=\"top\">likert dialogue</th>\n      <th>emotional</th>\n      <th>(109,13)_rerank_blender</th>\n      <td>4</td>\n      <td>4.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>consistent</th>\n      <th>(109,13)_rerank_blender</th>\n      <td>4</td>\n      <td>4.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>grammatical</th>\n      <th>(109,13)_rerank_blender</th>\n      <td>4</td>\n      <td>3.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>informative</th>\n      <th>(109,13)_rerank_blender</th>\n      <td>4</td>\n      <td>4.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>proactive</th>\n      <th>(109,13)_rerank_blender</th>\n      <td>4</td>\n      <td>3.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">behavior</th>\n      <th>follow up</th>\n      <th>((438,26)_rerank_blender, 14)</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>topic switch</th>\n      <th>((438,26)_rerank_blender, 14)</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>ignore</th>\n      <th>((438,26)_rerank_blender, 14)</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>irrelevant</th>\n      <th>((438,26)_rerank_blender, 14)</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>antisocial</th>\n      <th>((438,26)_rerank_blender, 14)</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>151664 rows Ã— 3 columns</p>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surge_annotations = data.surge_evaluation.annotation_dataframe()\n",
    "surge_annotations_comparative = data.surge_evaluation.comparative_annotation_dataframe()\n",
    "\n",
    "surge_annotations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 8 Comprehensive Analysis"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Metric Sensitivity"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "                                          rerank_blender                \\\n                                                   emora   blender2_3B   \ncategory        label                                                    \nbehavior        antisocial                  2.474602e-03  4.194563e-01   \n                commonsense contradiction   4.674101e-08  1.014559e-01   \n                correct fact                7.162630e-16  6.660799e-01   \n                empathetic                  3.697819e-01  3.927420e-01   \n                follow up                   2.214653e-01  2.639515e-26   \n                ignore                      1.197645e-03  3.957589e-01   \n                incorrect fact              1.851676e-62  9.507153e-55   \n                irrelevant                  1.449497e-01  4.882563e-09   \n                lack of empathy             1.615134e-05  6.580446e-04   \n                life info                   1.880903e-02  1.455560e-01   \n                partner contradiction       8.959598e-01  1.730739e-01   \n                preference info             4.708673e-04  2.621806e-05   \n                redundant                   2.507068e-02  4.701412e-06   \n                self contradiction          3.031944e-11  1.744282e-02   \n                topic switch                9.414420e-02  7.325721e-12   \n                uninterpretable             1.566895e-08  2.259988e-07   \nlikert dialogue consistent                  2.748855e-01  7.327280e-02   \n                emotional                   1.658327e-01  6.041001e-05   \n                engaging                    3.156970e-01  5.314064e-01   \n                grammatical                 2.151765e-06  6.783573e-08   \n                informative                 7.671632e-04  1.808310e-02   \n                proactive                   1.653928e-01  6.589875e-01   \n                quality                     2.152175e-01  1.150702e-02   \n                relevant                    3.673116e-01  4.738332e-03   \nlikert turn     consistent                  2.753539e-02  1.775618e-01   \n                emotional                   2.565909e-09  3.801480e-01   \n                engaging                    5.943432e-02  2.268474e-03   \n                grammatical                 4.112589e-62  4.328568e-82   \n                informative                 1.636008e-39  1.723153e-14   \n                proactive                   3.053150e-03  7.148207e-02   \n                quality                     2.306632e-06  1.169420e-28   \n                relevant                    8.985054e-02  5.131697e-26   \ncomparative     consistent                  4.074855e-01  5.577833e-02   \n                emotional                   1.000000e+00  4.119101e-01   \n                engaging                    1.597615e-01  4.280722e-02   \n                grammatical                 5.764306e-01  9.151865e-01   \n                informative                 4.087197e-02  1.424496e-03   \n                proactive                   4.596914e-01  1.014327e-01   \n                quality                     8.438977e-01  4.167748e-01   \n                relevant                    9.219488e-01  5.383940e-01   \n\n                                                                   emora  \\\n                                          bart_fid_rag_bcb   blender2_3B   \ncategory        label                                                      \nbehavior        antisocial                    1.087556e-02  1.427387e-02   \n                commonsense contradiction     2.194954e-02  1.139109e-04   \n                correct fact                  9.406698e-19  1.753072e-17   \n                empathetic                    5.085360e-10  9.659565e-01   \n                follow up                     4.876607e-32  2.111994e-32   \n                ignore                        5.297479e-03  1.598324e-02   \n                incorrect fact                1.503432e-01  1.317827e-03   \n                irrelevant                    9.615384e-07  9.402470e-06   \n                lack of empathy               2.186129e-06  2.456389e-14   \n                life info                     1.557004e-01  1.365093e-04   \n                partner contradiction         2.558235e-01  2.161155e-01   \n                preference info               1.216464e-07  1.340120e-14   \n                redundant                     1.650866e-01  1.644755e-02   \n                self contradiction            3.313734e-13  6.988648e-18   \n                topic switch                  9.474029e-24  1.630474e-17   \n                uninterpretable               2.337776e-02  3.176284e-01   \nlikert dialogue consistent                    1.683858e-04  5.808872e-03   \n                emotional                     9.699514e-02  2.872157e-07   \n                engaging                      7.158897e-05  8.548159e-02   \n                grammatical                   3.881436e-03  2.568080e-01   \n                informative                   2.298797e-01  3.983366e-01   \n                proactive                     1.689757e-10  3.135760e-01   \n                quality                       2.664361e-02  1.349715e-01   \n                relevant                      1.000000e+00  9.406266e-05   \nlikert turn     consistent                    1.729386e-02  4.210213e-01   \n                emotional                     6.910098e-06  4.219155e-12   \n                engaging                      6.771119e-05  2.113138e-01   \n                grammatical                   4.953496e-17  4.322484e-05   \n                informative                   6.143431e-02  2.675640e-10   \n                proactive                     6.464228e-55  8.519670e-07   \n                quality                       6.275738e-01  4.985069e-10   \n                relevant                      5.851968e-04  1.175540e-18   \ncomparative     consistent                    2.180537e-01  4.640654e-03   \n                emotional                     5.025090e-02  4.704921e-01   \n                engaging                      1.049607e-03  6.024123e-01   \n                grammatical                   6.569925e-01  4.397054e-01   \n                informative                   5.229910e-01  2.954133e-01   \n                proactive                     3.479967e-05  4.215233e-01   \n                quality                       2.564423e-01  6.062959e-01   \n                relevant                      4.069244e-01  4.167748e-01   \n\n                                                                blender2_3B  \n                                          bart_fid_rag_bcb bart_fid_rag_bcb  \ncategory        label                                                        \nbehavior        antisocial                    3.156357e-01     5.989715e-02  \n                commonsense contradiction     1.149751e-14     8.311311e-05  \n                correct fact                  2.974544e-61     2.680962e-17  \n                empathetic                    9.043662e-08     7.085574e-08  \n                follow up                     9.765460e-39     2.217655e-01  \n                ignore                        6.507543e-01     5.060281e-02  \n                incorrect fact                5.731725e-55     2.224882e-47  \n                irrelevant                    5.185477e-04     3.358462e-01  \n                lack of empathy               6.614582e-01     9.700592e-16  \n                life info                     1.602902e-04     9.735843e-01  \n                partner contradiction         3.125069e-01     8.218418e-01  \n                preference info               1.686865e-18     2.693987e-01  \n                redundant                     3.902713e-01     1.192447e-03  \n                self contradiction            1.069475e-36     4.099767e-07  \n                topic switch                  1.776032e-31     8.370685e-04  \n                uninterpretable               8.609413e-05     9.570766e-04  \nlikert dialogue consistent                    3.205759e-06     5.725907e-02  \n                emotional                     7.606930e-01     1.450068e-07  \n                engaging                      1.091060e-03     3.516962e-06  \n                grammatical                   5.306465e-02     4.480271e-03  \n                informative                   3.692907e-02     2.434823e-01  \n                proactive                     1.606956e-14     2.807027e-12  \n                quality                       4.166798e-04     4.611179e-06  \n                relevant                      3.873728e-01     6.865061e-03  \nlikert turn     consistent                    6.389787e-06     2.715287e-04  \n                emotional                     2.466497e-01     7.070456e-08  \n                engaging                      3.163461e-09     2.922566e-12  \n                grammatical                   7.879216e-16     6.171341e-29  \n                informative                   1.722815e-50     6.266230e-22  \n                proactive                     1.950987e-78     1.680143e-47  \n                quality                       5.964538e-05     8.031374e-24  \n                relevant                      7.353825e-02     1.778864e-11  \ncomparative     consistent                    3.130178e-02     5.665734e-01  \n                emotional                     6.297226e-02     3.018725e-01  \n                engaging                      7.478815e-02     2.480457e-01  \n                grammatical                   1.000000e+00     5.104099e-01  \n                informative                   1.888467e-01     1.375039e-02  \n                proactive                     9.010035e-04     1.543230e-02  \n                quality                       4.018128e-01     8.284233e-01  \n                relevant                      3.048852e-01     9.142116e-01  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th></th>\n      <th colspan=\"3\" halign=\"left\">rerank_blender</th>\n      <th colspan=\"2\" halign=\"left\">emora</th>\n      <th>blender2_3B</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th></th>\n      <th>emora</th>\n      <th>blender2_3B</th>\n      <th>bart_fid_rag_bcb</th>\n      <th>blender2_3B</th>\n      <th>bart_fid_rag_bcb</th>\n      <th>bart_fid_rag_bcb</th>\n    </tr>\n    <tr>\n      <th>category</th>\n      <th>label</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"16\" valign=\"top\">behavior</th>\n      <th>antisocial</th>\n      <td>2.474602e-03</td>\n      <td>4.194563e-01</td>\n      <td>1.087556e-02</td>\n      <td>1.427387e-02</td>\n      <td>3.156357e-01</td>\n      <td>5.989715e-02</td>\n    </tr>\n    <tr>\n      <th>commonsense contradiction</th>\n      <td>4.674101e-08</td>\n      <td>1.014559e-01</td>\n      <td>2.194954e-02</td>\n      <td>1.139109e-04</td>\n      <td>1.149751e-14</td>\n      <td>8.311311e-05</td>\n    </tr>\n    <tr>\n      <th>correct fact</th>\n      <td>7.162630e-16</td>\n      <td>6.660799e-01</td>\n      <td>9.406698e-19</td>\n      <td>1.753072e-17</td>\n      <td>2.974544e-61</td>\n      <td>2.680962e-17</td>\n    </tr>\n    <tr>\n      <th>empathetic</th>\n      <td>3.697819e-01</td>\n      <td>3.927420e-01</td>\n      <td>5.085360e-10</td>\n      <td>9.659565e-01</td>\n      <td>9.043662e-08</td>\n      <td>7.085574e-08</td>\n    </tr>\n    <tr>\n      <th>follow up</th>\n      <td>2.214653e-01</td>\n      <td>2.639515e-26</td>\n      <td>4.876607e-32</td>\n      <td>2.111994e-32</td>\n      <td>9.765460e-39</td>\n      <td>2.217655e-01</td>\n    </tr>\n    <tr>\n      <th>ignore</th>\n      <td>1.197645e-03</td>\n      <td>3.957589e-01</td>\n      <td>5.297479e-03</td>\n      <td>1.598324e-02</td>\n      <td>6.507543e-01</td>\n      <td>5.060281e-02</td>\n    </tr>\n    <tr>\n      <th>incorrect fact</th>\n      <td>1.851676e-62</td>\n      <td>9.507153e-55</td>\n      <td>1.503432e-01</td>\n      <td>1.317827e-03</td>\n      <td>5.731725e-55</td>\n      <td>2.224882e-47</td>\n    </tr>\n    <tr>\n      <th>irrelevant</th>\n      <td>1.449497e-01</td>\n      <td>4.882563e-09</td>\n      <td>9.615384e-07</td>\n      <td>9.402470e-06</td>\n      <td>5.185477e-04</td>\n      <td>3.358462e-01</td>\n    </tr>\n    <tr>\n      <th>lack of empathy</th>\n      <td>1.615134e-05</td>\n      <td>6.580446e-04</td>\n      <td>2.186129e-06</td>\n      <td>2.456389e-14</td>\n      <td>6.614582e-01</td>\n      <td>9.700592e-16</td>\n    </tr>\n    <tr>\n      <th>life info</th>\n      <td>1.880903e-02</td>\n      <td>1.455560e-01</td>\n      <td>1.557004e-01</td>\n      <td>1.365093e-04</td>\n      <td>1.602902e-04</td>\n      <td>9.735843e-01</td>\n    </tr>\n    <tr>\n      <th>partner contradiction</th>\n      <td>8.959598e-01</td>\n      <td>1.730739e-01</td>\n      <td>2.558235e-01</td>\n      <td>2.161155e-01</td>\n      <td>3.125069e-01</td>\n      <td>8.218418e-01</td>\n    </tr>\n    <tr>\n      <th>preference info</th>\n      <td>4.708673e-04</td>\n      <td>2.621806e-05</td>\n      <td>1.216464e-07</td>\n      <td>1.340120e-14</td>\n      <td>1.686865e-18</td>\n      <td>2.693987e-01</td>\n    </tr>\n    <tr>\n      <th>redundant</th>\n      <td>2.507068e-02</td>\n      <td>4.701412e-06</td>\n      <td>1.650866e-01</td>\n      <td>1.644755e-02</td>\n      <td>3.902713e-01</td>\n      <td>1.192447e-03</td>\n    </tr>\n    <tr>\n      <th>self contradiction</th>\n      <td>3.031944e-11</td>\n      <td>1.744282e-02</td>\n      <td>3.313734e-13</td>\n      <td>6.988648e-18</td>\n      <td>1.069475e-36</td>\n      <td>4.099767e-07</td>\n    </tr>\n    <tr>\n      <th>topic switch</th>\n      <td>9.414420e-02</td>\n      <td>7.325721e-12</td>\n      <td>9.474029e-24</td>\n      <td>1.630474e-17</td>\n      <td>1.776032e-31</td>\n      <td>8.370685e-04</td>\n    </tr>\n    <tr>\n      <th>uninterpretable</th>\n      <td>1.566895e-08</td>\n      <td>2.259988e-07</td>\n      <td>2.337776e-02</td>\n      <td>3.176284e-01</td>\n      <td>8.609413e-05</td>\n      <td>9.570766e-04</td>\n    </tr>\n    <tr>\n      <th rowspan=\"8\" valign=\"top\">likert dialogue</th>\n      <th>consistent</th>\n      <td>2.748855e-01</td>\n      <td>7.327280e-02</td>\n      <td>1.683858e-04</td>\n      <td>5.808872e-03</td>\n      <td>3.205759e-06</td>\n      <td>5.725907e-02</td>\n    </tr>\n    <tr>\n      <th>emotional</th>\n      <td>1.658327e-01</td>\n      <td>6.041001e-05</td>\n      <td>9.699514e-02</td>\n      <td>2.872157e-07</td>\n      <td>7.606930e-01</td>\n      <td>1.450068e-07</td>\n    </tr>\n    <tr>\n      <th>engaging</th>\n      <td>3.156970e-01</td>\n      <td>5.314064e-01</td>\n      <td>7.158897e-05</td>\n      <td>8.548159e-02</td>\n      <td>1.091060e-03</td>\n      <td>3.516962e-06</td>\n    </tr>\n    <tr>\n      <th>grammatical</th>\n      <td>2.151765e-06</td>\n      <td>6.783573e-08</td>\n      <td>3.881436e-03</td>\n      <td>2.568080e-01</td>\n      <td>5.306465e-02</td>\n      <td>4.480271e-03</td>\n    </tr>\n    <tr>\n      <th>informative</th>\n      <td>7.671632e-04</td>\n      <td>1.808310e-02</td>\n      <td>2.298797e-01</td>\n      <td>3.983366e-01</td>\n      <td>3.692907e-02</td>\n      <td>2.434823e-01</td>\n    </tr>\n    <tr>\n      <th>proactive</th>\n      <td>1.653928e-01</td>\n      <td>6.589875e-01</td>\n      <td>1.689757e-10</td>\n      <td>3.135760e-01</td>\n      <td>1.606956e-14</td>\n      <td>2.807027e-12</td>\n    </tr>\n    <tr>\n      <th>quality</th>\n      <td>2.152175e-01</td>\n      <td>1.150702e-02</td>\n      <td>2.664361e-02</td>\n      <td>1.349715e-01</td>\n      <td>4.166798e-04</td>\n      <td>4.611179e-06</td>\n    </tr>\n    <tr>\n      <th>relevant</th>\n      <td>3.673116e-01</td>\n      <td>4.738332e-03</td>\n      <td>1.000000e+00</td>\n      <td>9.406266e-05</td>\n      <td>3.873728e-01</td>\n      <td>6.865061e-03</td>\n    </tr>\n    <tr>\n      <th rowspan=\"8\" valign=\"top\">likert turn</th>\n      <th>consistent</th>\n      <td>2.753539e-02</td>\n      <td>1.775618e-01</td>\n      <td>1.729386e-02</td>\n      <td>4.210213e-01</td>\n      <td>6.389787e-06</td>\n      <td>2.715287e-04</td>\n    </tr>\n    <tr>\n      <th>emotional</th>\n      <td>2.565909e-09</td>\n      <td>3.801480e-01</td>\n      <td>6.910098e-06</td>\n      <td>4.219155e-12</td>\n      <td>2.466497e-01</td>\n      <td>7.070456e-08</td>\n    </tr>\n    <tr>\n      <th>engaging</th>\n      <td>5.943432e-02</td>\n      <td>2.268474e-03</td>\n      <td>6.771119e-05</td>\n      <td>2.113138e-01</td>\n      <td>3.163461e-09</td>\n      <td>2.922566e-12</td>\n    </tr>\n    <tr>\n      <th>grammatical</th>\n      <td>4.112589e-62</td>\n      <td>4.328568e-82</td>\n      <td>4.953496e-17</td>\n      <td>4.322484e-05</td>\n      <td>7.879216e-16</td>\n      <td>6.171341e-29</td>\n    </tr>\n    <tr>\n      <th>informative</th>\n      <td>1.636008e-39</td>\n      <td>1.723153e-14</td>\n      <td>6.143431e-02</td>\n      <td>2.675640e-10</td>\n      <td>1.722815e-50</td>\n      <td>6.266230e-22</td>\n    </tr>\n    <tr>\n      <th>proactive</th>\n      <td>3.053150e-03</td>\n      <td>7.148207e-02</td>\n      <td>6.464228e-55</td>\n      <td>8.519670e-07</td>\n      <td>1.950987e-78</td>\n      <td>1.680143e-47</td>\n    </tr>\n    <tr>\n      <th>quality</th>\n      <td>2.306632e-06</td>\n      <td>1.169420e-28</td>\n      <td>6.275738e-01</td>\n      <td>4.985069e-10</td>\n      <td>5.964538e-05</td>\n      <td>8.031374e-24</td>\n    </tr>\n    <tr>\n      <th>relevant</th>\n      <td>8.985054e-02</td>\n      <td>5.131697e-26</td>\n      <td>5.851968e-04</td>\n      <td>1.175540e-18</td>\n      <td>7.353825e-02</td>\n      <td>1.778864e-11</td>\n    </tr>\n    <tr>\n      <th rowspan=\"8\" valign=\"top\">comparative</th>\n      <th>consistent</th>\n      <td>4.074855e-01</td>\n      <td>5.577833e-02</td>\n      <td>2.180537e-01</td>\n      <td>4.640654e-03</td>\n      <td>3.130178e-02</td>\n      <td>5.665734e-01</td>\n    </tr>\n    <tr>\n      <th>emotional</th>\n      <td>1.000000e+00</td>\n      <td>4.119101e-01</td>\n      <td>5.025090e-02</td>\n      <td>4.704921e-01</td>\n      <td>6.297226e-02</td>\n      <td>3.018725e-01</td>\n    </tr>\n    <tr>\n      <th>engaging</th>\n      <td>1.597615e-01</td>\n      <td>4.280722e-02</td>\n      <td>1.049607e-03</td>\n      <td>6.024123e-01</td>\n      <td>7.478815e-02</td>\n      <td>2.480457e-01</td>\n    </tr>\n    <tr>\n      <th>grammatical</th>\n      <td>5.764306e-01</td>\n      <td>9.151865e-01</td>\n      <td>6.569925e-01</td>\n      <td>4.397054e-01</td>\n      <td>1.000000e+00</td>\n      <td>5.104099e-01</td>\n    </tr>\n    <tr>\n      <th>informative</th>\n      <td>4.087197e-02</td>\n      <td>1.424496e-03</td>\n      <td>5.229910e-01</td>\n      <td>2.954133e-01</td>\n      <td>1.888467e-01</td>\n      <td>1.375039e-02</td>\n    </tr>\n    <tr>\n      <th>proactive</th>\n      <td>4.596914e-01</td>\n      <td>1.014327e-01</td>\n      <td>3.479967e-05</td>\n      <td>4.215233e-01</td>\n      <td>9.010035e-04</td>\n      <td>1.543230e-02</td>\n    </tr>\n    <tr>\n      <th>quality</th>\n      <td>8.438977e-01</td>\n      <td>4.167748e-01</td>\n      <td>2.564423e-01</td>\n      <td>6.062959e-01</td>\n      <td>4.018128e-01</td>\n      <td>8.284233e-01</td>\n    </tr>\n    <tr>\n      <th>relevant</th>\n      <td>9.219488e-01</td>\n      <td>5.383940e-01</td>\n      <td>4.069244e-01</td>\n      <td>4.167748e-01</td>\n      <td>3.048852e-01</td>\n      <td>9.142116e-01</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "def p_vals(df: pd.DataFrame, test='t'):\n",
    "    \"\"\"\n",
    "    :param df: (bot, data point) x 1 -> score\n",
    "    :param test: statistical test function (t for t test, p for prop test, s for sign test)\n",
    "    :return: p values of test on each bot pair (pd.Series)\n",
    "    \"\"\"\n",
    "    bots = set(df.index.get_level_values(0))\n",
    "    bot_pairs = list(combinations(bots, 2))\n",
    "    result = {}\n",
    "    for ba, bb in bot_pairs:\n",
    "        a = df.xs(ba).to_numpy().squeeze()\n",
    "        b = df.xs(bb).to_numpy().squeeze()\n",
    "        if test == 't':\n",
    "            t, p = ttest_ind(a, b, equal_var=False)\n",
    "        elif test == 'p':\n",
    "            z, p = proportions_ztest(count=[\n",
    "                sum(a), sum(b)\n",
    "            ], nobs=[\n",
    "                len(a), len(b)\n",
    "            ])\n",
    "        elif test == 's':\n",
    "            # sign test\n",
    "            a = a[a==1]\n",
    "            b = b[b==1]\n",
    "            p = binom_test(sum(a), sum(a)+sum(b), p=0.5)\n",
    "        else:\n",
    "            raise ValueError('invalid arg for param \"test\"')\n",
    "        result[(ba, bb)] = p\n",
    "    result_series = pd.Series(result.values(), result)\n",
    "    return result_series\n",
    "\n",
    "@to_file\n",
    "def t_test_p_values_comparing_bots(annotations):\n",
    "    annotations = get_singly_annotated(annotations)\n",
    "    prop_annotations = annotations.xs(\n",
    "        category.behavior, level=sym.category, drop_level=False\n",
    "    )\n",
    "    comp_annotations = annotations.xs(\n",
    "        category.comparative, level=sym.category, drop_level=False\n",
    "    )\n",
    "    mean_annotations = annotations.drop(\n",
    "        index=category.behavior, level=sym.category\n",
    "    ).drop(\n",
    "        index=category.comparative, level=sym.category\n",
    "    )\n",
    "    mean_ps = mean_annotations.groupby(\n",
    "        [sym.category, sym.label]\n",
    "    ).apply(p_vals)\n",
    "    prop_ps = prop_annotations.groupby(\n",
    "        [sym.category, sym.label]\n",
    "    ).apply(lambda x: p_vals(x, test='p'))\n",
    "    comp_ps = comp_annotations.groupby(\n",
    "        [sym.category, sym.label]\n",
    "    ).apply(lambda x: p_vals(x, test='s'))\n",
    "    result = pd.concat([prop_ps, mean_ps, comp_ps], axis=0)\n",
    "    return result\n",
    "\n",
    "t_test_p_values_comparing_bots(surge_annotations, reload='results/t_test_p_values_comparing_bots')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Predictive Validity"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "from statsmodels.miscmodels.ordinal_model import OrderedModel\n",
    "from statsmodels.regression.linear_model import OLS as LinearModel\n",
    "from statsmodels.tools.tools import add_constant\n",
    "\n",
    "def dialogue_metrics(ev):\n",
    "    df: pd.DataFrame = ev.annotation_dataframe()\n",
    "    df = get_singly_annotated(df, seed=123)\n",
    "    reindexed = df.reset_index()\n",
    "    items = reindexed[sym.item]\n",
    "    dialogues = [e[0] if isinstance(e, tuple) else e for e in items]\n",
    "    reindexed['dialogue'] = dialogues\n",
    "    reindexed.set_index(\n",
    "        [sym.bot, sym.category, sym.label, 'dialogue', sym.item],\n",
    "        inplace=True, verify_integrity=True\n",
    "    )\n",
    "    ld = reindexed.xs(category.likert_dialogue, level=sym.category)\n",
    "    ld = ld.droplevel(sym.bot).droplevel(sym.item)\n",
    "    ld.columns = ['score']\n",
    "    ldq = ld.xs(scale.quality, level=sym.label)\n",
    "    ldq.columns = ['quality']\n",
    "\n",
    "    lt = reindexed.xs(category.likert_turn, level=sym.category)\n",
    "    lt = lt.groupby([sym.label, 'dialogue']).mean()\n",
    "    lt.columns = ['score']\n",
    "    ltq = lt.xs(scale.quality, level=sym.label)\n",
    "    ltq.columns = ['quality']\n",
    "\n",
    "    be = reindexed.xs(category.behavior, level=sym.category)\n",
    "    be = be.groupby([sym.label, 'dialogue']).mean()\n",
    "    be.columns = ['score']\n",
    "\n",
    "    ds = pd.concat(\n",
    "        [lt, be, ld],\n",
    "        keys=[category.likert_turn, category.behavior, category.likert_dialogue],\n",
    "        names=[sym.category, sym.label, 'dialogue']\n",
    "    )\n",
    "    likert_dialogue_quality_features = ds.join(ldq, on='dialogue')\n",
    "    likert_turn_quality_features = ds.join(ltq, on='dialogue')\n",
    "    return likert_dialogue_quality_features, likert_turn_quality_features\n",
    "\n",
    "\n",
    "def regressions(df, quality_column_name=None, model='linear'):\n",
    "    \"\"\"\n",
    "    :param df: dialogue x (*features, quality) -> value\n",
    "    :return: *(coef, low, high), mcfadden r^2\n",
    "    \"\"\"\n",
    "    if not quality_column_name:\n",
    "        quality_column_name = df.columns[-1]\n",
    "    qualities = df[quality_column_name]\n",
    "    features = [f for f in df.columns if f != quality_column_name]\n",
    "    if model == 'ordinal':\n",
    "        model = OrderedModel(qualities, df[features], distr='logit')\n",
    "        results = model.fit()\n",
    "        coefs = {f: results.params[f] for f in features}\n",
    "        prsqrd = results.prsquared\n",
    "        result = {stat.mcfad_r2: prsqrd, stat.p_of_llr_test: results.llr_pvalue}\n",
    "    elif model == 'linear':\n",
    "        x = add_constant(df[features])\n",
    "        y = qualities\n",
    "        model = LinearModel(y, x)\n",
    "        results = model.fit()\n",
    "        coefs = {f: results.params[f] for f in features}\n",
    "        rsquared = results.rsquared\n",
    "        result = {**coefs, stat.r2: rsquared, stat.p_of_f_test: results.f_pvalue}\n",
    "    else:\n",
    "        raise ValueError('Param \"model\" must be one of {\"linear\", \"ordinal\"}')\n",
    "    return pd.Series(result.values(), result)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 1.314613\n",
      "         Iterations: 217\n",
      "         Function evaluations: 355\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.314321\n",
      "         Iterations: 193\n",
      "         Function evaluations: 320\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.314382\n",
      "         Iterations: 210\n",
      "         Function evaluations: 341\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.327590\n",
      "         Iterations: 118\n",
      "         Function evaluations: 207\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.327138\n",
      "         Iterations: 188\n",
      "         Function evaluations: 311\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.314526\n",
      "         Iterations: 222\n",
      "         Function evaluations: 360\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.313996\n",
      "         Iterations: 212\n",
      "         Function evaluations: 354\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.311152\n",
      "         Iterations: 227\n",
      "         Function evaluations: 372\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.327515\n",
      "         Iterations: 244\n",
      "         Function evaluations: 398\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.298028\n",
      "         Iterations: 262\n",
      "         Function evaluations: 423\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.327602\n",
      "         Iterations: 120\n",
      "         Function evaluations: 202\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.306736\n",
      "         Iterations: 285\n",
      "         Function evaluations: 464\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.324691\n",
      "         Iterations: 226\n",
      "         Function evaluations: 361\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.309827\n",
      "         Iterations: 246\n",
      "         Function evaluations: 412\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.319315\n",
      "         Iterations: 252\n",
      "         Function evaluations: 405\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.301253\n",
      "         Iterations: 231\n",
      "         Function evaluations: 383\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.305421\n",
      "         Iterations: 257\n",
      "         Function evaluations: 427\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.326470\n",
      "         Iterations: 177\n",
      "         Function evaluations: 300\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.298477\n",
      "         Iterations: 271\n",
      "         Function evaluations: 437\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.326303\n",
      "         Iterations: 161\n",
      "         Function evaluations: 276\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.314723\n",
      "         Iterations: 231\n",
      "         Function evaluations: 378\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.314214\n",
      "         Iterations: 244\n",
      "         Function evaluations: 398\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.327604\n",
      "         Iterations: 111\n",
      "         Function evaluations: 192\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.324118\n",
      "         Iterations: 234\n",
      "         Function evaluations: 387\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.198636\n",
      "         Iterations: 218\n",
      "         Function evaluations: 361\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.202455\n",
      "         Iterations: 249\n",
      "         Function evaluations: 412\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.092076\n",
      "         Iterations: 246\n",
      "         Function evaluations: 395\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.286791\n",
      "         Iterations: 191\n",
      "         Function evaluations: 318\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.240186\n",
      "         Iterations: 222\n",
      "         Function evaluations: 368\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.169040\n",
      "         Iterations: 230\n",
      "         Function evaluations: 381\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.000000\n",
      "         Iterations: 424\n",
      "         Function evaluations: 764\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.164840\n",
      "         Iterations: 220\n",
      "         Function evaluations: 361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarah/opt/anaconda3/envs/dia_analysis/lib/python3.10/site-packages/statsmodels/base/model.py:592: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  warnings.warn('Inverting hessian failed, no bse or cov_params '\n"
     ]
    },
    {
     "data": {
      "text/plain": "Predicted                                 Likert Turn Quality               \\\nMetric                                         LR Coefficient LR R-Squared   \ncategory        label                                                        \nlikert turn     consistent                            0.21707      0.04474   \n                emotional                             0.18738      0.03755   \n                engaging                              0.16420      0.04061   \n                grammatical                           0.29094      0.06348   \n                informative                           0.02049      0.00046   \n                proactive                             0.22061      0.06614   \n                quality                               1.00000      1.00000   \n                relevant                              0.26306      0.09870   \nbehavior        antisocial                           -3.70553      0.01164   \n                commonsense contradiction            -1.29550      0.07139   \n                correct fact                         -0.34247      0.00899   \n                empathetic                            0.45030      0.02107   \n                follow up                             0.46015      0.02544   \n                ignore                               -1.74979      0.07209   \n                incorrect fact                       -0.83946      0.03412   \n                irrelevant                           -1.26057      0.06118   \n                lack of empathy                      -1.16185      0.04956   \n                life info                             0.18006      0.00186   \n                partner contradiction                -1.49766      0.04030   \n                preference info                       0.31426      0.00875   \n                redundant                            -0.42368      0.00251   \n                self contradiction                   -1.27412      0.02447   \n                topic switch                         -0.56434      0.01100   \n                uninterpretable                      -1.59035      0.00523   \nlikert dialogue consistent                            0.03652      0.00544   \n                emotional                             0.11540      0.03715   \n                engaging                              0.06870      0.01141   \n                grammatical                           0.02164      0.00097   \n                informative                           0.01384      0.00038   \n                proactive                             0.05628      0.00901   \n                quality                               0.12029      0.02906   \n                relevant                              0.11919      0.03677   \n\nPredicted                                                    \\\nMetric                                    P value of F-test   \ncategory        label                                         \nlikert turn     consistent                          0.00002   \n                emotional                           0.00010   \n                engaging                            0.00005   \n                grammatical                         0.00000   \n                informative                         0.66881   \n                proactive                           0.00000   \n                quality                             0.00000   \n                relevant                            0.00000   \nbehavior        antisocial                          0.03100   \n                commonsense contradiction           0.00000   \n                correct fact                        0.05813   \n                empathetic                          0.00362   \n                follow up                           0.00137   \n                ignore                              0.00000   \n                incorrect fact                      0.00020   \n                irrelevant                          0.00000   \n                lack of empathy                     0.00001   \n                life info                           0.38999   \n                partner contradiction               0.00005   \n                preference info                     0.06159   \n                redundant                           0.31783   \n                self contradiction                  0.00170   \n                topic switch                        0.03599   \n                uninterpretable                     0.14900   \nlikert dialogue consistent                          0.14075   \n                emotional                           0.00010   \n                engaging                            0.03266   \n                grammatical                         0.53499   \n                informative                         0.69605   \n                proactive                           0.05784   \n                quality                             0.00062   \n                relevant                            0.00011   \n\nPredicted                                 Likert Dialogue Quality  \\\nMetric                                             LR Coefficient   \ncategory        label                                               \nlikert turn     consistent                                0.25186   \n                emotional                                 0.23505   \n                engaging                                  0.19074   \n                grammatical                               0.01671   \n                informative                              -0.05404   \n                proactive                                 0.20584   \n                quality                                   0.24156   \n                relevant                                  0.23057   \nbehavior        antisocial                               -0.55548   \n                commonsense contradiction                -1.69743   \n                correct fact                              0.05121   \n                empathetic                                0.88404   \n                follow up                                 0.27118   \n                ignore                                   -1.71655   \n                incorrect fact                           -0.89117   \n                irrelevant                               -1.60563   \n                lack of empathy                          -1.54854   \n                life info                                 0.32752   \n                partner contradiction                    -2.59899   \n                preference info                           0.26322   \n                redundant                                -2.05277   \n                self contradiction                       -1.91209   \n                topic switch                              0.02456   \n                uninterpretable                          -2.73952   \nlikert dialogue consistent                                0.33319   \n                emotional                                 0.40710   \n                engaging                                  0.56247   \n                grammatical                               0.26529   \n                informative                               0.41837   \n                proactive                                 0.44016   \n                quality                                   1.00000   \n                relevant                                  0.47207   \n\nPredicted                                                                 \\\nMetric                                    LR R-Squared P value of F-test   \ncategory        label                                                      \nlikert turn     consistent                     0.02999           0.00050   \n                emotional                      0.02943           0.00057   \n                engaging                       0.02729           0.00091   \n                grammatical                    0.00010           0.83866   \n                informative                    0.00159           0.42573   \n                proactive                      0.02868           0.00067   \n                quality                        0.02906           0.00062   \n                relevant                       0.03776           0.00009   \nbehavior        antisocial                     0.00013           0.82001   \n                commonsense contradiction      0.06103           0.00000   \n                correct fact                   0.00010           0.84188   \n                empathetic                     0.04044           0.00005   \n                follow up                      0.00440           0.18548   \n                ignore                         0.03455           0.00019   \n                incorrect fact                 0.01915           0.00557   \n                irrelevant                     0.04943           0.00001   \n                lack of empathy                0.04384           0.00002   \n                life info                      0.00306           0.26971   \n                partner contradiction          0.06043           0.00000   \n                preference info                0.00306           0.26993   \n                redundant                      0.02931           0.00058   \n                self contradiction             0.02745           0.00088   \n                topic switch                   0.00001           0.94880   \n                uninterpretable                0.00772           0.07922   \nlikert dialogue consistent                     0.22558           0.00000   \n                emotional                      0.23022           0.00000   \n                engaging                       0.38103           0.00000   \n                grammatical                    0.07243           0.00000   \n                informative                    0.17475           0.00000   \n                proactive                      0.27452           0.00000   \n                quality                        1.00000           0.00000   \n                relevant                       0.28720           0.00000   \n\nPredicted                                                      \\\nMetric                                    OR Pseudo R-Squared   \ncategory        label                                           \nlikert turn     consistent                            0.00979   \n                emotional                             0.01001   \n                engaging                              0.00996   \n                grammatical                           0.00001   \n                informative                           0.00035   \n                proactive                             0.00985   \n                quality                               0.01025   \n                relevant                              0.01239   \nbehavior        antisocial                            0.00007   \n                commonsense contradiction             0.02228   \n                correct fact                          0.00000   \n                empathetic                            0.01572   \n                follow up                             0.00219   \n                ignore                                0.01339   \n                incorrect fact                        0.00624   \n                irrelevant                            0.01985   \n                lack of empathy                       0.01671   \n                life info                             0.00085   \n                partner contradiction                 0.02194   \n                preference info                       0.00098   \n                redundant                             0.00970   \n                self contradiction                    0.01009   \n                topic switch                          0.00000   \n                uninterpretable                       0.00263   \nlikert dialogue consistent                            0.09714   \n                emotional                             0.09427   \n                engaging                              0.17741   \n                grammatical                           0.03074   \n                informative                           0.06585   \n                proactive                             0.11944   \n                quality                               1.00000   \n                relevant                              0.12260   \n\nPredicted                                                      \nMetric                                    P value of LLR-test  \ncategory        label                                          \nlikert turn     consistent                            0.00126  \n                emotional                             0.00111  \n                engaging                              0.00114  \n                grammatical                           0.91405  \n                informative                           0.54115  \n                proactive                             0.00122  \n                quality                               0.00097  \n                relevant                              0.00029  \nbehavior        antisocial                            0.78842  \n                commonsense contradiction             0.00000  \n                correct fact                          0.96550  \n                empathetic                            0.00004  \n                follow up                             0.12681  \n                ignore                                0.00016  \n                incorrect fact                        0.01002  \n                irrelevant                            0.00000  \n                lack of empathy                       0.00003  \n                life info                             0.34079  \n                partner contradiction                 0.00000  \n                preference info                       0.30747  \n                redundant                             0.00133  \n                self contradiction                    0.00106  \n                topic switch                          0.98731  \n                uninterpretable                       0.09489  \nlikert dialogue consistent                            0.00000  \n                emotional                             0.00000  \n                engaging                              0.00000  \n                grammatical                           0.00000  \n                informative                           0.00000  \n                proactive                             0.00000  \n                quality                               0.00000  \n                relevant                              0.00000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th>Predicted</th>\n      <th colspan=\"3\" halign=\"left\">Likert Turn Quality</th>\n      <th colspan=\"5\" halign=\"left\">Likert Dialogue Quality</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>Metric</th>\n      <th>LR Coefficient</th>\n      <th>LR R-Squared</th>\n      <th>P value of F-test</th>\n      <th>LR Coefficient</th>\n      <th>LR R-Squared</th>\n      <th>P value of F-test</th>\n      <th>OR Pseudo R-Squared</th>\n      <th>P value of LLR-test</th>\n    </tr>\n    <tr>\n      <th>category</th>\n      <th>label</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"8\" valign=\"top\">likert turn</th>\n      <th>consistent</th>\n      <td>0.21707</td>\n      <td>0.04474</td>\n      <td>0.00002</td>\n      <td>0.25186</td>\n      <td>0.02999</td>\n      <td>0.00050</td>\n      <td>0.00979</td>\n      <td>0.00126</td>\n    </tr>\n    <tr>\n      <th>emotional</th>\n      <td>0.18738</td>\n      <td>0.03755</td>\n      <td>0.00010</td>\n      <td>0.23505</td>\n      <td>0.02943</td>\n      <td>0.00057</td>\n      <td>0.01001</td>\n      <td>0.00111</td>\n    </tr>\n    <tr>\n      <th>engaging</th>\n      <td>0.16420</td>\n      <td>0.04061</td>\n      <td>0.00005</td>\n      <td>0.19074</td>\n      <td>0.02729</td>\n      <td>0.00091</td>\n      <td>0.00996</td>\n      <td>0.00114</td>\n    </tr>\n    <tr>\n      <th>grammatical</th>\n      <td>0.29094</td>\n      <td>0.06348</td>\n      <td>0.00000</td>\n      <td>0.01671</td>\n      <td>0.00010</td>\n      <td>0.83866</td>\n      <td>0.00001</td>\n      <td>0.91405</td>\n    </tr>\n    <tr>\n      <th>informative</th>\n      <td>0.02049</td>\n      <td>0.00046</td>\n      <td>0.66881</td>\n      <td>-0.05404</td>\n      <td>0.00159</td>\n      <td>0.42573</td>\n      <td>0.00035</td>\n      <td>0.54115</td>\n    </tr>\n    <tr>\n      <th>proactive</th>\n      <td>0.22061</td>\n      <td>0.06614</td>\n      <td>0.00000</td>\n      <td>0.20584</td>\n      <td>0.02868</td>\n      <td>0.00067</td>\n      <td>0.00985</td>\n      <td>0.00122</td>\n    </tr>\n    <tr>\n      <th>quality</th>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>0.24156</td>\n      <td>0.02906</td>\n      <td>0.00062</td>\n      <td>0.01025</td>\n      <td>0.00097</td>\n    </tr>\n    <tr>\n      <th>relevant</th>\n      <td>0.26306</td>\n      <td>0.09870</td>\n      <td>0.00000</td>\n      <td>0.23057</td>\n      <td>0.03776</td>\n      <td>0.00009</td>\n      <td>0.01239</td>\n      <td>0.00029</td>\n    </tr>\n    <tr>\n      <th rowspan=\"16\" valign=\"top\">behavior</th>\n      <th>antisocial</th>\n      <td>-3.70553</td>\n      <td>0.01164</td>\n      <td>0.03100</td>\n      <td>-0.55548</td>\n      <td>0.00013</td>\n      <td>0.82001</td>\n      <td>0.00007</td>\n      <td>0.78842</td>\n    </tr>\n    <tr>\n      <th>commonsense contradiction</th>\n      <td>-1.29550</td>\n      <td>0.07139</td>\n      <td>0.00000</td>\n      <td>-1.69743</td>\n      <td>0.06103</td>\n      <td>0.00000</td>\n      <td>0.02228</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>correct fact</th>\n      <td>-0.34247</td>\n      <td>0.00899</td>\n      <td>0.05813</td>\n      <td>0.05121</td>\n      <td>0.00010</td>\n      <td>0.84188</td>\n      <td>0.00000</td>\n      <td>0.96550</td>\n    </tr>\n    <tr>\n      <th>empathetic</th>\n      <td>0.45030</td>\n      <td>0.02107</td>\n      <td>0.00362</td>\n      <td>0.88404</td>\n      <td>0.04044</td>\n      <td>0.00005</td>\n      <td>0.01572</td>\n      <td>0.00004</td>\n    </tr>\n    <tr>\n      <th>follow up</th>\n      <td>0.46015</td>\n      <td>0.02544</td>\n      <td>0.00137</td>\n      <td>0.27118</td>\n      <td>0.00440</td>\n      <td>0.18548</td>\n      <td>0.00219</td>\n      <td>0.12681</td>\n    </tr>\n    <tr>\n      <th>ignore</th>\n      <td>-1.74979</td>\n      <td>0.07209</td>\n      <td>0.00000</td>\n      <td>-1.71655</td>\n      <td>0.03455</td>\n      <td>0.00019</td>\n      <td>0.01339</td>\n      <td>0.00016</td>\n    </tr>\n    <tr>\n      <th>incorrect fact</th>\n      <td>-0.83946</td>\n      <td>0.03412</td>\n      <td>0.00020</td>\n      <td>-0.89117</td>\n      <td>0.01915</td>\n      <td>0.00557</td>\n      <td>0.00624</td>\n      <td>0.01002</td>\n    </tr>\n    <tr>\n      <th>irrelevant</th>\n      <td>-1.26057</td>\n      <td>0.06118</td>\n      <td>0.00000</td>\n      <td>-1.60563</td>\n      <td>0.04943</td>\n      <td>0.00001</td>\n      <td>0.01985</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>lack of empathy</th>\n      <td>-1.16185</td>\n      <td>0.04956</td>\n      <td>0.00001</td>\n      <td>-1.54854</td>\n      <td>0.04384</td>\n      <td>0.00002</td>\n      <td>0.01671</td>\n      <td>0.00003</td>\n    </tr>\n    <tr>\n      <th>life info</th>\n      <td>0.18006</td>\n      <td>0.00186</td>\n      <td>0.38999</td>\n      <td>0.32752</td>\n      <td>0.00306</td>\n      <td>0.26971</td>\n      <td>0.00085</td>\n      <td>0.34079</td>\n    </tr>\n    <tr>\n      <th>partner contradiction</th>\n      <td>-1.49766</td>\n      <td>0.04030</td>\n      <td>0.00005</td>\n      <td>-2.59899</td>\n      <td>0.06043</td>\n      <td>0.00000</td>\n      <td>0.02194</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>preference info</th>\n      <td>0.31426</td>\n      <td>0.00875</td>\n      <td>0.06159</td>\n      <td>0.26322</td>\n      <td>0.00306</td>\n      <td>0.26993</td>\n      <td>0.00098</td>\n      <td>0.30747</td>\n    </tr>\n    <tr>\n      <th>redundant</th>\n      <td>-0.42368</td>\n      <td>0.00251</td>\n      <td>0.31783</td>\n      <td>-2.05277</td>\n      <td>0.02931</td>\n      <td>0.00058</td>\n      <td>0.00970</td>\n      <td>0.00133</td>\n    </tr>\n    <tr>\n      <th>self contradiction</th>\n      <td>-1.27412</td>\n      <td>0.02447</td>\n      <td>0.00170</td>\n      <td>-1.91209</td>\n      <td>0.02745</td>\n      <td>0.00088</td>\n      <td>0.01009</td>\n      <td>0.00106</td>\n    </tr>\n    <tr>\n      <th>topic switch</th>\n      <td>-0.56434</td>\n      <td>0.01100</td>\n      <td>0.03599</td>\n      <td>0.02456</td>\n      <td>0.00001</td>\n      <td>0.94880</td>\n      <td>0.00000</td>\n      <td>0.98731</td>\n    </tr>\n    <tr>\n      <th>uninterpretable</th>\n      <td>-1.59035</td>\n      <td>0.00523</td>\n      <td>0.14900</td>\n      <td>-2.73952</td>\n      <td>0.00772</td>\n      <td>0.07922</td>\n      <td>0.00263</td>\n      <td>0.09489</td>\n    </tr>\n    <tr>\n      <th rowspan=\"8\" valign=\"top\">likert dialogue</th>\n      <th>consistent</th>\n      <td>0.03652</td>\n      <td>0.00544</td>\n      <td>0.14075</td>\n      <td>0.33319</td>\n      <td>0.22558</td>\n      <td>0.00000</td>\n      <td>0.09714</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>emotional</th>\n      <td>0.11540</td>\n      <td>0.03715</td>\n      <td>0.00010</td>\n      <td>0.40710</td>\n      <td>0.23022</td>\n      <td>0.00000</td>\n      <td>0.09427</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>engaging</th>\n      <td>0.06870</td>\n      <td>0.01141</td>\n      <td>0.03266</td>\n      <td>0.56247</td>\n      <td>0.38103</td>\n      <td>0.00000</td>\n      <td>0.17741</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>grammatical</th>\n      <td>0.02164</td>\n      <td>0.00097</td>\n      <td>0.53499</td>\n      <td>0.26529</td>\n      <td>0.07243</td>\n      <td>0.00000</td>\n      <td>0.03074</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>informative</th>\n      <td>0.01384</td>\n      <td>0.00038</td>\n      <td>0.69605</td>\n      <td>0.41837</td>\n      <td>0.17475</td>\n      <td>0.00000</td>\n      <td>0.06585</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>proactive</th>\n      <td>0.05628</td>\n      <td>0.00901</td>\n      <td>0.05784</td>\n      <td>0.44016</td>\n      <td>0.27452</td>\n      <td>0.00000</td>\n      <td>0.11944</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>quality</th>\n      <td>0.12029</td>\n      <td>0.02906</td>\n      <td>0.00062</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>relevant</th>\n      <td>0.11919</td>\n      <td>0.03677</td>\n      <td>0.00011</td>\n      <td>0.47207</td>\n      <td>0.28720</td>\n      <td>0.00000</td>\n      <td>0.12260</td>\n      <td>0.00000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@to_file\n",
    "def dialogue_quality_regressions(ev):\n",
    "    ldq, ltq = dialogue_metrics(ev)\n",
    "    ldq_groups = ldq.groupby(\n",
    "        [sym.category, sym.label]\n",
    "    )\n",
    "    ltq_groups = ltq.groupby(\n",
    "        [sym.category, sym.label]\n",
    "    )\n",
    "    names = ['Predicted', 'Metric']\n",
    "    linear_result = ldq_groups.apply(lambda x: regressions(x, model='linear'))\n",
    "    linear_result.columns = pd.MultiIndex.from_arrays(\n",
    "        [['Likert Dialogue Quality']*3,\n",
    "        ['LR Coefficient', 'LR R-Squared', stat.p_of_f_test]],\n",
    "        names=names\n",
    "    )\n",
    "    ordinal_result = ldq_groups.apply(lambda x: regressions(x, model='ordinal'))\n",
    "    ordinal_result.columns = pd.MultiIndex.from_arrays(\n",
    "        [['Likert Dialogue Quality']*2,\n",
    "        ['OR Pseudo R-Squared', stat.p_of_llr_test]],\n",
    "        names=names\n",
    "    )\n",
    "    linear_turn_result = ltq_groups.apply(regressions)\n",
    "    linear_turn_result.columns = pd.MultiIndex.from_arrays(\n",
    "        [['Likert Turn Quality']*3,\n",
    "        ['LR Coefficient', 'LR R-Squared', stat.p_of_f_test]],\n",
    "        names=names\n",
    "    )\n",
    "    result = pd.concat((linear_turn_result, linear_result, ordinal_result), axis=1)\n",
    "    return result.round(5)\n",
    "\n",
    "regs = dialogue_quality_regressions(\n",
    "    data.surge_evaluation,\n",
    "    reload='results/dialogue_quality_regressions'\n",
    ")\n",
    "regs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "Predicted         category                      label Likert Dialogue Quality  \\\nMetric                                                           LR R-Squared   \n0              likert turn                 consistent                 0.02999   \n1              likert turn                  emotional                 0.02943   \n2              likert turn                   engaging                 0.02729   \n3              likert turn                grammatical                 0.00010   \n4              likert turn                informative                 0.00159   \n5              likert turn                  proactive                 0.02868   \n6              likert turn                    quality                 0.02906   \n7              likert turn                   relevant                 0.03776   \n8                 behavior                 antisocial                 0.00013   \n9                 behavior  commonsense contradiction                 0.06103   \n10                behavior               correct fact                 0.00010   \n11                behavior                 empathetic                 0.04044   \n12                behavior                  follow up                 0.00440   \n13                behavior                     ignore                 0.03455   \n14                behavior             incorrect fact                 0.01915   \n15                behavior                 irrelevant                 0.04943   \n16                behavior            lack of empathy                 0.04384   \n17                behavior                  life info                 0.00306   \n18                behavior      partner contradiction                 0.06043   \n19                behavior            preference info                 0.00306   \n20                behavior                  redundant                 0.02931   \n21                behavior         self contradiction                 0.02745   \n22                behavior               topic switch                 0.00001   \n23                behavior            uninterpretable                 0.00772   \n24         likert dialogue                 consistent                 0.22558   \n25         likert dialogue                  emotional                 0.23022   \n26         likert dialogue                   engaging                 0.38103   \n27         likert dialogue                grammatical                 0.07243   \n28         likert dialogue                informative                 0.17475   \n29         likert dialogue                  proactive                 0.27452   \n30         likert dialogue                   relevant                 0.28720   \n\nPredicted                    \nMetric    P value of F-test  \n0                   0.00050  \n1                   0.00057  \n2                   0.00091  \n3                   0.83866  \n4                   0.42573  \n5                   0.00067  \n6                   0.00062  \n7                   0.00009  \n8                   0.82001  \n9                   0.00000  \n10                  0.84188  \n11                  0.00005  \n12                  0.18548  \n13                  0.00019  \n14                  0.00557  \n15                  0.00001  \n16                  0.00002  \n17                  0.26971  \n18                  0.00000  \n19                  0.26993  \n20                  0.00058  \n21                  0.00088  \n22                  0.94880  \n23                  0.07922  \n24                  0.00000  \n25                  0.00000  \n26                  0.00000  \n27                  0.00000  \n28                  0.00000  \n29                  0.00000  \n30                  0.00000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th>Predicted</th>\n      <th>category</th>\n      <th>label</th>\n      <th colspan=\"2\" halign=\"left\">Likert Dialogue Quality</th>\n    </tr>\n    <tr>\n      <th>Metric</th>\n      <th></th>\n      <th></th>\n      <th>LR R-Squared</th>\n      <th>P value of F-test</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>likert turn</td>\n      <td>consistent</td>\n      <td>0.02999</td>\n      <td>0.00050</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>likert turn</td>\n      <td>emotional</td>\n      <td>0.02943</td>\n      <td>0.00057</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>likert turn</td>\n      <td>engaging</td>\n      <td>0.02729</td>\n      <td>0.00091</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>likert turn</td>\n      <td>grammatical</td>\n      <td>0.00010</td>\n      <td>0.83866</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>likert turn</td>\n      <td>informative</td>\n      <td>0.00159</td>\n      <td>0.42573</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>likert turn</td>\n      <td>proactive</td>\n      <td>0.02868</td>\n      <td>0.00067</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>likert turn</td>\n      <td>quality</td>\n      <td>0.02906</td>\n      <td>0.00062</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>likert turn</td>\n      <td>relevant</td>\n      <td>0.03776</td>\n      <td>0.00009</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>behavior</td>\n      <td>antisocial</td>\n      <td>0.00013</td>\n      <td>0.82001</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>behavior</td>\n      <td>commonsense contradiction</td>\n      <td>0.06103</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>behavior</td>\n      <td>correct fact</td>\n      <td>0.00010</td>\n      <td>0.84188</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>behavior</td>\n      <td>empathetic</td>\n      <td>0.04044</td>\n      <td>0.00005</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>behavior</td>\n      <td>follow up</td>\n      <td>0.00440</td>\n      <td>0.18548</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>behavior</td>\n      <td>ignore</td>\n      <td>0.03455</td>\n      <td>0.00019</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>behavior</td>\n      <td>incorrect fact</td>\n      <td>0.01915</td>\n      <td>0.00557</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>behavior</td>\n      <td>irrelevant</td>\n      <td>0.04943</td>\n      <td>0.00001</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>behavior</td>\n      <td>lack of empathy</td>\n      <td>0.04384</td>\n      <td>0.00002</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>behavior</td>\n      <td>life info</td>\n      <td>0.00306</td>\n      <td>0.26971</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>behavior</td>\n      <td>partner contradiction</td>\n      <td>0.06043</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>behavior</td>\n      <td>preference info</td>\n      <td>0.00306</td>\n      <td>0.26993</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>behavior</td>\n      <td>redundant</td>\n      <td>0.02931</td>\n      <td>0.00058</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>behavior</td>\n      <td>self contradiction</td>\n      <td>0.02745</td>\n      <td>0.00088</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>behavior</td>\n      <td>topic switch</td>\n      <td>0.00001</td>\n      <td>0.94880</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>behavior</td>\n      <td>uninterpretable</td>\n      <td>0.00772</td>\n      <td>0.07922</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>likert dialogue</td>\n      <td>consistent</td>\n      <td>0.22558</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>likert dialogue</td>\n      <td>emotional</td>\n      <td>0.23022</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>likert dialogue</td>\n      <td>engaging</td>\n      <td>0.38103</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>likert dialogue</td>\n      <td>grammatical</td>\n      <td>0.07243</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>likert dialogue</td>\n      <td>informative</td>\n      <td>0.17475</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>likert dialogue</td>\n      <td>proactive</td>\n      <td>0.27452</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>likert dialogue</td>\n      <td>relevant</td>\n      <td>0.28720</td>\n      <td>0.00000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_plot_regs = regs[[(\"Likert Dialogue Quality\", \"LR R-Squared\"), (\"Likert Dialogue Quality\", \"P value of F-test\")]]\n",
    "to_plot_regs = to_plot_regs.drop((\"likert dialogue\", \"quality\"))\n",
    "to_plot_regs = to_plot_regs.reset_index()\n",
    "to_plot_regs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "regs = prettify(regs, to_csv=\"results/paper/predictive_validity.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Incremental Validity"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "                                       Adjusted R-Squared  P value of F-test\nlikert turn emotional                             0.17799            0.00000\n            relevant                              0.17720            0.00000\n            consistent                            0.17213            0.00000\nbehavior    redundant                             0.17160            0.00000\n            empathetic                            0.16777            0.00000\n            commonsense contradiction             0.15683            0.00000\nlikert turn informative                           0.15412            0.00000\nbehavior    self contradiction                    0.15336            0.00000\n            life info                             0.14527            0.00000\nlikert turn proactive                             0.14519            0.00000\nbehavior    antisocial                            0.13908            0.00000\n            incorrect fact                        0.13901            0.00000\n            partner contradiction                 0.12782            0.00000\n            correct fact                          0.11063            0.00000\n            lack of empathy                       0.10907            0.00000\n            irrelevant                            0.10015            0.00000\nlikert turn engaging                              0.07098            0.00014\nbehavior    uninterpretable                       0.04991            0.00253\n            topic switch                          0.04041            0.00600\n            follow up                             0.03633            0.00547\nlikert turn grammatical                           0.03606            0.00223\nbehavior    ignore                                0.03606            0.00068\n            preference info                       0.00306            0.26993",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>Adjusted R-Squared</th>\n      <th>P value of F-test</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">likert turn</th>\n      <th>emotional</th>\n      <td>0.17799</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>relevant</th>\n      <td>0.17720</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>consistent</th>\n      <td>0.17213</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">behavior</th>\n      <th>redundant</th>\n      <td>0.17160</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>empathetic</th>\n      <td>0.16777</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>commonsense contradiction</th>\n      <td>0.15683</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>likert turn</th>\n      <th>informative</th>\n      <td>0.15412</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">behavior</th>\n      <th>self contradiction</th>\n      <td>0.15336</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>life info</th>\n      <td>0.14527</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>likert turn</th>\n      <th>proactive</th>\n      <td>0.14519</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th rowspan=\"6\" valign=\"top\">behavior</th>\n      <th>antisocial</th>\n      <td>0.13908</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>incorrect fact</th>\n      <td>0.13901</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>partner contradiction</th>\n      <td>0.12782</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>correct fact</th>\n      <td>0.11063</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>lack of empathy</th>\n      <td>0.10907</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>irrelevant</th>\n      <td>0.10015</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>likert turn</th>\n      <th>engaging</th>\n      <td>0.07098</td>\n      <td>0.00014</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">behavior</th>\n      <th>uninterpretable</th>\n      <td>0.04991</td>\n      <td>0.00253</td>\n    </tr>\n    <tr>\n      <th>topic switch</th>\n      <td>0.04041</td>\n      <td>0.00600</td>\n    </tr>\n    <tr>\n      <th>follow up</th>\n      <td>0.03633</td>\n      <td>0.00547</td>\n    </tr>\n    <tr>\n      <th>likert turn</th>\n      <th>grammatical</th>\n      <td>0.03606</td>\n      <td>0.00223</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">behavior</th>\n      <th>ignore</th>\n      <td>0.03606</td>\n      <td>0.00068</td>\n    </tr>\n    <tr>\n      <th>preference info</th>\n      <td>0.00306</td>\n      <td>0.26993</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def drop_column_level_duplication(df: pd.DataFrame, columns, levels=None):\n",
    "    if levels is None:\n",
    "        levels = list(range(len(columns)))\n",
    "    level_columns = df.xs(columns, axis=1, level=levels)\n",
    "    unique = level_columns.iloc[:,0].to_frame()\n",
    "    unique.columns = [columns]\n",
    "    dropped = df.drop(columns=columns, level=levels)\n",
    "    result = pd.concat([dropped, unique], axis=1)\n",
    "    return result\n",
    "\n",
    "def multivariate_regression(df: pd.DataFrame, model='linear'):\n",
    "    def apply_regressions(df: pd.DataFrame):\n",
    "        unstacked = df.unstack([sym.category, sym.label])\n",
    "        unstacked = drop_column_level_duplication(unstacked, 'quality', 0)\n",
    "        results = regressions(unstacked, quality_column_name='quality', model=model)\n",
    "        return results\n",
    "    result = apply_regressions(df)\n",
    "    result.index = [\n",
    "        (idx[1] if isinstance(idx, tuple) else idx)\n",
    "        for idx in result.index.values\n",
    "    ]\n",
    "    return result.round(5)\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "@to_file\n",
    "def incremental_regression(\n",
    "        df: pd.DataFrame,\n",
    "        categories,\n",
    "        model='linear',\n",
    "        exclude_quality=True,\n",
    "        beam=1,\n",
    "        select='backward'\n",
    "):\n",
    "    data_points = set(df.index.get_level_values('dialogue'))\n",
    "    num_data_points = len(data_points)\n",
    "    adjust = lambda r2, f: 1 - (1 - r2) * ((num_data_points - 1) / (num_data_points - f))\n",
    "    Step: type = namedtuple('Step', ('r2', 'p', 'feature'))\n",
    "    class Path(list):\n",
    "        def metric(self):\n",
    "            # if len(self) == 0: return 0\n",
    "            # else: return self[-1].llr if len(self) == 1 else self[-1].llr / self[-2].llr\n",
    "            return self.r2\n",
    "        @property\n",
    "        def r2(self):\n",
    "            return adjust(self[-1].r2, len(self)) if self else 0\n",
    "        # @property\n",
    "        # def adj_r2(self):\n",
    "        #     return adjust(self.r2, len(self))\n",
    "        @property\n",
    "        def p(self): return self[-1].p if self else 1\n",
    "        @property\n",
    "        def features(self): return {x.feature for x in self}\n",
    "    r2_name = stat.r2 if model=='linear' else stat.mcfad_r2\n",
    "    p_name = stat.p_of_f_test if model=='linear' else stat.p_of_llr_test\n",
    "    frontier = [Path()]\n",
    "    feature_pool = {\n",
    "        x[:2] for x in df.index.values\n",
    "        if (not (exclude_quality and scale.quality in x))\n",
    "        and x[0] in categories\n",
    "    }\n",
    "    for _ in feature_pool:\n",
    "        new_frontier = []\n",
    "        for path in frontier:\n",
    "            for candidate in feature_pool - path.features:\n",
    "                if select == 'forward':\n",
    "                    candidate_features = path.features | {candidate}\n",
    "                elif select == 'backward':\n",
    "                    candidate_features = feature_pool - path.features\n",
    "                else:\n",
    "                    raise ValueError('param select must be one of {\"forward\", \"backward\"}')\n",
    "                row_mask = [\n",
    "                    x[:2] in candidate_features\n",
    "                    and (not (exclude_quality and scale.quality in x))\n",
    "                    and x[0] in categories\n",
    "                    for x in df.index.values\n",
    "                ]\n",
    "                candidate_df = df.loc[row_mask, :]\n",
    "                candidate_results = multivariate_regression(candidate_df, model=model)\n",
    "                r2 = candidate_results[r2_name].item()\n",
    "                p = candidate_results[p_name]\n",
    "                new_frontier.append(Path([*path, Step(r2, p, candidate)]))\n",
    "        frontier = sorted(new_frontier, key=lambda x: x.metric(), reverse=True)[:beam]\n",
    "    result = {step.feature: {'Adjusted R-Squared': step.r2, p_name: step.p} for step in frontier[0]}\n",
    "    return pd.DataFrame(result.values(), result)\n",
    "\n",
    "\n",
    "ldq, ltq = dialogue_metrics(data.surge_evaluation)\n",
    "regs = incremental_regression(\n",
    "    ldq, (category.likert_turn, category.behavior), beam=1,\n",
    "    reload='results/dialogue_incremental_regressions'\n",
    ")\n",
    "regs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "                                    Adjusted R-Squared  P value of F-test\nbehavior antisocial                            0.15964                0.0\n         life info                             0.15955                0.0\n         preference info                       0.15850                0.0\n         commonsense contradiction             0.15692                0.0\n         uninterpretable                       0.15503                0.0\n         ignore                                0.15250                0.0\n         correct fact                          0.15197                0.0\n         topic switch                          0.14809                0.0\n         follow up                             0.14527                0.0\n         redundant                             0.14366                0.0\n         lack of empathy                       0.13925                0.0\n         incorrect fact                        0.13547                0.0\n         self contradiction                    0.12608                0.0\n         irrelevant                            0.11049                0.0\n         empathetic                            0.09489                0.0\n         partner contradiction                 0.06043                0.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>Adjusted R-Squared</th>\n      <th>P value of F-test</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"16\" valign=\"top\">behavior</th>\n      <th>antisocial</th>\n      <td>0.15964</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>life info</th>\n      <td>0.15955</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>preference info</th>\n      <td>0.15850</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>commonsense contradiction</th>\n      <td>0.15692</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>uninterpretable</th>\n      <td>0.15503</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>ignore</th>\n      <td>0.15250</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>correct fact</th>\n      <td>0.15197</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>topic switch</th>\n      <td>0.14809</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>follow up</th>\n      <td>0.14527</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>redundant</th>\n      <td>0.14366</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>lack of empathy</th>\n      <td>0.13925</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>incorrect fact</th>\n      <td>0.13547</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>self contradiction</th>\n      <td>0.12608</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>irrelevant</th>\n      <td>0.11049</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>empathetic</th>\n      <td>0.09489</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>partner contradiction</th>\n      <td>0.06043</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "behavior_regs = incremental_regression(\n",
    "    ldq, (category.behavior,), beam=10,\n",
    "    reload='results/behavior_incremental_regressions'\n",
    ")\n",
    "behavior_regs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "                         Adjusted R-Squared  P value of F-test\nlikert turn grammatical             0.08566            0.00001\n            informative             0.08508            0.00000\n            engaging                0.08285            0.00000\n            emotional               0.07753            0.00000\n            consistent              0.06889            0.00000\n            proactive               0.05786            0.00001\n            relevant                0.03776            0.00009",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>Adjusted R-Squared</th>\n      <th>P value of F-test</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"7\" valign=\"top\">likert turn</th>\n      <th>grammatical</th>\n      <td>0.08566</td>\n      <td>0.00001</td>\n    </tr>\n    <tr>\n      <th>informative</th>\n      <td>0.08508</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>engaging</th>\n      <td>0.08285</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>emotional</th>\n      <td>0.07753</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>consistent</th>\n      <td>0.06889</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>proactive</th>\n      <td>0.05786</td>\n      <td>0.00001</td>\n    </tr>\n    <tr>\n      <th>relevant</th>\n      <td>0.03776</td>\n      <td>0.00009</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likert_turn_regs = incremental_regression(\n",
    "    ldq, (category.likert_turn,), beam=10,\n",
    "    reload='results/likert_turn_incremental_regressions'\n",
    ")\n",
    "likert_turn_regs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "                             Adjusted R-Squared  P value of F-test\nlikert dialogue emotional               0.58426                0.0\n                informative             0.57832                0.0\n                grammatical             0.56439                0.0\n                relevant                0.54517                0.0\n                proactive               0.51636                0.0\n                consistent              0.48673                0.0\n                engaging                0.38103                0.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>Adjusted R-Squared</th>\n      <th>P value of F-test</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"7\" valign=\"top\">likert dialogue</th>\n      <th>emotional</th>\n      <td>0.58426</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>informative</th>\n      <td>0.57832</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>grammatical</th>\n      <td>0.56439</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>relevant</th>\n      <td>0.54517</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>proactive</th>\n      <td>0.51636</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>consistent</th>\n      <td>0.48673</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>engaging</th>\n      <td>0.38103</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likert_dialogue_regs = incremental_regression(\n",
    "    ldq, (category.likert_dialogue,), beam=10,\n",
    "    reload='results/likert_dialogue_incremental_regressions'\n",
    ")\n",
    "likert_dialogue_regs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Table for Paper"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "                     ABC-Eval  Adjusted R-Squared R-Squared    delta  \\\n0                  antisocial             0.15964   15.9640      nan   \n1                   life info             0.15955   15.9550  -0.0090   \n2             preference info             0.15850   15.8500  -0.1050   \n3   commonsense contradiction             0.15692   15.6920  -0.1580   \n4             uninterpretable             0.15503   15.5030  -0.1890   \n5                      ignore             0.15250   15.2500  -0.2530   \n6                correct fact             0.15197   15.1970  -0.0530   \n7                topic switch             0.14809   14.8090  -0.3880   \n8                   follow up             0.14527   14.5270  -0.2820   \n9                   redundant             0.14366   14.3660  -0.1610   \n10            lack of empathy             0.13925   13.9250  -0.4410   \n11             incorrect fact             0.13547   13.5470  -0.3780   \n12         self contradiction             0.12608   12.6080  -0.9390   \n13                 irrelevant             0.11049   11.0490  -1.5590   \n14                 empathetic             0.09489    9.4890  -1.5600   \n15      partner contradiction             0.06043    6.0430  -3.4460   \n\n      R-Squared delta  \n0       15.9640 (nan)  \n1   15.9550 (-0.0090)  \n2   15.8500 (-0.1050)  \n3   15.6920 (-0.1580)  \n4   15.5030 (-0.1890)  \n5   15.2500 (-0.2530)  \n6   15.1970 (-0.0530)  \n7   14.8090 (-0.3880)  \n8   14.5270 (-0.2820)  \n9   14.3660 (-0.1610)  \n10  13.9250 (-0.4410)  \n11  13.5470 (-0.3780)  \n12  12.6080 (-0.9390)  \n13  11.0490 (-1.5590)  \n14   9.4890 (-1.5600)  \n15   6.0430 (-3.4460)  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ABC-Eval</th>\n      <th>Adjusted R-Squared</th>\n      <th>R-Squared</th>\n      <th>delta</th>\n      <th>R-Squared delta</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>antisocial</td>\n      <td>0.15964</td>\n      <td>15.9640</td>\n      <td>nan</td>\n      <td>15.9640 (nan)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>life info</td>\n      <td>0.15955</td>\n      <td>15.9550</td>\n      <td>-0.0090</td>\n      <td>15.9550 (-0.0090)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>preference info</td>\n      <td>0.15850</td>\n      <td>15.8500</td>\n      <td>-0.1050</td>\n      <td>15.8500 (-0.1050)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>commonsense contradiction</td>\n      <td>0.15692</td>\n      <td>15.6920</td>\n      <td>-0.1580</td>\n      <td>15.6920 (-0.1580)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>uninterpretable</td>\n      <td>0.15503</td>\n      <td>15.5030</td>\n      <td>-0.1890</td>\n      <td>15.5030 (-0.1890)</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>ignore</td>\n      <td>0.15250</td>\n      <td>15.2500</td>\n      <td>-0.2530</td>\n      <td>15.2500 (-0.2530)</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>correct fact</td>\n      <td>0.15197</td>\n      <td>15.1970</td>\n      <td>-0.0530</td>\n      <td>15.1970 (-0.0530)</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>topic switch</td>\n      <td>0.14809</td>\n      <td>14.8090</td>\n      <td>-0.3880</td>\n      <td>14.8090 (-0.3880)</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>follow up</td>\n      <td>0.14527</td>\n      <td>14.5270</td>\n      <td>-0.2820</td>\n      <td>14.5270 (-0.2820)</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>redundant</td>\n      <td>0.14366</td>\n      <td>14.3660</td>\n      <td>-0.1610</td>\n      <td>14.3660 (-0.1610)</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>lack of empathy</td>\n      <td>0.13925</td>\n      <td>13.9250</td>\n      <td>-0.4410</td>\n      <td>13.9250 (-0.4410)</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>incorrect fact</td>\n      <td>0.13547</td>\n      <td>13.5470</td>\n      <td>-0.3780</td>\n      <td>13.5470 (-0.3780)</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>self contradiction</td>\n      <td>0.12608</td>\n      <td>12.6080</td>\n      <td>-0.9390</td>\n      <td>12.6080 (-0.9390)</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>irrelevant</td>\n      <td>0.11049</td>\n      <td>11.0490</td>\n      <td>-1.5590</td>\n      <td>11.0490 (-1.5590)</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>empathetic</td>\n      <td>0.09489</td>\n      <td>9.4890</td>\n      <td>-1.5600</td>\n      <td>9.4890 (-1.5600)</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>partner contradiction</td>\n      <td>0.06043</td>\n      <td>6.0430</td>\n      <td>-3.4460</td>\n      <td>6.0430 (-3.4460)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_delta(df):\n",
    "    df['R-Squared'] = (df['Adjusted R-Squared']*100)\n",
    "    df['delta'] = df['R-Squared'].diff()\n",
    "    df['delta'] = df['delta'].map('{:.4f}'.format)\n",
    "    df['R-Squared'] = df['R-Squared'].map('{:.4f}'.format)\n",
    "    df['R-Squared delta'] = df['R-Squared'] + ' (' + df['delta'] + ')'\n",
    "\n",
    "final_behavior_regs = behavior_regs.reset_index().rename({'level_1': 'ABC-Eval'}, axis=1).drop(['level_0', 'P value of F-test'], axis=1)\n",
    "add_delta(final_behavior_regs)\n",
    "\n",
    "final_likert_turn_regs = likert_turn_regs.reset_index().rename({'level_1': 'Likert Turn'}, axis=1).drop(['level_0', 'P value of F-test'], axis=1)\n",
    "add_delta(final_likert_turn_regs)\n",
    "\n",
    "final_likert_dialogue_regs = likert_dialogue_regs.reset_index().rename({'level_1': 'Likert Dialogue'}, axis=1).drop(['level_0', 'P value of F-test'], axis=1)\n",
    "add_delta(final_likert_dialogue_regs)\n",
    "\n",
    "final_behavior_regs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "                     ABC-Eval    R-Squared delta  Likert Turn  \\\n0                  antisocial      15.9640 (nan)  grammatical   \n1                   life info  15.9550 (-0.0090)  informative   \n2             preference info  15.8500 (-0.1050)     engaging   \n3   commonsense contradiction  15.6920 (-0.1580)    emotional   \n4             uninterpretable  15.5030 (-0.1890)   consistent   \n5                      ignore  15.2500 (-0.2530)    proactive   \n6                correct fact  15.1970 (-0.0530)     relevant   \n7                topic switch  14.8090 (-0.3880)          NaN   \n8                   follow up  14.5270 (-0.2820)          NaN   \n9                   redundant  14.3660 (-0.1610)          NaN   \n10            lack of empathy  13.9250 (-0.4410)          NaN   \n11             incorrect fact  13.5470 (-0.3780)          NaN   \n12         self contradiction  12.6080 (-0.9390)          NaN   \n13                 irrelevant  11.0490 (-1.5590)          NaN   \n14                 empathetic   9.4890 (-1.5600)          NaN   \n15      partner contradiction   6.0430 (-3.4460)          NaN   \n\n     R-Squared delta Likert Dialogue     R-Squared delta  \n0       8.5660 (nan)       emotional       58.4260 (nan)  \n1   8.5080 (-0.0580)     informative   57.8320 (-0.5940)  \n2   8.2850 (-0.2230)     grammatical   56.4390 (-1.3930)  \n3   7.7530 (-0.5320)        relevant   54.5170 (-1.9220)  \n4   6.8890 (-0.8640)       proactive   51.6360 (-2.8810)  \n5   5.7860 (-1.1030)      consistent   48.6730 (-2.9630)  \n6   3.7760 (-2.0100)        engaging  38.1030 (-10.5700)  \n7                NaN             NaN                 NaN  \n8                NaN             NaN                 NaN  \n9                NaN             NaN                 NaN  \n10               NaN             NaN                 NaN  \n11               NaN             NaN                 NaN  \n12               NaN             NaN                 NaN  \n13               NaN             NaN                 NaN  \n14               NaN             NaN                 NaN  \n15               NaN             NaN                 NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ABC-Eval</th>\n      <th>R-Squared delta</th>\n      <th>Likert Turn</th>\n      <th>R-Squared delta</th>\n      <th>Likert Dialogue</th>\n      <th>R-Squared delta</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>antisocial</td>\n      <td>15.9640 (nan)</td>\n      <td>grammatical</td>\n      <td>8.5660 (nan)</td>\n      <td>emotional</td>\n      <td>58.4260 (nan)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>life info</td>\n      <td>15.9550 (-0.0090)</td>\n      <td>informative</td>\n      <td>8.5080 (-0.0580)</td>\n      <td>informative</td>\n      <td>57.8320 (-0.5940)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>preference info</td>\n      <td>15.8500 (-0.1050)</td>\n      <td>engaging</td>\n      <td>8.2850 (-0.2230)</td>\n      <td>grammatical</td>\n      <td>56.4390 (-1.3930)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>commonsense contradiction</td>\n      <td>15.6920 (-0.1580)</td>\n      <td>emotional</td>\n      <td>7.7530 (-0.5320)</td>\n      <td>relevant</td>\n      <td>54.5170 (-1.9220)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>uninterpretable</td>\n      <td>15.5030 (-0.1890)</td>\n      <td>consistent</td>\n      <td>6.8890 (-0.8640)</td>\n      <td>proactive</td>\n      <td>51.6360 (-2.8810)</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>ignore</td>\n      <td>15.2500 (-0.2530)</td>\n      <td>proactive</td>\n      <td>5.7860 (-1.1030)</td>\n      <td>consistent</td>\n      <td>48.6730 (-2.9630)</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>correct fact</td>\n      <td>15.1970 (-0.0530)</td>\n      <td>relevant</td>\n      <td>3.7760 (-2.0100)</td>\n      <td>engaging</td>\n      <td>38.1030 (-10.5700)</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>topic switch</td>\n      <td>14.8090 (-0.3880)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>follow up</td>\n      <td>14.5270 (-0.2820)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>redundant</td>\n      <td>14.3660 (-0.1610)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>lack of empathy</td>\n      <td>13.9250 (-0.4410)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>incorrect fact</td>\n      <td>13.5470 (-0.3780)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>self contradiction</td>\n      <td>12.6080 (-0.9390)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>irrelevant</td>\n      <td>11.0490 (-1.5590)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>empathetic</td>\n      <td>9.4890 (-1.5600)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>partner contradiction</td>\n      <td>6.0430 (-3.4460)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined = pd.concat(\n",
    "    [\n",
    "        final_behavior_regs[['ABC-Eval', 'R-Squared delta']],\n",
    "        final_likert_turn_regs[['Likert Turn', 'R-Squared delta']],\n",
    "        final_likert_dialogue_regs[['Likert Dialogue', 'R-Squared delta']]\n",
    "    ],\n",
    "    axis=1)\n",
    "\n",
    "combined.to_csv('results/paper/incremental_validity.csv', index=False)\n",
    "combined"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}