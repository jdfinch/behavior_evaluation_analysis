{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from analysis import *\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "from scipy.stats import binom_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "surge_annotations = data.surge_evaluation.annotation_dataframe()\n",
    "surge_annotations_comparative = data.surge_evaluation.comparative_annotation_dataframe()\n",
    "\n",
    "surge_annotations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 8 Comprehensive Analysis"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Metric Sensitivity"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "def p_vals(df: pd.DataFrame, test='t'):\n",
    "    \"\"\"\n",
    "    :param df: (bot, data point) x 1 -> score\n",
    "    :param test: statistical test function (t for t test, p for prop test, s for sign test)\n",
    "    :return: p values of test on each bot pair (pd.Series)\n",
    "    \"\"\"\n",
    "    bots = set(df.index.get_level_values(0))\n",
    "    bot_pairs = list(combinations(bots, 2))\n",
    "    result = {}\n",
    "    for ba, bb in bot_pairs:\n",
    "        a = df.xs(ba).to_numpy().squeeze()\n",
    "        b = df.xs(bb).to_numpy().squeeze()\n",
    "        if test == 't':\n",
    "            t, p = ttest_ind(a, b, equal_var=False)\n",
    "        elif test == 'p':\n",
    "            z, p = proportions_ztest(count=[\n",
    "                sum(a), sum(b)\n",
    "            ], nobs=[\n",
    "                len(a), len(b)\n",
    "            ])\n",
    "        elif test == 's':\n",
    "            # sign test\n",
    "            a = a[a==1]\n",
    "            b = b[b==1]\n",
    "            p = binom_test(sum(a), sum(a)+sum(b), p=0.5)\n",
    "        else:\n",
    "            raise ValueError('invalid arg for param \"test\"')\n",
    "        result[(ba, bb)] = p\n",
    "    result_series = pd.Series(result.values(), result)\n",
    "    return result_series\n",
    "\n",
    "@to_file\n",
    "def t_test_p_values_comparing_bots(annotations):\n",
    "    annotations = get_singly_annotated(annotations)\n",
    "    prop_annotations = annotations.xs(\n",
    "        category.behavior, level=sym.category, drop_level=False\n",
    "    )\n",
    "    comp_annotations = annotations.xs(\n",
    "        category.comparative, level=sym.category, drop_level=False\n",
    "    )\n",
    "    mean_annotations = annotations.drop(\n",
    "        index=category.behavior, level=sym.category\n",
    "    ).drop(\n",
    "        index=category.comparative, level=sym.category\n",
    "    )\n",
    "    mean_ps = mean_annotations.groupby(\n",
    "        [sym.category, sym.label]\n",
    "    ).apply(p_vals)\n",
    "    prop_ps = prop_annotations.groupby(\n",
    "        [sym.category, sym.label]\n",
    "    ).apply(lambda x: p_vals(x, test='p'))\n",
    "    comp_ps = comp_annotations.groupby(\n",
    "        [sym.category, sym.label]\n",
    "    ).apply(lambda x: p_vals(x, test='s'))\n",
    "    result = pd.concat([prop_ps, mean_ps, comp_ps], axis=0)\n",
    "    return result\n",
    "\n",
    "t_test_p_values_comparing_bots(surge_annotations, load='results/t_test_p_values_comparing_bots')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Predictive Validity"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "Predicted                                 Likert Turn Quality               \\\nMetric                                         LR Coefficient LR R-Squared   \ncategory        label                                                        \nlikert turn     consistent                            0.22018      0.04654   \n                emotional                             0.16635      0.02928   \n                engaging                              0.16493      0.04114   \n                grammatical                           0.29904      0.06781   \n                informative                           0.01924      0.00040   \n                proactive                             0.21331      0.06253   \n                quality                               1.00000      1.00000   \n                relevant                              0.25511      0.09226   \nbehavior        antisocial                           -3.60729      0.00827   \n                commonsense contradiction            -1.19415      0.06063   \n                correct fact                         -0.37007      0.01075   \n                empathetic                            0.53305      0.03006   \n                follow up                             0.51605      0.03255   \n                ignore                               -1.71880      0.07233   \n                incorrect fact                       -0.90583      0.03955   \n                irrelevant                           -1.21588      0.05546   \n                lack of empathy                      -1.03156      0.03894   \n                life info                             0.21801      0.00280   \n                partner contradiction                -1.43733      0.03773   \n                preference info                       0.35770      0.01165   \n                redundant                            -0.42178      0.00264   \n                self contradiction                   -1.19834      0.02215   \n                topic switch                         -0.64819      0.01557   \n                uninterpretable                      -2.07462      0.00883   \nlikert dialogue consistent                            0.03822      0.00604   \n                emotional                             0.09712      0.02544   \n                engaging                              0.08389      0.01732   \n                grammatical                           0.03235      0.00221   \n                informative                           0.01647      0.00057   \n                proactive                             0.05898      0.01004   \n                quality                               0.10592      0.02412   \n                relevant                              0.12210      0.03822   \n\nPredicted                                                    \\\nMetric                                    P value of F-test   \ncategory        label                                         \nlikert turn     consistent                          0.00001   \n                emotional                           0.00059   \n                engaging                            0.00004   \n                grammatical                         0.00000   \n                informative                         0.68836   \n                proactive                           0.00000   \n                quality                             0.00000   \n                relevant                            0.00000   \nbehavior        antisocial                          0.06928   \n                commonsense contradiction           0.00000   \n                correct fact                        0.03816   \n                empathetic                          0.00050   \n                follow up                           0.00029   \n                ignore                              0.00000   \n                incorrect fact                      0.00006   \n                irrelevant                          0.00000   \n                lack of empathy                     0.00007   \n                life info                           0.29079   \n                partner contradiction               0.00009   \n                preference info                     0.03094   \n                redundant                           0.30520   \n                self contradiction                  0.00285   \n                topic switch                        0.01252   \n                uninterpretable                     0.06044   \nlikert dialogue consistent                          0.12082   \n                emotional                           0.00137   \n                engaging                            0.00840   \n                grammatical                         0.34831   \n                informative                         0.63504   \n                proactive                           0.04517   \n                quality                             0.00184   \n                relevant                            0.00008   \n\nPredicted                                 Likert Dialogue Quality  \\\nMetric                                             LR Coefficient   \ncategory        label                                               \nlikert turn     consistent                                0.24864   \n                emotional                                 0.22243   \n                engaging                                  0.19437   \n                grammatical                               0.00659   \n                informative                              -0.05261   \n                proactive                                 0.22051   \n                quality                                   0.22776   \n                relevant                                  0.21768   \nbehavior        antisocial                               -0.00927   \n                commonsense contradiction                -2.06686   \n                correct fact                             -0.08224   \n                empathetic                                0.90559   \n                follow up                                 0.32794   \n                ignore                                   -1.96812   \n                incorrect fact                           -0.69496   \n                irrelevant                               -1.66669   \n                lack of empathy                          -1.82071   \n                life info                                 0.42049   \n                partner contradiction                    -3.32392   \n                preference info                           0.25218   \n                redundant                                -2.65851   \n                self contradiction                       -1.82208   \n                topic switch                             -0.15859   \n                uninterpretable                          -3.30846   \nlikert dialogue consistent                                0.38390   \n                emotional                                 0.45774   \n                engaging                                  0.58396   \n                grammatical                               0.28315   \n                informative                               0.46460   \n                proactive                                 0.47087   \n                quality                                   1.00000   \n                relevant                                  0.51230   \n\nPredicted                                                                 \\\nMetric                                    LR R-Squared P value of F-test   \ncategory        label                                                      \nlikert turn     consistent                     0.02760           0.00085   \n                emotional                      0.02434           0.00175   \n                engaging                       0.02657           0.00107   \n                grammatical                    0.00002           0.93777   \n                informative                    0.00141           0.45444   \n                proactive                      0.03107           0.00040   \n                quality                        0.02412           0.00184   \n                relevant                       0.03124           0.00038   \nbehavior        antisocial                     0.00000           0.99747   \n                commonsense contradiction      0.08446           0.00000   \n                correct fact                   0.00025           0.75402   \n                empathetic                     0.04034           0.00005   \n                follow up                      0.00611           0.11850   \n                ignore                         0.04410           0.00002   \n                incorrect fact                 0.01083           0.03750   \n                irrelevant                     0.04846           0.00001   \n                lack of empathy                0.05641           0.00000   \n                life info                      0.00485           0.16446   \n                partner contradiction          0.09382           0.00000   \n                preference info                0.00269           0.30064   \n                redundant                      0.04880           0.00001   \n                self contradiction             0.02381           0.00197   \n                topic switch                   0.00043           0.67809   \n                uninterpretable                0.01044           0.04108   \nlikert dialogue consistent                     0.28328           0.00000   \n                emotional                      0.26276           0.00000   \n                engaging                       0.39031           0.00000   \n                grammatical                    0.07875           0.00000   \n                informative                    0.20974           0.00000   \n                proactive                      0.29764           0.00000   \n                quality                        1.00000           0.00000   \n                relevant                       0.31291           0.00000   \n\nPredicted                                                      \\\nMetric                                    OR Pseudo R-Squared   \ncategory        label                                           \nlikert turn     consistent                            0.00862   \n                emotional                             0.00802   \n                engaging                              0.00887   \n                grammatical                           0.00000   \n                informative                           0.00046   \n                proactive                             0.01032   \n                quality                               0.00825   \n                relevant                              0.01012   \nbehavior        antisocial                            0.00000   \n                commonsense contradiction             0.02971   \n                correct fact                          0.00014   \n                empathetic                            0.01478   \n                follow up                             0.00282   \n                ignore                                0.01622   \n                incorrect fact                        0.00354   \n                irrelevant                            0.01750   \n                lack of empathy                       0.02008   \n                life info                             0.00148   \n                partner contradiction                 0.03531   \n                preference info                       0.00075   \n                redundant                             0.01548   \n                self contradiction                    0.00783   \n                topic switch                          0.00027   \n                uninterpretable                       0.00352   \nlikert dialogue consistent                            0.12196   \n                emotional                             0.10688   \n                engaging                              0.17640   \n                grammatical                           0.03533   \n                informative                           0.08125   \n                proactive                             0.12848   \n                quality                               1.00000   \n                relevant                              0.13511   \n\nPredicted                                                      \nMetric                                    P value of LLR-test  \ncategory        label                                          \nlikert turn     consistent                            0.00225  \n                emotional                             0.00320  \n                engaging                              0.00194  \n                grammatical                           0.95730  \n                informative                           0.47933  \n                proactive                             0.00083  \n                quality                               0.00280  \n                relevant                              0.00093  \nbehavior        antisocial                            0.96702  \n                commonsense contradiction             0.00000  \n                correct fact                          0.69687  \n                empathetic                            0.00006  \n                follow up                             0.08057  \n                ignore                                0.00003  \n                incorrect fact                        0.05009  \n                irrelevant                            0.00001  \n                lack of empathy                       0.00000  \n                life info                             0.20531  \n                partner contradiction                 0.00000  \n                preference info                       0.36851  \n                redundant                             0.00004  \n                self contradiction                    0.00359  \n                topic switch                          0.58954  \n                uninterpretable                       0.05075  \nlikert dialogue consistent                            0.00000  \n                emotional                             0.00000  \n                engaging                              0.00000  \n                grammatical                           0.00000  \n                informative                           0.00000  \n                proactive                             0.00000  \n                quality                               0.00000  \n                relevant                              0.00000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th>Predicted</th>\n      <th colspan=\"3\" halign=\"left\">Likert Turn Quality</th>\n      <th colspan=\"5\" halign=\"left\">Likert Dialogue Quality</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>Metric</th>\n      <th>LR Coefficient</th>\n      <th>LR R-Squared</th>\n      <th>P value of F-test</th>\n      <th>LR Coefficient</th>\n      <th>LR R-Squared</th>\n      <th>P value of F-test</th>\n      <th>OR Pseudo R-Squared</th>\n      <th>P value of LLR-test</th>\n    </tr>\n    <tr>\n      <th>category</th>\n      <th>label</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"8\" valign=\"top\">likert turn</th>\n      <th>consistent</th>\n      <td>0.22018</td>\n      <td>0.04654</td>\n      <td>0.00001</td>\n      <td>0.24864</td>\n      <td>0.02760</td>\n      <td>0.00085</td>\n      <td>0.00862</td>\n      <td>0.00225</td>\n    </tr>\n    <tr>\n      <th>emotional</th>\n      <td>0.16635</td>\n      <td>0.02928</td>\n      <td>0.00059</td>\n      <td>0.22243</td>\n      <td>0.02434</td>\n      <td>0.00175</td>\n      <td>0.00802</td>\n      <td>0.00320</td>\n    </tr>\n    <tr>\n      <th>engaging</th>\n      <td>0.16493</td>\n      <td>0.04114</td>\n      <td>0.00004</td>\n      <td>0.19437</td>\n      <td>0.02657</td>\n      <td>0.00107</td>\n      <td>0.00887</td>\n      <td>0.00194</td>\n    </tr>\n    <tr>\n      <th>grammatical</th>\n      <td>0.29904</td>\n      <td>0.06781</td>\n      <td>0.00000</td>\n      <td>0.00659</td>\n      <td>0.00002</td>\n      <td>0.93777</td>\n      <td>0.00000</td>\n      <td>0.95730</td>\n    </tr>\n    <tr>\n      <th>informative</th>\n      <td>0.01924</td>\n      <td>0.00040</td>\n      <td>0.68836</td>\n      <td>-0.05261</td>\n      <td>0.00141</td>\n      <td>0.45444</td>\n      <td>0.00046</td>\n      <td>0.47933</td>\n    </tr>\n    <tr>\n      <th>proactive</th>\n      <td>0.21331</td>\n      <td>0.06253</td>\n      <td>0.00000</td>\n      <td>0.22051</td>\n      <td>0.03107</td>\n      <td>0.00040</td>\n      <td>0.01032</td>\n      <td>0.00083</td>\n    </tr>\n    <tr>\n      <th>quality</th>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>0.22776</td>\n      <td>0.02412</td>\n      <td>0.00184</td>\n      <td>0.00825</td>\n      <td>0.00280</td>\n    </tr>\n    <tr>\n      <th>relevant</th>\n      <td>0.25511</td>\n      <td>0.09226</td>\n      <td>0.00000</td>\n      <td>0.21768</td>\n      <td>0.03124</td>\n      <td>0.00038</td>\n      <td>0.01012</td>\n      <td>0.00093</td>\n    </tr>\n    <tr>\n      <th rowspan=\"16\" valign=\"top\">behavior</th>\n      <th>antisocial</th>\n      <td>-3.60729</td>\n      <td>0.00827</td>\n      <td>0.06928</td>\n      <td>-0.00927</td>\n      <td>0.00000</td>\n      <td>0.99747</td>\n      <td>0.00000</td>\n      <td>0.96702</td>\n    </tr>\n    <tr>\n      <th>commonsense contradiction</th>\n      <td>-1.19415</td>\n      <td>0.06063</td>\n      <td>0.00000</td>\n      <td>-2.06686</td>\n      <td>0.08446</td>\n      <td>0.00000</td>\n      <td>0.02971</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>correct fact</th>\n      <td>-0.37007</td>\n      <td>0.01075</td>\n      <td>0.03816</td>\n      <td>-0.08224</td>\n      <td>0.00025</td>\n      <td>0.75402</td>\n      <td>0.00014</td>\n      <td>0.69687</td>\n    </tr>\n    <tr>\n      <th>empathetic</th>\n      <td>0.53305</td>\n      <td>0.03006</td>\n      <td>0.00050</td>\n      <td>0.90559</td>\n      <td>0.04034</td>\n      <td>0.00005</td>\n      <td>0.01478</td>\n      <td>0.00006</td>\n    </tr>\n    <tr>\n      <th>follow up</th>\n      <td>0.51605</td>\n      <td>0.03255</td>\n      <td>0.00029</td>\n      <td>0.32794</td>\n      <td>0.00611</td>\n      <td>0.11850</td>\n      <td>0.00282</td>\n      <td>0.08057</td>\n    </tr>\n    <tr>\n      <th>ignore</th>\n      <td>-1.71880</td>\n      <td>0.07233</td>\n      <td>0.00000</td>\n      <td>-1.96812</td>\n      <td>0.04410</td>\n      <td>0.00002</td>\n      <td>0.01622</td>\n      <td>0.00003</td>\n    </tr>\n    <tr>\n      <th>incorrect fact</th>\n      <td>-0.90583</td>\n      <td>0.03955</td>\n      <td>0.00006</td>\n      <td>-0.69496</td>\n      <td>0.01083</td>\n      <td>0.03750</td>\n      <td>0.00354</td>\n      <td>0.05009</td>\n    </tr>\n    <tr>\n      <th>irrelevant</th>\n      <td>-1.21588</td>\n      <td>0.05546</td>\n      <td>0.00000</td>\n      <td>-1.66669</td>\n      <td>0.04846</td>\n      <td>0.00001</td>\n      <td>0.01750</td>\n      <td>0.00001</td>\n    </tr>\n    <tr>\n      <th>lack of empathy</th>\n      <td>-1.03156</td>\n      <td>0.03894</td>\n      <td>0.00007</td>\n      <td>-1.82071</td>\n      <td>0.05641</td>\n      <td>0.00000</td>\n      <td>0.02008</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>life info</th>\n      <td>0.21801</td>\n      <td>0.00280</td>\n      <td>0.29079</td>\n      <td>0.42049</td>\n      <td>0.00485</td>\n      <td>0.16446</td>\n      <td>0.00148</td>\n      <td>0.20531</td>\n    </tr>\n    <tr>\n      <th>partner contradiction</th>\n      <td>-1.43733</td>\n      <td>0.03773</td>\n      <td>0.00009</td>\n      <td>-3.32392</td>\n      <td>0.09382</td>\n      <td>0.00000</td>\n      <td>0.03531</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>preference info</th>\n      <td>0.35770</td>\n      <td>0.01165</td>\n      <td>0.03094</td>\n      <td>0.25218</td>\n      <td>0.00269</td>\n      <td>0.30064</td>\n      <td>0.00075</td>\n      <td>0.36851</td>\n    </tr>\n    <tr>\n      <th>redundant</th>\n      <td>-0.42178</td>\n      <td>0.00264</td>\n      <td>0.30520</td>\n      <td>-2.65851</td>\n      <td>0.04880</td>\n      <td>0.00001</td>\n      <td>0.01548</td>\n      <td>0.00004</td>\n    </tr>\n    <tr>\n      <th>self contradiction</th>\n      <td>-1.19834</td>\n      <td>0.02215</td>\n      <td>0.00285</td>\n      <td>-1.82208</td>\n      <td>0.02381</td>\n      <td>0.00197</td>\n      <td>0.00783</td>\n      <td>0.00359</td>\n    </tr>\n    <tr>\n      <th>topic switch</th>\n      <td>-0.64819</td>\n      <td>0.01557</td>\n      <td>0.01252</td>\n      <td>-0.15859</td>\n      <td>0.00043</td>\n      <td>0.67809</td>\n      <td>0.00027</td>\n      <td>0.58954</td>\n    </tr>\n    <tr>\n      <th>uninterpretable</th>\n      <td>-2.07462</td>\n      <td>0.00883</td>\n      <td>0.06044</td>\n      <td>-3.30846</td>\n      <td>0.01044</td>\n      <td>0.04108</td>\n      <td>0.00352</td>\n      <td>0.05075</td>\n    </tr>\n    <tr>\n      <th rowspan=\"8\" valign=\"top\">likert dialogue</th>\n      <th>consistent</th>\n      <td>0.03822</td>\n      <td>0.00604</td>\n      <td>0.12082</td>\n      <td>0.38390</td>\n      <td>0.28328</td>\n      <td>0.00000</td>\n      <td>0.12196</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>emotional</th>\n      <td>0.09712</td>\n      <td>0.02544</td>\n      <td>0.00137</td>\n      <td>0.45774</td>\n      <td>0.26276</td>\n      <td>0.00000</td>\n      <td>0.10688</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>engaging</th>\n      <td>0.08389</td>\n      <td>0.01732</td>\n      <td>0.00840</td>\n      <td>0.58396</td>\n      <td>0.39031</td>\n      <td>0.00000</td>\n      <td>0.17640</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>grammatical</th>\n      <td>0.03235</td>\n      <td>0.00221</td>\n      <td>0.34831</td>\n      <td>0.28315</td>\n      <td>0.07875</td>\n      <td>0.00000</td>\n      <td>0.03533</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>informative</th>\n      <td>0.01647</td>\n      <td>0.00057</td>\n      <td>0.63504</td>\n      <td>0.46460</td>\n      <td>0.20974</td>\n      <td>0.00000</td>\n      <td>0.08125</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>proactive</th>\n      <td>0.05898</td>\n      <td>0.01004</td>\n      <td>0.04517</td>\n      <td>0.47087</td>\n      <td>0.29764</td>\n      <td>0.00000</td>\n      <td>0.12848</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>quality</th>\n      <td>0.10592</td>\n      <td>0.02412</td>\n      <td>0.00184</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>relevant</th>\n      <td>0.12210</td>\n      <td>0.03822</td>\n      <td>0.00008</td>\n      <td>0.51230</td>\n      <td>0.31291</td>\n      <td>0.00000</td>\n      <td>0.13511</td>\n      <td>0.00000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.miscmodels.ordinal_model import OrderedModel\n",
    "from statsmodels.regression.linear_model import OLS as LinearModel\n",
    "from statsmodels.tools.tools import add_constant\n",
    "\n",
    "def dialogue_metrics(ev):\n",
    "    df: pd.DataFrame = ev.annotation_dataframe()\n",
    "    df = get_singly_annotated(df, seed=123)\n",
    "    reindexed = df.reset_index()\n",
    "    items = reindexed[sym.item]\n",
    "    dialogues = [e[0] if isinstance(e, tuple) else e for e in items]\n",
    "    reindexed['dialogue'] = dialogues\n",
    "    reindexed.set_index(\n",
    "        [sym.bot, sym.category, sym.label, 'dialogue', sym.item],\n",
    "        inplace=True, verify_integrity=True\n",
    "    )\n",
    "    ld = reindexed.xs(category.likert_dialogue, level=sym.category)\n",
    "    ld = ld.droplevel(sym.bot).droplevel(sym.item)\n",
    "    ld.columns = ['score']\n",
    "    ldq = ld.xs(scale.quality, level=sym.label)\n",
    "    ldq.columns = ['quality']\n",
    "\n",
    "    lt = reindexed.xs(category.likert_turn, level=sym.category)\n",
    "    lt = lt.groupby([sym.label, 'dialogue']).mean()\n",
    "    lt.columns = ['score']\n",
    "    ltq = lt.xs(scale.quality, level=sym.label)\n",
    "    ltq.columns = ['quality']\n",
    "\n",
    "    be = reindexed.xs(category.behavior, level=sym.category)\n",
    "    be = be.groupby([sym.label, 'dialogue']).mean()\n",
    "    be.columns = ['score']\n",
    "\n",
    "    ds = pd.concat(\n",
    "        [lt, be, ld],\n",
    "        keys=[category.likert_turn, category.behavior, category.likert_dialogue],\n",
    "        names=[sym.category, sym.label, 'dialogue']\n",
    "    )\n",
    "    likert_dialogue_quality_features = ds.join(ldq, on='dialogue')\n",
    "    likert_turn_quality_features = ds.join(ltq, on='dialogue')\n",
    "    return likert_dialogue_quality_features, likert_turn_quality_features\n",
    "\n",
    "\n",
    "def regressions(df, quality_column_name=None, model='linear'):\n",
    "    \"\"\"\n",
    "    :param df: dialogue x (*features, quality) -> value\n",
    "    :return: *(coef, low, high), mcfadden r^2\n",
    "    \"\"\"\n",
    "    if not quality_column_name:\n",
    "        quality_column_name = df.columns[-1]\n",
    "    qualities = df[quality_column_name]\n",
    "    features = [f for f in df.columns if f != quality_column_name]\n",
    "    if model == 'ordinal':\n",
    "        model = OrderedModel(qualities, df[features], distr='logit')\n",
    "        results = model.fit()\n",
    "        coefs = {f: results.params[f] for f in features}\n",
    "        prsqrd = results.prsquared\n",
    "        result = {stat.mcfad_r2: prsqrd, 'P value of LLR-test': results.llr_pvalue}\n",
    "    elif model == 'linear':\n",
    "        x = add_constant(df[features])\n",
    "        y = qualities\n",
    "        model = LinearModel(y, x)\n",
    "        results = model.fit()\n",
    "        coefs = {f: results.params[f] for f in features}\n",
    "        rsquared = results.rsquared\n",
    "        result = {**coefs, 'R-Squared': rsquared, 'P value of F-test': results.f_pvalue}\n",
    "    else:\n",
    "        raise ValueError('Param \"model\" must be one of {\"linear\", \"ordinal\"}')\n",
    "    return pd.Series(result.values(), result)\n",
    "\n",
    "@to_file\n",
    "def dialogue_quality_regressions(ev):\n",
    "    ldq, ltq = dialogue_metrics(ev)\n",
    "    ldq_groups = ldq.groupby(\n",
    "        [sym.category, sym.label]\n",
    "    )\n",
    "    ltq_groups = ltq.groupby(\n",
    "        [sym.category, sym.label]\n",
    "    )\n",
    "    names = ['Predicted', 'Metric']\n",
    "    linear_result = ldq_groups.apply(lambda x: regressions(x, model='linear'))\n",
    "    linear_result.columns = pd.MultiIndex.from_arrays(\n",
    "        [['Likert Dialogue Quality']*3,\n",
    "        ['LR Coefficient', 'LR R-Squared', 'P value of F-test']],\n",
    "        names=names\n",
    "    )\n",
    "    ordinal_result = ldq_groups.apply(lambda x: regressions(x, model='ordinal'))\n",
    "    ordinal_result.columns = pd.MultiIndex.from_arrays(\n",
    "        [['Likert Dialogue Quality']*2,\n",
    "        ['OR Pseudo R-Squared', 'P value of LLR-test']],\n",
    "        names=names\n",
    "    )\n",
    "    linear_turn_result = ltq_groups.apply(regressions)\n",
    "    linear_turn_result.columns = pd.MultiIndex.from_arrays(\n",
    "        [['Likert Turn Quality']*3,\n",
    "        ['LR Coefficient', 'LR R-Squared', 'P value of F-test']],\n",
    "        names=names\n",
    "    )\n",
    "    result = pd.concat((linear_turn_result, linear_result, ordinal_result), axis=1)\n",
    "    return result.round(5)\n",
    "\n",
    "dialogue_quality_regressions(\n",
    "    data.surge_evaluation,\n",
    "    load='results/dialogue_quality_regressions'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def stepwise_regression(df: pd.DataFrame, quality_column_name=None, model='linear'):\n",
    "    if model == 'linear':\n",
    "        ...\n",
    "    elif model == 'ordinal':\n",
    "        ...\n",
    "    left = ...\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}